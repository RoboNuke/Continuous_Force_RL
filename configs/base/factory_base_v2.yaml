# Base Factory Configuration V2
# Updated for ConfigManagerV2 - No reference syntax, direct values only

# Task name (required for new config system)
task_name: "Isaac-Factory-PegInsert-Direct-v0"

# PRIMARY PARAMETERS (overrides defaults in PrimaryConfig)
primary:
  agents_per_break_force: 2  # Number of agents per break force condition
  num_envs_per_agent: 256    # Environments per individual agent
  break_forces: -1  # Break force conditions (-1 = unbreakable)
  decimation: 8
  policy_hz: 15
  max_steps: 10240000
  debug_mode: false
  seed: -1
  ckpt_tracker_path: "/nfs/stak/users/brownhun/ckpt_tracker2.txt"
  ctrl_torque: false

# ENVIRONMENT OVERRIDES (Direct Isaac Lab FactoryEnvCfg parameters)
environment:
  # episode_length_s comes from Isaac Lab defaults (10.0s for peg insert)
  # decimation comes from primary config applied automatically
  filter_collisions: true

  # Observation attribute mapping for Isaac Lab integration
  component_attr_map:
    fingertip_pos: "fingertip_midpoint_pos"
    fingertip_pos_rel_fixed: "fingertip_pos_rel_fixed"
    fingertip_quat: "fingertip_midpoint_quat"
    ee_linvel: "ee_linvel_fd"
    ee_angvel: "ee_angvel_fd"
    joint_pos: "joint_pos"
    prev_actions: "prev_actions"
    force_torque: "robot_force_torque"
    held_pos: "held_pos"
    held_pos_rel_fixed: "held_pos_rel_fixed"
    held_quat: "held_quat"
    fixed_pos: "fixed_pos"
    fixed_quat: "fixed_quat"

  # Factory task configuration (will be merged into Isaac Lab's task config)
  task:
    name: "peg_insert"  # Used for task-specific logic

# MODEL CONFIGURATION (SimBa architecture parameters)
model:
  # Standard model parameters
  force_encoding: null
  last_layer_scale: 1.0
  act_init_std: 1.0
  critic_output_init_mean: 50

  # Actor architecture (SimBa policy network)
  actor:
    n: 1  # Number of SimBa layers
    latent_size: 256  # Hidden dimension

  # Critic architecture (SimBa value network)
  critic:
    n: 3  # Number of SimBa layers
    latent_size: 1024  # Hidden dimension

  # Hybrid agent configuration
  use_hybrid_agent: false

# WRAPPERS CONFIGURATION (Direct wrapper parameters)
wrappers:
  # Fragile object behavior
  fragile_objects:
    enabled: true
    # break_force and num_agents are computed from primary config automatically

  # Efficient environment resetting
  efficient_reset:
    enabled: true

  # Force-torque sensor
  force_torque_sensor:
    enabled: false
    use_tanh_scaling: false
    tanh_scale: 0.03

  # Observation format conversion (Isaac Lab dict -> single tensor)
  observation_manager:
    enabled: true
    merge_strategy: "concatenate"

  # Domain randomization noise
  observation_noise:
    enabled: false
    global_scale: 1.0
    apply_to_critic: true
    seed: null

  # Hybrid force-position control
  hybrid_control:
    enabled: false
    # ctrl_torque is computed from primary config automatically
    reward_type: "simp"

  # Factory-specific metrics tracking
  factory_metrics:
    enabled: true
    # num_agents is computed from primary config automatically

  # Wandb logging with factory metrics
  wandb_logging:
    enabled: true
    wandb_project: "Continuous_Force_RL"
    wandb_entity: "hur"
    wandb_name: null
    wandb_group: null
    wandb_tags: []

  # Enhanced action logging
  action_logging:
    enabled: false
    track_selection: true
    track_pos: true
    track_rot: true
    track_force: true
    track_torque: true
    force_size: 6
    logging_frequency: 100

# EXPERIMENT CONFIGURATION
experiment:
  name: "factory_base"
  tags: ["baseline", "factory"]
  group: "factory_experiments"
  wandb_project: "Continuous_Force_RL"
  wandb_entity: "hur"

# AGENT CONFIGURATION (SKRL PPO parameters + custom extensions)
agent:
  # Core identification
  class: "PPO"
  disable_progressbar: true

  # Checkpoint and experiment tracking
  track_ckpts: true
  # ckpt_tracker_path comes from primary config automatically

  # Experiment logging (will be updated by launch_utils)
  experiment_directory: "DEFAULT_DIRECTORY"
  experiment_name: "DEFAULT_EXP_NAME"
  write_interval: 150
  checkpoint_interval: 1500
  wandb_project: "OVERRIDE_WITH_ARG"
  wandb_tags: []
  wandb_group: ""

  # SKRL PPO PARAMETERS (these override SKRL defaults)
  # rollouts and mini_batches are auto-calculated from episode timing
  learning_epochs: 4
  mini_batches: 150
  discount_factor: 0.99
  lambda_: 0.95  # Note: underscore for Python compatibility
  random_timesteps: 0
  learning_starts: 0
  random_value_timesteps: 150
  mixed_precision: false

  # CUSTOM LEARNING PARAMETERS (extensions to SKRL)
  policy_learning_rate: 1.0e-6
  critic_learning_rate: 1.0e-5
  value_update_ratio: 2

  # Optimizer parameters
  optimizer_betas: [0.999, 0.999]
  optimizer_eps: 1.0e-8
  optimizer_weight_decay: 0

  # Loss and clipping
  use_huber_value_loss: true
  grad_norm_clip: 0.5
  ratio_clip: 0.2
  clip_predicted_values: false
  value_clip: 0.2
  entropy_loss_scale: 0.0
  value_loss_scale: 1.0
  kl_threshold: 0.05
  time_limit_bootstrap: true

  # Reward shaping
  reward_shaper_type: 'const_scale'
  rewards_shaper_scale: 0.1

  # Preprocessors
  state_preprocessor: true
  value_preprocessor: true

  # Learning rate scheduler
  learning_rate_scheduler: "KLAdaptiveLR"
  learning_rate_scheduler_kwargs:
    kl_threshold: 0.01
    min_lr: 1.0e-9