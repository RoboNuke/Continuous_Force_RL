# Hybrid Agent Control Experiment Configuration 

# Base configuration to inherit from
base_config: "configs/base/PiH_base.yaml"

primary:
  #agents_per_break_force: 1  # Number of agents per break force condition
  #num_envs_per_agent: 16    # Environments per individual agent
  ckpt_tracker_path: "/nfs/stak/users/brownhun/logFix_hybrid_agent_tracker.txt"
  #break_forces: [25]

# Model configuration for hybrid agent
model:
  use_hybrid_agent: true
  last_layer_scale: 0.1
  hybrid_agent:
    unit_std_init: false
    init_bias: 2.5 #1.1
    init_scale_last_layer: true
    init_layer_scale: 0.1
    pre_layer_scale_factor: 0.1

    unit_factor_std_init: 1.0

  use_separate_heads: false
  selection_head_hidden_dim: 64
  component_head_hidden_dim: 128

# Enable hybrid control wrapper and related systems
wrappers:
  # Enable hybrid control wrapper
  hybrid_control:
    enabled: true
    reward_type: "none"
    
  pose_contact_logging:
    enabled: false

environment:
  hybrid_task:
    good_force_cmd_rew: 0.134
    bad_force_cmd_rew: -0.134 #-0.4

#agent:
#policy_learning_rate: 5.0e-4
#critic_learning_rate: 1.0e-4
#value_update_ratio: 3
#learning_epochs: 1

# Experiment metadata
experiment:
  name: "hybrid_fix_noShuf_noAdv_pLR1-5"
  tags: []
  group: "hybrid_fix_noShuf_noAdv_pLR1-5"