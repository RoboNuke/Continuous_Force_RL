# Hybrid Agent Control Experiment Configuration 

# Base configuration to inherit from
base_config: "configs/base/PiH_base.yaml"

primary:
  ckpt_tracker_path: "/nfs/stak/users/brownhun/ckpt_trackers/LCLoP_noDer_ff_tracker.txt"
  max_steps: 10022400

# Model configuration for hybrid agent
model:
  use_hybrid_agent: true
  hybrid_agent:
    force_init_std: 0.1 # implies a 96% range [-2.5, 2.5] 

# Enable hybrid control wrapper and related systems
wrappers:
  # Enable hybrid control wrapper
  hybrid_control:
    enabled: true
    reward_type: "none"
    
  pose_contact_logging:
    enabled: false

agent:
  policy_learning_rate: 1.0e-5
  critic_learning_rate: 1.0e-5
  #learning_epochs: 1

environment:
  ctrl:
    force_action_bounds: [50.0, 50.0, 50.0]
    torque_action_bounds: [0.5, 0.5, 0.5]
    force_action_threshold: [10.0, 10.0, 10.0]
    torque_action_threshold: [0.1, 0.1, 0.1]
    default_task_force_gains: [0.1, 0.1, 0.1, 0.001, 0.001, 0.001]

# Experiment metadata
experiment:
  name: "LCLoP2_noDer_ff_test"
  tags: ['Force-Force']
  group: "LCLoP2_noDer_ff_test"