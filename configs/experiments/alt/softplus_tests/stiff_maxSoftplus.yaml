# Hybrid Agent Control Experiment Configuration 

# Base configuration to inherit from
base_config: "configs/base/PiH_base.yaml"

primary:
  agents_per_break_force: 5 # Number of agents per break force condition
  num_envs_per_agent: 256   # Environments per individual agent
  max_steps: 3000064 #25000192

# Model configuration for hybrid agent
model:
  use_hybrid_agent: true
  #hybrid_agent:
  #  force_init_std: 0.1 # implies a 96% range [-2.5, 2.5] 

# Enable hybrid control wrapper and related systems
wrappers:
  # Enable hybrid control wrapper
  hybrid_control:
    enabled: true
    reward_type: "none"
    use_ground_truth_selection: false
    
  pose_contact_logging:
    enabled: false


  force_reward:
    enable_contact_reward: false
    contact_reward_weight: 2.0

    enable_softplus: true
    softplus_weight: 2.0
    enable_softplus_max: true

agent:
  supervised_selection_loss_weight: 1.0
#  policy_learning_rate: 5.0e-4
#  critic_learning_rate: 1.0e-4
#  #learning_epochs: 1

environment:
  sim:
    physx:
      solver_type: 1
      max_position_iteration_count: &pos_iter 32  # Important to avoid interpenetration.
      max_velocity_iteration_count: &vel_iter 8
      bounce_threshold_velocity: 0.2
      friction_offset_threshold: 0.01
      friction_correlation_distance: 0.00625
      #gpu_max_rigid_contact_count: 2**23
      #gpu_max_rigid_patch_count: 2**23
      gpu_max_num_partitions: 1

  robot:
    spawn:
      rigid_props:
        solver_position_iteration_count: *pos_iter
        solver_velocity_iteration_count: *vel_iter
        linear_damping: &lin_damp 0.0

      articulation_props:
        solver_position_iteration_count: *pos_iter
        solver_velocity_iteration_count: *vel_iter

  task:
    fixed_asset:
      spawn:
        rigid_props:
          solver_position_iteration_count: *pos_iter
          solver_velocity_iteration_count: *vel_iter
          linear_damping: *lin_damp

    held_asset:
      spawn:
        rigid_props:
          solver_position_iteration_count: *pos_iter
          solver_velocity_iteration_count: *vel_iter
          linear_damping: *lin_damp

  ctrl:
    apply_ema_force: true
    async_z_force_bounds: true
    force_action_bounds: [20.0, 20.0, 20.0] #
    torque_action_bounds: [0.5, 0.5, 0.5]
    force_action_threshold: [2.0, 2.0, 2.0] #
    torque_action_threshold: [0.1, 0.1, 0.1]

    default_task_prop_gains: [565.0, 565.0, 565.0, 28.0, 28.0, 28.0]
    default_task_force_gains: [0.5, 0.5, 0.5, 0.001, 0.001, 0.001]

    no_sel_ema: true
    use_delta_force: false  # false=absolute (action*bounds), true=delta (action*threshold+current)

    # Force PID control
    enable_force_derivative: false  # Enable D term (velocity damping) in force control
    enable_force_integral: false    # Enable I term in force control
    default_task_force_integ_gains: [0.01, 0.01, 0.01, 0.001, 0.001, 0.001]  # Ki gains
    force_integral_clamp: 50.0      # Anti-windup clamp for integral term

  # OBSERVATION RANDOMIZATION CONFIGURATION
  obs_rand:
    fixed_asset_pos: [0.001, 0.001, 0.001]  
    
# Experiment metadata
experiment:
  name: &exp_name "LCLoP_stiffNewEnv_maxSoftplus-2"
  tags: ['exp_perf-comp']
  group: *exp_name