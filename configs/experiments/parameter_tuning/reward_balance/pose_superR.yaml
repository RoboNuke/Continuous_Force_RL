# Hybrid Agent Control Experiment Configuration 

# Base configuration to inherit from
base_config: "configs/base/PiH_base.yaml"

primary:
  agents_per_break_force: 5 # Number of agents per break force condition
  num_envs_per_agent: 256   # Environments per individual agent
  max_steps: 10000128 #3000064 #25000192

# Model configuration for hybrid agent
model:
  use_hybrid_agent: false

environment:
  # OBSERVATION RANDOMIZATION CONFIGURATION
  obs_rand:
    fixed_asset_pos: [0.0025, 0.0025, 0.0025]  

wrappers:
  fragile_objects:
    peg_break_rew: -15.0

  factory_metrics:
    engagement_reward_scale: 60.0  # Scale for engagement rewards (default 1.0 = no change)
    success_reward_scale: 40.0
    timeout_penalty: -20.0
  
  force_reward:
    enable_contact_reward: false
    contact_reward_weight: 2.0

    enable_square_vel: false
    square_vel_weight: 10.0

agent:
  rewards_shaper_scale: 0.00625 #0.1
# Experiment metadata
experiment:
  name: "pose_rewBalance5_super"
  tags: ['medFixedNoise','ft_noise','ee_pos_noise']
  group: "pose_rewBalance5_super"