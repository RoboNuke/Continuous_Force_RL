{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Clearance Comparison Analysis\n",
    "\n",
    "This notebook generates a 2Ã—N grid comparing performance across different clearance values:\n",
    "- Top row: Success Rate vs Position Noise\n",
    "- Bottom row: Break Rate vs Position Noise\n",
    "- Gold highlight box around the reference clearance level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BLOCK 1: IMPORTS & LOCAL CONFIGURATION\n# ============================================================\n\nimport wandb\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\n# Import shared utilities\nfrom analysis_utils import (\n    # Constants\n    ENTITY, PROJECT, COLORS,\n    TAG_EVAL_PERFORMANCE, TAG_EVAL_NOISE,\n    METRIC_SUCCESS, METRIC_BREAKS, METRIC_TOTAL,\n    # Data functions\n    get_best_checkpoint_per_run,\n    download_eval_data,\n    # Plotting functions\n    plot_multi_panel_grid,\n    print_data_summary,\n)\n\n# ============================================================\n# LOCAL CONFIGURATION (specific to this analysis)\n# ============================================================\n\n# Clearance Levels - keys are internal names, each contains method tags\nCLEARANCE_LEVELS = {\n    \"0.5mm\": {\n        \"Pose\": \"PLACEHOLDER_POSE_0.5MM\",\n        \"Hybrid-Basic\": \"PLACEHOLDER_HYBRID_0.5MM\",\n        \"LCLoP\": \"PLACEHOLDER_LCLOP_0.5MM\",\n    },\n    \"1mm\": {\n        \"Pose\": \"PLACEHOLDER_POSE_1MM\",\n        \"Hybrid-Basic\": \"PLACEHOLDER_HYBRID_1MM\",\n        \"LCLoP\": \"PLACEHOLDER_LCLOP_1MM\",\n    },\n    \"2mm\": {\n        \"Pose\": \"PLACEHOLDER_POSE_2MM\",\n        \"Hybrid-Basic\": \"PLACEHOLDER_HYBRID_2MM\",\n        \"LCLoP\": \"PLACEHOLDER_LCLOP_2MM\",\n    },\n    \"4mm\": {\n        \"Pose\": \"PLACEHOLDER_POSE_4MM\",\n        \"Hybrid-Basic\": \"PLACEHOLDER_HYBRID_4MM\",\n        \"LCLoP\": \"PLACEHOLDER_LCLOP_4MM\",\n    },\n}\n\n# Display name mapping\nCLEARANCE_DISPLAY_NAMES = {\n    \"0.5mm\": \"Clearance = 0.5mm\",\n    \"1mm\": \"Clearance = 1mm\",\n    \"2mm\": \"Clearance = 2mm\",\n    \"4mm\": \"Clearance = 4mm\",\n}\n\n# Noise Level Mapping: display label -> metric range string\nNOISE_LEVELS = {\n    \"1mm\": \"0mm-1mm\",\n    \"2.5mm\": \"1mm-2.5mm\",\n    \"5mm\": \"2.5mm-5mm\",\n    \"7.5mm\": \"5mm-7.5mm\",\n}\n\n# Policy Selection\nTOP_N_POLICIES = None\nMAX_CHECKPOINT = None  # Set to int to limit checkpoint search (e.g., 2000000 for first 2M steps)\n\n# Highlight Configuration\nHIGHLIGHT_CLEARANCE = \"1mm\"  # Which clearance to highlight with gold box, or None\n\n# N/A panels (for clearance levels where break rate is not applicable)\nNA_CLEARANCES = []\n\n# Plot Configuration\nSUCCESS_Y_LIM = (0, 100)\nSUCCESS_Y_TICKS = [0, 20, 40, 60, 80, 100]\nBREAK_Y_LIM = (0, 25)\nBREAK_Y_TICKS = [0, 5, 10, 15, 20, 25]\n\n# Error type: \"ci\" for 95% confidence interval, \"binary_se\" for binary standard error\nERROR_TYPE = \"ci\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BLOCK 2: DETERMINE BEST POLICY\n# ============================================================\n\napi = wandb.Api()\nbest_checkpoints = defaultdict(dict)  # best_checkpoints[clearance][method]\n\nfor clearance, method_tags in CLEARANCE_LEVELS.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"Clearance: {clearance}\")\n    print(f\"{'='*60}\")\n    for method_name, method_tag in method_tags.items():\n        print(f\"\\n  {method_name} ({method_tag}):\")\n        best_checkpoints[clearance][method_name] = get_best_checkpoint_per_run(\n            api, method_tag, max_checkpoint=MAX_CHECKPOINT\n        )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 3: DOWNLOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "noise_data = defaultdict(dict)  # noise_data[clearance][method]\n",
    "\n",
    "for clearance, method_tags in CLEARANCE_LEVELS.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Downloading data for Clearance: {clearance}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for method_name, method_tag in method_tags.items():\n",
    "        print(f\"\\n  {method_name}...\")\n",
    "        noise_data[clearance][method_name] = download_eval_data(\n",
    "            api=api,\n",
    "            method_tag=method_tag,\n",
    "            best_checkpoints=best_checkpoints[clearance][method_name],\n",
    "            level_mapping=NOISE_LEVELS,\n",
    "            prefix_template=\"Noise_Eval({level})_Core\",\n",
    "            level_col_name=\"noise_level\",\n",
    "            eval_tag=TAG_EVAL_NOISE,\n",
    "        )\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for clearance in CLEARANCE_LEVELS.keys():\n",
    "    print(f\"\\n{clearance}:\")\n",
    "    for method_name in CLEARANCE_LEVELS[clearance].keys():\n",
    "        df = noise_data[clearance][method_name]\n",
    "        if not df.empty:\n",
    "            num_runs = df[\"run_name\"].nunique()\n",
    "            print(f\"  {method_name}: {num_runs} runs\")\n",
    "        else:\n",
    "            print(f\"  {method_name}: No data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 4: CLEARANCE COMPARISON FIGURE\n",
    "# ============================================================\n",
    "\n",
    "# Get method names from first clearance level\n",
    "method_names = list(CLEARANCE_LEVELS[list(CLEARANCE_LEVELS.keys())[0]].keys())\n",
    "\n",
    "# Success Rate Plot\n",
    "fig, axes = plot_multi_panel_grid(\n",
    "    data=dict(noise_data),\n",
    "    panel_keys=list(CLEARANCE_LEVELS.keys()),\n",
    "    panel_display_names=CLEARANCE_DISPLAY_NAMES,\n",
    "    method_names=method_names,\n",
    "    level_labels=list(NOISE_LEVELS.keys()),\n",
    "    level_col=\"noise_level\",\n",
    "    metric=\"success\",\n",
    "    n_cols=len(CLEARANCE_LEVELS),  # All clearances in one row\n",
    "    suptitle=\"Performance vs Position Noise Across Clearance Values\",\n",
    "    x_label=\"Position Noise\",\n",
    "    y_label=\"Success Rate (%)\",\n",
    "    y_lim=SUCCESS_Y_LIM,\n",
    "    y_ticks=SUCCESS_Y_TICKS,\n",
    "    figsize_per_cell=(3.5, 3),\n",
    "    error_type=ERROR_TYPE,\n",
    "    highlight_panel=HIGHLIGHT_CLEARANCE,\n",
    "    filter_top_n=TOP_N_POLICIES,\n",
    "    best_checkpoints=dict(best_checkpoints),\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Break Rate Plot\n",
    "fig, axes = plot_multi_panel_grid(\n",
    "    data=dict(noise_data),\n",
    "    panel_keys=list(CLEARANCE_LEVELS.keys()),\n",
    "    panel_display_names=CLEARANCE_DISPLAY_NAMES,\n",
    "    method_names=method_names,\n",
    "    level_labels=list(NOISE_LEVELS.keys()),\n",
    "    level_col=\"noise_level\",\n",
    "    metric=\"breaks\",\n",
    "    n_cols=len(CLEARANCE_LEVELS),  # All clearances in one row\n",
    "    suptitle=\"Break Rate vs Position Noise Across Clearance Values\",\n",
    "    x_label=\"Position Noise\",\n",
    "    y_label=\"Break Rate (%)\",\n",
    "    y_lim=BREAK_Y_LIM,\n",
    "    y_ticks=BREAK_Y_TICKS,\n",
    "    figsize_per_cell=(3.5, 3),\n",
    "    error_type=ERROR_TYPE,\n",
    "    highlight_panel=HIGHLIGHT_CLEARANCE,\n",
    "    na_panels=NA_CLEARANCES,\n",
    "    filter_top_n=TOP_N_POLICIES,\n",
    "    best_checkpoints=dict(best_checkpoints),\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}