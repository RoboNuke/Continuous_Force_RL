{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Trajectory Analysis\n",
    "\n",
    "This notebook generates trajectory visualization plots for detailed analysis of policy behavior.\n",
    "\n",
    "**Features:**\n",
    "- Runs `wandb_eval.py` via subprocess if trajectory data doesn't exist\n",
    "- Multi-panel trajectory plots with phase annotations\n",
    "- Break analysis by phase\n",
    "- Selection confidence comparison\n",
    "- Selection probability trajectories by phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 1: IMPORTS & CONSTANTS\n",
    "# ============================================================\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "# WandB Configuration\n",
    "ENTITY = \"hur\"\n",
    "PROJECT = \"SG_Exps\"\n",
    "\n",
    "# Method Tags - internal name -> wandb tag\n",
    "METHOD_TAGS = {\n",
    "    #\"Pose(1mm)\": \"pose_task_frag:2026-01-06_00:52\",\n",
    "    #\"Pose(2.5mm)\" : \"pose_25mm-noise:2026-01-19_07:50_15N\",\n",
    "    #\"Pose-7.5mm\":\"pose_75mm-noise:2026-01-17_19:18\",\n",
    "    #\"MATCH(1mm)\": \"LCLoP_task_frag:2026-01-06_00:27\",\n",
    "    #\"Hybrid-Basic(1mm)\": \"basic-hybrid_task_frag:2026-01-06_00:56\",\n",
    "\n",
    "    # hex\n",
    "    #\"Pose\": \"pose_hex:2026-01-13_22:49\",\n",
    "    #\"SWISH\": \"LCLoP_hex:2026-01-13_22:49\",\n",
    "\n",
    "\n",
    "    #\"Pose(1mm)\": \"pose_base-case:2026-02-02_13:40\",\n",
    "    #\"Pose(2.5mm)\": \"pose_25mm:2026-02-02_13:40\",\n",
    "    #\"MATCH(1mm)\": \"MATCH_base-case:2026-02-04_17:46\",\n",
    "    #\"Hybrid-Basic(1mm)\": \"basic-hybrid_base-case:2026-02-02_13:40\",\n",
    "\n",
    "    \"Pose(1mm)\": \"pose_breakable_f10N:2026-02-04_17:49\",\n",
    "    #\"Pose(2.5mm)\": \"pose_25mm_f10:2026-02-05_22:12\",\n",
    "    \"MATCH(1mm)\": \"MATCH_breakable_10N:2026-02-04_17:49\",\n",
    "    #\"Hybrid-Basic(1mm)\": \"basic-hybrid_breakable_f10N:2026-02-04_17:49\",\n",
    "}\n",
    "\n",
    "# Method display settings\n",
    "METHOD_COLORS = {\n",
    "    \"Pose(1mm)\": \"#2ca02c\",        # Green\n",
    "    \"Hybrid-Basic\": \"#ff7f0e\", # Orange\n",
    "    \"MATCH(1mm)\": \"#1f77b4\",       # Blue\n",
    "}\n",
    "\n",
    "# Evaluation Tags\n",
    "TAG_EVAL_PERFORMANCE = \"eval_performance\"\n",
    "\n",
    "# Metrics for best policy selection\n",
    "METRIC_SUCCESS = \"num_successful_completions\"\n",
    "METRIC_BREAKS = \"num_breaks\"\n",
    "\n",
    "# Trajectory Evaluation Configuration\n",
    "WANDB_EVAL_SCRIPT = \"../../eval/wandb_eval.py\"  # Relative to this notebook\n",
    "TRAJ_OUTPUT_BASE = \"../../eval/traj_data\"  # Base directory for trajectory data\n",
    "\n",
    "# Phase definitions (matching traj_vis.ipynb)\n",
    "PHASES = ['approaching', 'initial_contact', 'insertion']\n",
    "PHASE_COLORS = {\n",
    "    'approaching': '#90EE90',      # Light green\n",
    "    'initial_contact': '#FFD700',  # Gold\n",
    "    'insertion': '#87CEEB',        # Sky blue\n",
    "}\n",
    "\n",
    "# Outcome definitions\n",
    "OUTCOMES = ['success', 'break', 'timeout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Method: Pose(1mm) (pose_breakable_f10N:2026-02-04_17:49)\n",
      "============================================================\n",
      "  Found 15 training runs\n",
      "    pose_breakable_f(10)_0 (train:k90prlbx): best checkpoint at step 2188800 (score: 93)\n",
      "    pose_breakable_f(10)_1 (train:6r4liews): best checkpoint at step 1804800 (score: 91)\n",
      "    pose_breakable_f(10)_2 (train:4t553y8v): best checkpoint at step 1843200 (score: 92)\n",
      "    pose_breakable_f(10)_3 (train:54gdfza4): best checkpoint at step 2419200 (score: 92)\n",
      "    pose_breakable_f(10)_4 (train:46f1mxa0): best checkpoint at step 38400 (score: 0)\n",
      "\n",
      "============================================================\n",
      "Method: MATCH(1mm) (MATCH_breakable_10N:2026-02-04_17:49)\n",
      "============================================================\n",
      "  Found 15 training runs\n",
      "    MATCH_breakable_f(10)_0 (train:of3r2sqa): best checkpoint at step 1075200 (score: 95)\n",
      "    MATCH_breakable_f(10)_1 (train:jxbubm3w): best checkpoint at step 1651200 (score: 97)\n",
      "    MATCH_breakable_f(10)_2 (train:cev3fqe4): best checkpoint at step 2265600 (score: 97)\n",
      "    MATCH_breakable_f(10)_3 (train:mcsh8h2p): best checkpoint at step 1497600 (score: 82)\n",
      "    MATCH_breakable_f(10)_4 (train:zw7lzka0): best checkpoint at step 2073600 (score: 94)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 2: DETERMINE BEST POLICY\n",
    "# ============================================================\n",
    "\n",
    "def get_best_checkpoint_per_run(api, method_tag):\n",
    "    \"\"\"\n",
    "    Find the best checkpoint for each training run based on eval_performance runs.\n",
    "    \n",
    "    Returns dict mapping training_run_id -> {run_name, best_step, score, eval_run_id}\n",
    "    \"\"\"\n",
    "    # Query eval runs\n",
    "    eval_runs = api.runs(\n",
    "        f\"{ENTITY}/{PROJECT}\",\n",
    "        filters={\"$and\": [{\"tags\": method_tag}, {\"tags\": TAG_EVAL_PERFORMANCE}]}\n",
    "    )\n",
    "    \n",
    "    # Query training runs (have method_tag but NOT eval_performance)\n",
    "    training_runs = api.runs(\n",
    "        f\"{ENTITY}/{PROJECT}\",\n",
    "        filters={\"$and\": [{\"tags\": method_tag}, {\"tags\": {\"$ne\": TAG_EVAL_PERFORMANCE}}]}\n",
    "    )\n",
    "    \n",
    "    # Build lookup: training run name -> training run id\n",
    "    training_run_lookup = {}\n",
    "    for run in training_runs:\n",
    "        training_run_lookup[run.name] = run.id\n",
    "    \n",
    "    print(f\"  Found {len(training_run_lookup)} training runs\")\n",
    "    \n",
    "    best_checkpoints = {}\n",
    "    for eval_run in eval_runs:\n",
    "        history = eval_run.history()\n",
    "        if history.empty:\n",
    "            print(f\"  Warning: Eval run {eval_run.name} has no history data\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate score: successes - breaks\n",
    "        history[\"score\"] = history[f\"Eval_Core/{METRIC_SUCCESS}\"] - history[f\"Eval_Core/{METRIC_BREAKS}\"]\n",
    "        best_idx = history[\"score\"].idxmax()\n",
    "        best_step = int(history.loc[best_idx, \"total_steps\"])\n",
    "        \n",
    "        # Extract training run name from eval run name\n",
    "        # Eval run: \"Eval_performance_pose_perf-comp_f(10)_0\"\n",
    "        # Training run: \"pose_perf-comp_f(10)_0\"\n",
    "        eval_run_name = eval_run.name\n",
    "        if eval_run_name.startswith(\"Eval_performance_\"):\n",
    "            training_run_name = eval_run_name[len(\"Eval_performance_\"):]\n",
    "        elif eval_run_name.startswith(\"Eval_noise_\"):\n",
    "            training_run_name = eval_run_name[len(\"Eval_noise_\"):]\n",
    "        else:\n",
    "            # Try to find a matching training run by suffix\n",
    "            training_run_name = eval_run_name\n",
    "        \n",
    "        # Look up training run ID\n",
    "        if training_run_name not in training_run_lookup:\n",
    "            print(f\"  Warning: Could not find training run for eval run {eval_run_name}\")\n",
    "            print(f\"    Expected training run name: {training_run_name}\")\n",
    "            continue\n",
    "        \n",
    "        training_run_id = training_run_lookup[training_run_name]\n",
    "        \n",
    "        best_checkpoints[training_run_id] = {\n",
    "            \"run_name\": training_run_name,\n",
    "            \"best_step\": best_step,\n",
    "            \"score\": history.loc[best_idx, \"score\"],\n",
    "            \"eval_run_id\": eval_run.id,\n",
    "            \"eval_run_name\": eval_run_name,\n",
    "        }\n",
    "        print(f\"    {training_run_name} (train:{training_run_id}): best checkpoint at step {best_step} (score: {history.loc[best_idx, 'score']:.0f})\")\n",
    "    \n",
    "    return best_checkpoints\n",
    "\n",
    "# Get best checkpoints for each method\n",
    "api = wandb.Api()\n",
    "best_checkpoints = {}  # best_checkpoints[method]\n",
    "\n",
    "for method_name, method_tag in METHOD_TAGS.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Method: {method_name} ({method_tag})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    best_checkpoints[method_name] = get_best_checkpoint_per_run(api, method_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/hunter/Continuous_Force_RL\n",
      "Eval script: /home/hunter/Continuous_Force_RL/eval/wandb_eval.py\n",
      "Output base: /home/hunter/Continuous_Force_RL/eval/traj_data\n",
      "\n",
      "============================================================\n",
      "Processing: Pose(1mm)\n",
      "============================================================\n",
      "\n",
      "  Run: pose_breakable_f(10)_0 (id: k90prlbx)\n",
      "    Best checkpoint: 2188800 (score: 93)\n",
      "    Running trajectory evaluation...\n",
      "\n",
      "Command: /home/hunter/miniconda3/envs/isaaclab_drail/bin/python /home/hunter/Continuous_Force_RL/eval/wandb_eval.py --tag pose_breakable_f10N:2026-02-04_17:49 --checkpoint 2188800 --eval_mode trajectory --traj_output_dir /home/hunter/Continuous_Force_RL/eval/traj_data/pose_breakable_f10N_2026-02-04_17_49 --entity hur --project SG_Exps --run_id k90prlbx\n",
      "Working directory: /home/hunter/Continuous_Force_RL\n",
      "PYTHONPATH: /home/hunter/Continuous_Force_RL:/opt/ros/humble/lib/python3.10/site-packages:/opt/ros/humble/local/lib/python3.10/dist-packages\n",
      "\n",
      "------------------------------------------------------------\n",
      "Starting trajectory evaluation for k90prlbx at checkpoint 2188800...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Parsing arguments...\n",
      "Launching Isaac Sim AppLauncher...\n",
      "[INFO][AppLauncher]: Loading experience file: /home/hunter/IsaacLabDRAIL/IsaacLab/apps/isaaclab.python.headless.kit\n",
      "[Warning] [simulation_app.simulation_app] Modules: ['omni.kit_app'] were loaded before SimulationApp was started and might not be loaded correctly.\n",
      "[Warning] [simulation_app.simulation_app] Please check to make sure no extra omniverse or pxr modules are imported before the call to SimulationApp(...)\n",
      "Loading user config located at: '/home/hunter/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/omni/data/Kit/Isaac-Sim/4.5/user.config.json'\n",
      "[Info] [carb] Logging to file: /home/hunter/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/omni/logs/Kit/Isaac-Sim/4.5/kit_20260217_165608.log\n",
      "2026-02-18 00:56:08 [0ms] [Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.\n",
      "2026-02-18 00:56:09 [81ms] [Warning] [omni.usd_config.extension] Enable omni.materialx.libs extension to use MaterialX\n",
      "2026-02-18 00:56:09 [265ms] [Warning] [omni.datastore] OmniHub is inaccessible\n",
      "2026-02-18 00:56:09 [333ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.\n",
      "MESA: warning: Driver does not support the 0x7d67 PCI ID.\n",
      "MESA: warning: Driver does not support the 0x7d67 PCI ID.\n",
      "\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Driver Version: 580.95.05     | Graphics API: Vulkan\n",
      "|=============================================================================================|\n",
      "| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |\n",
      "|     |                                  |        |     |            | Device-ID | UUID       |\n",
      "|     |                                  |        |     |            | Bus-ID    |            |\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| 0   | NVIDIA GeForce RTX 5090          | Yes: 0 |     | 32853   MB | 10de      | 0          |\n",
      "|     |                                  |        |     |            | 2b85      | 4bfc8f6e.. |\n",
      "|     |                                  |        |     |            | 2         |            |\n",
      "|=============================================================================================|\n",
      "| OS: 22.04.5 LTS (Jammy Jellyfish) ubuntu, Version: 22.04.5, Kernel: 6.8.0-87-generic\n",
      "| XServer Vendor: The X.Org Foundation, XServer Version: 12101004 (1.21.1.4)\n",
      "| Processor: Intel(R) Core(TM) Ultra 9 285K\n",
      "| Cores: 24 | Logical Cores: 24\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "| Total Memory (MB): 31539 | Free Memory: 20829\n",
      "| Total Page/Swap (MB): 2047 | Free Page/Swap: 627\n",
      "|---------------------------------------------------------------------------------------------|\n",
      "2026-02-18 00:56:14 [5,449ms] [Warning] [gpu.foundation.plugin] IOMMU is enabled.\n",
      "AppLauncher initialized, importing modules...\n",
      "Enabled camera view lighting mode (/rtx/useViewLightingMode)\n",
      "[CONFIG]: Using Isaac Lab v2+ imports\n",
      "[CONFIG]: Using Isaac Lab v2+ task imports\n",
      "[CONFIG]: Using Isaac Lab v2+ task imports\n",
      "[CONFIG]: Using Isaac Lab v2+ task imports\n",
      "[CONFIG]: Using Isaac Lab v2+ task imports\n",
      "[CONFIG]: Using Isaac Lab v2+ task imports\n",
      "[CONFIG]: Using Isaac Lab v2+ task imports\n",
      "WARNING: carb.input not available. Manual control will not work.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hunter/Continuous_Force_RL/eval/wandb_eval.py\", line 159, in <module>\n",
      "    import torchvision.transforms.functional as F\n",
      "  File \"/home/hunter/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "  File \"/home/hunter/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/torchvision/_meta_registrations.py\", line 164, in <module>\n",
      "    def meta_nms(dets, scores, iou_threshold):\n",
      "  File \"/home/hunter/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/torch/library.py\", line 795, in register\n",
      "    use_lib._register_fake(op_name, func, _stacklevel=stacklevel + 1)\n",
      "  File \"/home/hunter/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/torch/library.py\", line 184, in _register_fake\n",
      "    handle = entry.fake_impl.register(func_to_register, source)\n",
      "  File \"/home/hunter/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/torch/_library/fake_impl.py\", line 31, in register\n",
      "    if torch._C._dispatch_has_kernel_for_dispatch_key(self.qualname, \"Meta\"):\n",
      "RuntimeError: operator torchvision::nms does not exist\n",
      "2026-02-18 00:56:15 [6,284ms] [Warning] [omni.fabric.plugin] gFabricState->gUsdStageToSimStageWithHistoryMap had 1 outstanding SimStageWithHistory(s) at shutdown\n",
      "2026-02-18 00:56:15 [6,357ms] [Warning] [carb] Recursive unloadAllPlugins() detected!\n",
      "\n",
      "------------------------------------------------------------\n",
      "Trajectory evaluation FAILED (Python exception detected)\n",
      "\n",
      "  WARNING: Evaluation failed for pose_breakable_f(10)_0\n",
      "  Stopping to avoid repeated failures.\n",
      "\n",
      "============================================================\n",
      "TRAJECTORY DATA SUMMARY\n",
      "============================================================\n",
      "\n",
      "Pose(1mm):\n",
      "  Path: /home/hunter/Continuous_Force_RL/eval/traj_data/pose_breakable_f10N_2026-02-04_17_49\n",
      "  Status: MISSING (no data)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 3: RUN TRAJECTORY EVALUATION (IF NEEDED)\n",
    "# ============================================================\n",
    "\n",
    "# Get absolute paths for the script and output directory\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../..\"))\n",
    "WANDB_EVAL_SCRIPT_ABS = os.path.join(PROJECT_ROOT, \"eval/wandb_eval.py\")\n",
    "TRAJ_OUTPUT_BASE_ABS = os.path.join(PROJECT_ROOT, \"eval/traj_data\")\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Eval script: {WANDB_EVAL_SCRIPT_ABS}\")\n",
    "print(f\"Output base: {TRAJ_OUTPUT_BASE_ABS}\")\n",
    "\n",
    "\n",
    "def get_traj_output_path(method_tag: str) -> str:\n",
    "    \"\"\"Get the output directory for trajectory data for a method.\"\"\"\n",
    "    # Format: {base}/{tag}/\n",
    "    safe_tag = method_tag.replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "    return os.path.join(TRAJ_OUTPUT_BASE_ABS, safe_tag)\n",
    "\n",
    "\n",
    "def check_run_data_exists(output_dir: str, run_id: str, checkpoint: int) -> bool:\n",
    "    \"\"\"Check if trajectory data exists for a specific run and checkpoint.\"\"\"\n",
    "    run_dir = os.path.join(output_dir, run_id)\n",
    "    if not os.path.exists(run_dir):\n",
    "        return False\n",
    "    \n",
    "    # Check for the specific checkpoint pkl file\n",
    "    pkl_file = f\"traj_{checkpoint}.pkl\"\n",
    "    return os.path.exists(os.path.join(run_dir, pkl_file))\n",
    "\n",
    "\n",
    "def run_trajectory_eval(\n",
    "    method_tag: str,\n",
    "    checkpoint: int,\n",
    "    output_dir: str,\n",
    "    run_id: str,\n",
    "    dry_run: bool = False\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Run wandb_eval.py with trajectory mode for a specific run and checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        method_tag: WandB tag for the method\n",
    "        checkpoint: Checkpoint step to evaluate\n",
    "        output_dir: Directory to save trajectory data\n",
    "        run_id: Specific run ID to evaluate\n",
    "        dry_run: If True, print command without executing\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        sys.executable, WANDB_EVAL_SCRIPT_ABS,\n",
    "        \"--tag\", method_tag,\n",
    "        \"--checkpoint\", str(checkpoint),\n",
    "        \"--eval_mode\", \"trajectory\",\n",
    "        \"--traj_output_dir\", output_dir,\n",
    "        \"--entity\", ENTITY,\n",
    "        \"--project\", PROJECT,\n",
    "        \"--run_id\", run_id,\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nCommand: {' '.join(cmd)}\")\n",
    "    print(f\"Working directory: {PROJECT_ROOT}\")\n",
    "    \n",
    "    if dry_run:\n",
    "        print(\"[DRY RUN] Would execute above command\")\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        # Set up environment with PYTHONPATH including project root\n",
    "        env = os.environ.copy()\n",
    "        pythonpath = env.get('PYTHONPATH', '')\n",
    "        if pythonpath:\n",
    "            env['PYTHONPATH'] = f\"{PROJECT_ROOT}:{pythonpath}\"\n",
    "        else:\n",
    "            env['PYTHONPATH'] = PROJECT_ROOT\n",
    "        \n",
    "        print(f\"PYTHONPATH: {env['PYTHONPATH']}\")\n",
    "        \n",
    "        # Use Popen to stream output in real-time\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(f\"Starting trajectory evaluation for {run_id} at checkpoint {checkpoint}...\")\n",
    "        print(\"-\"*60 + \"\\n\")\n",
    "        \n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True,\n",
    "            cwd=PROJECT_ROOT,\n",
    "            env=env,\n",
    "        )\n",
    "        \n",
    "        # Stream output line by line\n",
    "        output_lines = []\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')\n",
    "            output_lines.append(line)\n",
    "        \n",
    "        # Wait for process to complete\n",
    "        return_code = process.wait()\n",
    "        \n",
    "        # Check for Python exceptions\n",
    "        output_text = ''.join(output_lines)\n",
    "        has_python_exception = 'Traceback (most recent call last):' in output_text\n",
    "        has_module_error = 'ModuleNotFoundError:' in output_text\n",
    "        \n",
    "        # Check for success indicators\n",
    "        has_success = 'Evaluation complete!' in output_text or 'Saved trajectory data' in output_text\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        if return_code != 0:\n",
    "            print(f\"Trajectory evaluation FAILED with return code: {return_code}\")\n",
    "            return False\n",
    "        elif has_python_exception or has_module_error:\n",
    "            print(f\"Trajectory evaluation FAILED (Python exception detected)\")\n",
    "            return False\n",
    "        elif has_success:\n",
    "            print(\"Trajectory evaluation completed successfully!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Trajectory evaluation completed (no explicit success/failure detected)\")\n",
    "            return True\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"Trajectory evaluation timed out after 1 hour\")\n",
    "        process.kill()\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Exception running trajectory eval: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "\n",
    "# Configuration for this run\n",
    "DRY_RUN = False  # Set to False to actually run evaluations\n",
    "FORCE_RERUN = False  # Set to True to re-run even if data exists\n",
    "\n",
    "# Check and run trajectory evaluations for each run at its own best checkpoint\n",
    "# Process ONE RUN AT A TIME to avoid multiple Isaac Sim instances\n",
    "traj_data_paths = {}  # traj_data_paths[method] = output_dir\n",
    "\n",
    "methods_to_process = list(METHOD_TAGS.items())\n",
    "evaluation_failed = False\n",
    "\n",
    "for method_name, method_tag in methods_to_process:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {method_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    method_checkpoints = best_checkpoints.get(method_name, {})\n",
    "    if not method_checkpoints:\n",
    "        print(f\"  No checkpoints found for {method_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Output directory is per-method (not per-checkpoint)\n",
    "    output_dir = get_traj_output_path(method_tag)\n",
    "    traj_data_paths[method_name] = output_dir\n",
    "    \n",
    "    # Process each run individually at its own best checkpoint\n",
    "    for run_id, run_info in method_checkpoints.items():\n",
    "        run_name = run_info[\"run_name\"]\n",
    "        best_step = run_info[\"best_step\"]\n",
    "        score = run_info[\"score\"]\n",
    "        \n",
    "        print(f\"\\n  Run: {run_name} (id: {run_id})\")\n",
    "        print(f\"    Best checkpoint: {best_step} (score: {score})\")\n",
    "        \n",
    "        # Check if data already exists for this run\n",
    "        if check_run_data_exists(output_dir, run_id, best_step) and not FORCE_RERUN:\n",
    "            print(f\"    Data exists, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"    Running trajectory evaluation...\")\n",
    "        \n",
    "        success = run_trajectory_eval(\n",
    "            method_tag, best_step, output_dir, run_id, dry_run=DRY_RUN\n",
    "        )\n",
    "        \n",
    "        if not success and not DRY_RUN:\n",
    "            print(f\"\\n  WARNING: Evaluation failed for {run_name}\")\n",
    "            print(f\"  Stopping to avoid repeated failures.\")\n",
    "            evaluation_failed = True\n",
    "            break\n",
    "    \n",
    "    if evaluation_failed:\n",
    "        break\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAJECTORY DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for method_name, output_dir in traj_data_paths.items():\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Path: {output_dir}\")\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"  Status: MISSING (no data)\")\n",
    "        continue\n",
    "    \n",
    "    method_checkpoints = best_checkpoints.get(method_name, {})\n",
    "    total_runs = len(method_checkpoints)\n",
    "    found_runs = 0\n",
    "    \n",
    "    for run_id, run_info in method_checkpoints.items():\n",
    "        best_step = run_info[\"best_step\"]\n",
    "        exists = check_run_data_exists(output_dir, run_id, best_step)\n",
    "        status = \"OK\" if exists else \"MISSING\"\n",
    "        if exists:\n",
    "            found_runs += 1\n",
    "        print(f\"    {run_info['run_name']}: checkpoint {best_step} [{status}]\")\n",
    "    \n",
    "    print(f\"  Total: {found_runs}/{total_runs} runs have data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trajectory data...\n",
      "Warning: Output directory does not exist: /home/hunter/Continuous_Force_RL/eval/traj_data/pose_breakable_f10N_2026-02-04_17_49\n",
      "\n",
      "Total: 0 episodes, 0 break events\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 4: DATA LOADING FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def _standardize_step(step: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Ensure step dict has all expected fields with correct format.\n",
    "    Converts numpy arrays to lists, handles missing fields with defaults.\n",
    "    \"\"\"\n",
    "    field_map = {\n",
    "        'contact_force': ['contact_force', 'force', 'wrench'],\n",
    "        'contact_state': ['contact_state', 'in_contact', 'contact'],\n",
    "        'control_selection': ['control_selection', 'mode_selection', 'selection'],\n",
    "        'control_probability': ['control_probability', 'mode_prob', 'selection_prob'],\n",
    "        'velocity': ['velocity', 'ee_velocity', 'vel'],\n",
    "        'position_error': ['position_error', 'pos_error', 'pos_err'],\n",
    "        'force_error': ['force_error', 'f_error', 'force_err'],\n",
    "        'phase': ['phase'],\n",
    "        'peg_pos': ['peg_pos', 'ee_pos', 'position'],\n",
    "        'terminated': ['terminated', 'done', 'terminal'],\n",
    "        'rewards': ['rewards', 'reward'],\n",
    "    }\n",
    "    \n",
    "    def get_field(data, keys, default=None):\n",
    "        for k in keys:\n",
    "            if k in data:\n",
    "                val = data[k]\n",
    "                if hasattr(val, 'tolist'):\n",
    "                    return val.tolist()\n",
    "                return val\n",
    "        return default\n",
    "    \n",
    "    return {\n",
    "        'step': step.get('step', 0),\n",
    "        'phase': get_field(step, field_map['phase'], 'unknown'),\n",
    "        'contact_force': get_field(step, field_map['contact_force'], [0, 0, 0]),\n",
    "        'contact_state': get_field(step, field_map['contact_state'], False),\n",
    "        'control_selection': get_field(step, field_map['control_selection'], [0, 0, 0]),\n",
    "        'control_probability': get_field(step, field_map['control_probability'], [0.5, 0.5, 0.5]),\n",
    "        'velocity': get_field(step, field_map['velocity'], [0, 0, 0]),\n",
    "        'position_error': get_field(step, field_map['position_error'], [0, 0, 0]),\n",
    "        'force_error': get_field(step, field_map['force_error'], [0, 0, 0]),\n",
    "        'peg_pos': get_field(step, field_map['peg_pos'], None),\n",
    "        'terminated': get_field(step, field_map['terminated'], False),\n",
    "        'rewards': get_field(step, field_map['rewards'], {}),\n",
    "    }\n",
    "\n",
    "\n",
    "def _parse_episode(raw_ep: Dict, policy: str, episode_id: str, run_id: str) -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"Parse a single episode into standardized format.\"\"\"\n",
    "    steps = raw_ep.get('policy_steps', raw_ep.get('steps', raw_ep.get('trajectory', [])))\n",
    "    \n",
    "    hole_pos = raw_ep.get('hole_pos', None)\n",
    "    initial_peg_pos = raw_ep.get('initial_peg_pos', None)\n",
    "    \n",
    "    if hole_pos is not None and hasattr(hole_pos, 'tolist'):\n",
    "        hole_pos = hole_pos.tolist()\n",
    "    if initial_peg_pos is not None and hasattr(initial_peg_pos, 'tolist'):\n",
    "        initial_peg_pos = initial_peg_pos.tolist()\n",
    "    \n",
    "    standardized_steps = []\n",
    "    for s in steps:\n",
    "        std_step = _standardize_step(s)\n",
    "        \n",
    "        # Compute insertion_depth and lateral_error if we have hole_pos and peg_pos\n",
    "        if hole_pos is not None and std_step.get('peg_pos') is not None:\n",
    "            peg_pos = std_step['peg_pos']\n",
    "            std_step['insertion_depth'] = hole_pos[2] - peg_pos[2]\n",
    "            # Lateral error = XY distance from peg to hole center\n",
    "            std_step['lateral_error'] = ((peg_pos[0] - hole_pos[0])**2 + (peg_pos[1] - hole_pos[1])**2)**0.5\n",
    "        \n",
    "        standardized_steps.append(std_step)\n",
    "    \n",
    "    break_sim_steps = raw_ep.get('break_sim_steps', None)\n",
    "    \n",
    "    # Infer outcome\n",
    "    outcome = raw_ep.get('outcome', None)\n",
    "    if outcome is None:\n",
    "        outcome = 'success' if any(s.get('terminated', False) for s in steps) else 'timeout'\n",
    "    \n",
    "    parsed_episode = {\n",
    "        'policy': policy,\n",
    "        'episode_id': episode_id,\n",
    "        'run_id': run_id,\n",
    "        'outcome': outcome,\n",
    "        'steps': standardized_steps,\n",
    "        'hole_pos': hole_pos,\n",
    "        'initial_peg_pos': initial_peg_pos,\n",
    "    }\n",
    "    \n",
    "    break_event = None\n",
    "    if outcome == 'break' and break_sim_steps is not None:\n",
    "        break_event = {\n",
    "            'policy': policy,\n",
    "            'episode_id': episode_id,\n",
    "            'run_id': run_id,\n",
    "            'sim_steps': [_standardize_step(s) for s in break_sim_steps]\n",
    "        }\n",
    "    \n",
    "    return parsed_episode, break_event\n",
    "\n",
    "\n",
    "def load_trajectory_data_for_method(\n",
    "    output_dir: str,\n",
    "    policy_name: str,\n",
    "    method_checkpoints: Dict[str, Dict],\n",
    "    verbose: bool = True\n",
    ") -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Load trajectory data from .pkl files for a method.\n",
    "    \n",
    "    Each run has its own best checkpoint, so we load the specific pkl file\n",
    "    for each run based on its checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory containing run subdirectories with .pkl files\n",
    "        policy_name: Name to assign to this policy\n",
    "        method_checkpoints: Dict mapping run_id -> {run_name, best_step, score}\n",
    "        verbose: Print loading progress\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (episode_data, break_events)\n",
    "    \"\"\"\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        if verbose:\n",
    "            print(f\"Warning: Output directory does not exist: {output_dir}\")\n",
    "        return [], []\n",
    "    \n",
    "    episode_data = []\n",
    "    break_events = []\n",
    "    load_stats = {'runs': 0, 'episodes': 0, 'breaks': 0}\n",
    "    \n",
    "    for run_id, run_info in method_checkpoints.items():\n",
    "        best_step = run_info[\"best_step\"]\n",
    "        run_dir = os.path.join(output_dir, run_id)\n",
    "        pkl_file = f\"traj_{best_step}.pkl\"\n",
    "        pkl_path = os.path.join(run_dir, pkl_file)\n",
    "        \n",
    "        if not os.path.exists(pkl_path):\n",
    "            if verbose:\n",
    "                print(f\"  Warning: Missing {pkl_file} for run {run_id}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                raw_data = pickle.load(f)\n",
    "            \n",
    "            # Parse the trajectory data\n",
    "            if isinstance(raw_data, dict) and 'trajectories' in raw_data:\n",
    "                trajectories = raw_data['trajectories']\n",
    "                for env_key, env_data in trajectories.items():\n",
    "                    env_idx = int(env_key.replace('env_', ''))\n",
    "                    episode_id = f\"{run_id}_env_{env_idx}\"\n",
    "                    parsed_ep, break_event = _parse_episode(env_data, policy_name, episode_id, run_id)\n",
    "                    episode_data.append(parsed_ep)\n",
    "                    load_stats['episodes'] += 1\n",
    "                    if break_event is not None:\n",
    "                        break_events.append(break_event)\n",
    "                        load_stats['breaks'] += 1\n",
    "            \n",
    "            load_stats['runs'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Error loading {pkl_path}: {e}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Loaded {policy_name}: {load_stats['runs']} runs, {load_stats['episodes']} episodes, {load_stats['breaks']} breaks\")\n",
    "    \n",
    "    return episode_data, break_events\n",
    "\n",
    "\n",
    "# Load all trajectory data\n",
    "all_episode_data = []\n",
    "all_break_events = []\n",
    "\n",
    "print(\"Loading trajectory data...\")\n",
    "for method_name, output_dir in traj_data_paths.items():\n",
    "    method_checkpoints = best_checkpoints.get(method_name, {})\n",
    "    episodes, breaks = load_trajectory_data_for_method(\n",
    "        output_dir, method_name, method_checkpoints\n",
    "    )\n",
    "    all_episode_data.extend(episodes)\n",
    "    all_break_events.extend(breaks)\n",
    "\n",
    "print(f\"\\nTotal: {len(all_episode_data)} episodes, {len(all_break_events)} break events\")\n",
    "\n",
    "# Print outcome breakdown\n",
    "if all_episode_data:\n",
    "    outcome_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for ep in all_episode_data:\n",
    "        outcome_counts[ep['policy']][ep['outcome']] += 1\n",
    "    \n",
    "    print(\"\\nOutcome breakdown:\")\n",
    "    for policy in sorted(outcome_counts.keys()):\n",
    "        counts = outcome_counts[policy]\n",
    "        print(f\"  {policy}: success={counts['success']}, break={counts['break']}, timeout={counts['timeout']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded. Please run trajectory evaluation first.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 5: MULTI-PANEL TRAJECTORY PLOT (Phase-Based Normalization)\n",
    "# ============================================================\n",
    "#\n",
    "# Generates a 2x2 multi-panel figure with phase-based normalization:\n",
    "# - Each phase is normalized separately across all trajectories\n",
    "# - Phase proportions are computed from average phase lengths in the data\n",
    "# - Phase labels drawn directly on each phase region\n",
    "# - Each subplot has its own legend for methods\n",
    "\n",
    "import importlib\n",
    "import analysis_utils\n",
    "importlib.reload(analysis_utils)\n",
    "from analysis_utils import (\n",
    "    # Font sizes\n",
    "    FONT_SUPTITLE, FONT_TITLE, FONT_AXIS_LABEL, FONT_TICK, FONT_LEGEND,\n",
    "    # Plot styling\n",
    "    DEFAULT_DPI, TIGHT_PAD, TIGHT_W_PAD, TIGHT_H_PAD,\n",
    "    AXIS_LABEL_PAD_X, AXIS_LABEL_PAD_Y, TICK_PAD_X, TICK_PAD_Y,\n",
    "    LEGEND_HANDLE_LENGTH,\n",
    "    # Trajectory styling\n",
    "    TRAJ_PHASE_COLORS, TRAJ_PHASE_DISPLAY, TRAJ_PHASE_ALPHA,\n",
    "    SELECTION_PROB_COLORS,\n",
    "    TRAJ_PHASE_BOUNDARY_LINES, TRAJ_PHASE_BOUNDARY_COLOR,\n",
    "    TRAJ_PHASE_BOUNDARY_LINESTYLE, TRAJ_PHASE_BOUNDARY_LINEWIDTH,\n",
    "    TRAJ_PHASE_LABEL_FONTSIZE, TRAJ_PHASE_LABEL_ALPHA, TRAJ_PHASE_LABEL_Y_POS,\n",
    ")\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE = (12, 8)\n",
    "N_POINTS_TOTAL = 100  # Total points across all phases\n",
    "ALPHA_FILL = 0.3  # Alpha for std fill\n",
    "\n",
    "# Phase configuration - order of phases\n",
    "PHASE_ORDER = ['approaching', 'initial_contact', 'insertion']\n",
    "\n",
    "# Method line styles\n",
    "METHOD_STYLES = {\n",
    "    \"Pose(1mm)\": {\"linestyle\": \"--\", \"linewidth\": 2},\n",
    "    \"Hybrid-Basic\": {\"linestyle\": \"-.\", \"linewidth\": 2},\n",
    "    \"MATCH(1mm)\": {\"linestyle\": \"-\", \"linewidth\": 2},\n",
    "    \"LCLoP\": {\"linestyle\": \"-\", \"linewidth\": 2},\n",
    "}\n",
    "\n",
    "# Variables to plot - with subplot titles\n",
    "# 'negate': True to flip sign (for Z position and contact force)\n",
    "# 'type': 'standard' for normal plot, 'selection_prob' for special selection probability plot\n",
    "# 'policies': list of policies to include, or None for all\n",
    "# 'ylim': optional y-axis limits\n",
    "VARIABLES = [\n",
    "    {'key': 'insertion_depth', 'label': 'Z Position (mm)', 'title': 'End-Effector Z Trajectory', \n",
    "     'axis': None, 'scale': 1000, 'negate': True, 'type': 'standard'},\n",
    "    {'key': 'lateral_error', 'label': 'XY Error (mm)', 'title': 'Lateral Alignment Error', \n",
    "     'axis': None, 'scale': 1000, 'type': 'standard'},\n",
    "    {'key': 'control_probability', 'label': 'P(Force Control)', 'title': 'MATCH Force Control Selection Probability', \n",
    "     'type': 'selection_prob', 'policies': ['MATCH(1mm)'], 'ylim': (0, 1)},\n",
    "    {'key': 'contact_force', 'label': 'Contact Force (N)', 'title': 'Contact Force Magnitude', \n",
    "     'axis': 2, 'scale': 1, 'negate': True, 'type': 'standard'},\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def extract_variable(step: Dict, var_config: Dict) -> Optional[float]:\n",
    "    \"\"\"Extract a single value from a step based on variable config.\"\"\"\n",
    "    key = var_config['key']\n",
    "    axis = var_config.get('axis')\n",
    "    scale = var_config.get('scale', 1)\n",
    "    negate = var_config.get('negate', False)\n",
    "    \n",
    "    val = step.get(key)\n",
    "    if val is None:\n",
    "        return None\n",
    "    \n",
    "    result = None\n",
    "    if axis == 'xy':\n",
    "        if isinstance(val, (list, np.ndarray)) and len(val) >= 2:\n",
    "            result = np.sqrt(val[0]**2 + val[1]**2) * scale\n",
    "    elif axis is not None:\n",
    "        if isinstance(val, (list, np.ndarray)) and len(val) > axis:\n",
    "            result = val[axis] * scale\n",
    "    else:\n",
    "        if isinstance(val, (list, np.ndarray)):\n",
    "            result = val[0] * scale if len(val) > 0 else None\n",
    "        else:\n",
    "            result = val * scale\n",
    "    \n",
    "    if result is not None and negate:\n",
    "        result = -result\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_selection_prob_z(step: Dict) -> Optional[float]:\n",
    "    \"\"\"Extract Z-axis selection probability.\"\"\"\n",
    "    val = step.get('control_probability')\n",
    "    if val is None:\n",
    "        return None\n",
    "    if isinstance(val, (list, np.ndarray)) and len(val) > 2:\n",
    "        return val[2]  # Z-axis\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_selection_prob_xy(step: Dict) -> Optional[float]:\n",
    "    \"\"\"Extract average XY selection probability.\"\"\"\n",
    "    val = step.get('control_probability')\n",
    "    if val is None:\n",
    "        return None\n",
    "    if isinstance(val, (list, np.ndarray)) and len(val) >= 2:\n",
    "        return (val[0] + val[1]) / 2  # Average of X and Y\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_phase_proportions(episode_data: List[Dict]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute phase proportions based on average phase lengths across all episodes.\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping phase name to proportion (sums to 1.0).\n",
    "    \"\"\"\n",
    "    phase_lengths = defaultdict(list)\n",
    "    \n",
    "    for episode in episode_data:\n",
    "        # Count steps per phase in this episode\n",
    "        phase_counts = defaultdict(int)\n",
    "        for step in episode['steps']:\n",
    "            phase = step.get('phase', 'unknown')\n",
    "            if phase in TRAJ_PHASE_COLORS:\n",
    "                phase_counts[phase] += 1\n",
    "        \n",
    "        # Record lengths for phases that exist in this episode\n",
    "        for phase in PHASE_ORDER:\n",
    "            if phase in phase_counts:\n",
    "                phase_lengths[phase].append(phase_counts[phase])\n",
    "    \n",
    "    # Compute average length for each phase\n",
    "    avg_lengths = {}\n",
    "    for phase in PHASE_ORDER:\n",
    "        if phase in phase_lengths and len(phase_lengths[phase]) > 0:\n",
    "            avg_lengths[phase] = np.mean(phase_lengths[phase])\n",
    "        else:\n",
    "            avg_lengths[phase] = 0\n",
    "    \n",
    "    # Convert to proportions\n",
    "    total_length = sum(avg_lengths.values())\n",
    "    if total_length == 0:\n",
    "        # Fallback to equal proportions\n",
    "        n_phases = len(PHASE_ORDER)\n",
    "        return {phase: 1.0 / n_phases for phase in PHASE_ORDER}\n",
    "    \n",
    "    proportions = {phase: length / total_length for phase, length in avg_lengths.items()}\n",
    "    \n",
    "    # Print computed proportions\n",
    "    print(\"Computed phase proportions from data:\")\n",
    "    for phase in PHASE_ORDER:\n",
    "        print(f\"  {phase}: {proportions[phase]:.1%} (avg {avg_lengths[phase]:.1f} steps)\")\n",
    "    \n",
    "    return proportions\n",
    "\n",
    "\n",
    "def segment_episode_by_phase(episode: Dict) -> Dict[str, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Segment an episode's steps by phase.\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping phase name to list of steps in that phase.\n",
    "    \"\"\"\n",
    "    segments = defaultdict(list)\n",
    "    \n",
    "    for step in episode['steps']:\n",
    "        phase = step.get('phase', 'unknown')\n",
    "        if phase in TRAJ_PHASE_COLORS:\n",
    "            segments[phase].append(step)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "def normalize_phase_segments(\n",
    "    episodes_by_policy: Dict[str, List[Dict]],\n",
    "    var_config: Dict,\n",
    "    phase_proportions: Dict[str, float],\n",
    "    n_points_total: int = 100\n",
    ") -> Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Normalize trajectories by phase and compute mean/std for each policy.\n",
    "    \n",
    "    Each phase is normalized to its allocated proportion of the total points.\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping policy name to (t, mean, std) arrays for the full normalized trajectory.\n",
    "    \"\"\"\n",
    "    # Calculate points per phase based on proportions\n",
    "    points_per_phase = {}\n",
    "    for phase in PHASE_ORDER:\n",
    "        points_per_phase[phase] = max(1, int(n_points_total * phase_proportions.get(phase, 0)))\n",
    "    \n",
    "    # Adjust to ensure total is exactly n_points_total\n",
    "    total_points = sum(points_per_phase.values())\n",
    "    diff = n_points_total - total_points\n",
    "    if diff != 0:\n",
    "        # Add/subtract from the largest phase\n",
    "        largest_phase = max(points_per_phase, key=points_per_phase.get)\n",
    "        points_per_phase[largest_phase] += diff\n",
    "    \n",
    "    # Build time axis\n",
    "    t_full = np.linspace(0, 1, n_points_total)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for policy, episodes in episodes_by_policy.items():\n",
    "        all_trajectories = []\n",
    "        \n",
    "        for episode in episodes:\n",
    "            segments = segment_episode_by_phase(episode)\n",
    "            \n",
    "            # Build normalized trajectory for this episode\n",
    "            trajectory_parts = []\n",
    "            \n",
    "            for phase in PHASE_ORDER:\n",
    "                n_points = points_per_phase.get(phase, 0)\n",
    "                if n_points == 0:\n",
    "                    continue\n",
    "                \n",
    "                if phase in segments and len(segments[phase]) > 0:\n",
    "                    # Extract values for this phase\n",
    "                    values = []\n",
    "                    for step in segments[phase]:\n",
    "                        val = extract_variable(step, var_config)\n",
    "                        values.append(val if val is not None else np.nan)\n",
    "                    \n",
    "                    if len(values) > 1:\n",
    "                        # Interpolate to allocated points\n",
    "                        t_orig = np.linspace(0, 1, len(values))\n",
    "                        t_target = np.linspace(0, 1, n_points)\n",
    "                        interpolated = np.interp(t_target, t_orig, values)\n",
    "                        trajectory_parts.append(interpolated)\n",
    "                    elif len(values) == 1:\n",
    "                        # Single point - repeat\n",
    "                        trajectory_parts.append(np.full(n_points, values[0]))\n",
    "                    else:\n",
    "                        trajectory_parts.append(np.full(n_points, np.nan))\n",
    "                else:\n",
    "                    # Phase not present - fill with NaN\n",
    "                    trajectory_parts.append(np.full(n_points, np.nan))\n",
    "            \n",
    "            if trajectory_parts:\n",
    "                full_trajectory = np.concatenate(trajectory_parts)\n",
    "                if len(full_trajectory) == n_points_total:\n",
    "                    all_trajectories.append(full_trajectory)\n",
    "        \n",
    "        if all_trajectories:\n",
    "            trajectories = np.array(all_trajectories)\n",
    "            n = len(all_trajectories)\n",
    "            with np.errstate(all='ignore'):\n",
    "                mean = np.nanmean(trajectories, axis=0)\n",
    "                std = np.nanstd(trajectories, axis=0)\n",
    "            results[policy] = (t_full, mean, std, n)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def normalize_selection_prob_segments(\n",
    "    episodes_by_policy: Dict[str, List[Dict]],\n",
    "    extract_func,\n",
    "    phase_proportions: Dict[str, float],\n",
    "    n_points_total: int = 100\n",
    ") -> Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Normalize selection probability trajectories by phase.\n",
    "    \n",
    "    Similar to normalize_phase_segments but uses a custom extraction function.\n",
    "    \"\"\"\n",
    "    # Calculate points per phase based on proportions\n",
    "    points_per_phase = {}\n",
    "    for phase in PHASE_ORDER:\n",
    "        points_per_phase[phase] = max(1, int(n_points_total * phase_proportions.get(phase, 0)))\n",
    "    \n",
    "    # Adjust to ensure total is exactly n_points_total\n",
    "    total_points = sum(points_per_phase.values())\n",
    "    diff = n_points_total - total_points\n",
    "    if diff != 0:\n",
    "        largest_phase = max(points_per_phase, key=points_per_phase.get)\n",
    "        points_per_phase[largest_phase] += diff\n",
    "    \n",
    "    # Build time axis\n",
    "    t_full = np.linspace(0, 1, n_points_total)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for policy, episodes in episodes_by_policy.items():\n",
    "        all_trajectories = []\n",
    "        \n",
    "        for episode in episodes:\n",
    "            segments = segment_episode_by_phase(episode)\n",
    "            trajectory_parts = []\n",
    "            \n",
    "            for phase in PHASE_ORDER:\n",
    "                n_points = points_per_phase.get(phase, 0)\n",
    "                if n_points == 0:\n",
    "                    continue\n",
    "                \n",
    "                if phase in segments and len(segments[phase]) > 0:\n",
    "                    values = []\n",
    "                    for step in segments[phase]:\n",
    "                        val = extract_func(step)\n",
    "                        values.append(val if val is not None else np.nan)\n",
    "                    \n",
    "                    if len(values) > 1:\n",
    "                        t_orig = np.linspace(0, 1, len(values))\n",
    "                        t_target = np.linspace(0, 1, n_points)\n",
    "                        interpolated = np.interp(t_target, t_orig, values)\n",
    "                        trajectory_parts.append(interpolated)\n",
    "                    elif len(values) == 1:\n",
    "                        trajectory_parts.append(np.full(n_points, values[0]))\n",
    "                    else:\n",
    "                        trajectory_parts.append(np.full(n_points, np.nan))\n",
    "                else:\n",
    "                    trajectory_parts.append(np.full(n_points, np.nan))\n",
    "            \n",
    "            if trajectory_parts:\n",
    "                full_trajectory = np.concatenate(trajectory_parts)\n",
    "                if len(full_trajectory) == n_points_total:\n",
    "                    all_trajectories.append(full_trajectory)\n",
    "        \n",
    "        if all_trajectories:\n",
    "            trajectories = np.array(all_trajectories)\n",
    "            n = len(all_trajectories)\n",
    "            with np.errstate(all='ignore'):\n",
    "                mean = np.nanmean(trajectories, axis=0)\n",
    "                std = np.nanstd(trajectories, axis=0)\n",
    "            results[policy] = (t_full, mean, std, n)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def get_phase_boundaries(phase_proportions: Dict[str, float]) -> List[Tuple[float, float, str]]:\n",
    "    \"\"\"\n",
    "    Get phase boundaries as (start, end, phase_name) tuples in normalized coordinates.\n",
    "    \"\"\"\n",
    "    boundaries = []\n",
    "    cumulative = 0.0\n",
    "    \n",
    "    for phase in PHASE_ORDER:\n",
    "        proportion = phase_proportions.get(phase, 0)\n",
    "        if proportion > 0:\n",
    "            start = cumulative\n",
    "            end = cumulative + proportion\n",
    "            boundaries.append((start, end, phase))\n",
    "            cumulative = end\n",
    "    \n",
    "    return boundaries\n",
    "\n",
    "\n",
    "def draw_phase_decorations(ax, phase_boundaries, draw_boundary_lines=TRAJ_PHASE_BOUNDARY_LINES):\n",
    "    \"\"\"\n",
    "    Draw phase background shading, labels, and optional boundary lines on an axes.\n",
    "    \"\"\"\n",
    "    for start, end, phase in phase_boundaries:\n",
    "        color = TRAJ_PHASE_COLORS.get(phase, '#cccccc')\n",
    "        display = TRAJ_PHASE_DISPLAY.get(phase, phase)\n",
    "\n",
    "        # Background shading\n",
    "        ax.axvspan(start, end, alpha=TRAJ_PHASE_ALPHA, color=color, zorder=0)\n",
    "\n",
    "        # Phase label centered in region\n",
    "        center_x = (start + end) / 2\n",
    "        ax.text(\n",
    "            center_x, TRAJ_PHASE_LABEL_Y_POS, display,\n",
    "            transform=ax.get_xaxis_transform(),\n",
    "            ha='center', va='top',\n",
    "            fontsize=TRAJ_PHASE_LABEL_FONTSIZE,\n",
    "            alpha=TRAJ_PHASE_LABEL_ALPHA,\n",
    "            fontstyle='italic',\n",
    "        )\n",
    "\n",
    "    # Vertical boundary lines between phases\n",
    "    if draw_boundary_lines:\n",
    "        for i, (start, end, phase) in enumerate(phase_boundaries):\n",
    "            if i > 0:  # Skip first boundary (left edge of plot)\n",
    "                ax.axvline(\n",
    "                    x=start,\n",
    "                    color=TRAJ_PHASE_BOUNDARY_COLOR,\n",
    "                    linestyle=TRAJ_PHASE_BOUNDARY_LINESTYLE,\n",
    "                    linewidth=TRAJ_PHASE_BOUNDARY_LINEWIDTH,\n",
    "                    zorder=2,\n",
    "                )\n",
    "\n",
    "\n",
    "def plot_trajectory_multipanel(\n",
    "    episode_data: List[Dict],\n",
    "    variables: List[Dict],\n",
    "    n_points: int = 100,\n",
    "    figsize: Tuple[float, float] = (12, 8),\n",
    "    draw_boundary_lines: bool = TRAJ_PHASE_BOUNDARY_LINES,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create 2x2 multi-panel trajectory plot with phase-based normalization.\n",
    "    \"\"\"\n",
    "    n_vars = len(variables)\n",
    "    n_rows = 2\n",
    "    n_cols = 2\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, dpi=DEFAULT_DPI)\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    # Compute phase proportions from data\n",
    "    phase_proportions = compute_phase_proportions(episode_data)\n",
    "    \n",
    "    # Group episodes by policy\n",
    "    episodes_by_policy = defaultdict(list)\n",
    "    for ep in episode_data:\n",
    "        episodes_by_policy[ep['policy']].append(ep)\n",
    "    \n",
    "    # Get phase boundaries\n",
    "    phase_boundaries = get_phase_boundaries(phase_proportions)\n",
    "    \n",
    "    for ax_idx, var_config in enumerate(variables):\n",
    "        if ax_idx >= len(axes_flat):\n",
    "            break\n",
    "        ax = axes_flat[ax_idx]\n",
    "        \n",
    "        # Draw phase backgrounds, labels, and boundary lines\n",
    "        draw_phase_decorations(ax, phase_boundaries, draw_boundary_lines)\n",
    "        \n",
    "        plot_type = var_config.get('type', 'standard')\n",
    "        allowed_policies = var_config.get('policies', None)\n",
    "        \n",
    "        if plot_type == 'selection_prob':\n",
    "            filtered_episodes = {p: eps for p, eps in episodes_by_policy.items() \n",
    "                               if allowed_policies is None or p in allowed_policies}\n",
    "            \n",
    "            z_data = normalize_selection_prob_segments(filtered_episodes, extract_selection_prob_z, \n",
    "                                                        phase_proportions, n_points)\n",
    "            for policy, (t, mean, std, n) in z_data.items():\n",
    "                ci = 1.96 * std / np.sqrt(n)\n",
    "                ax.plot(t, mean, color=SELECTION_PROB_COLORS['z'], linestyle='-', \n",
    "                       linewidth=2, label='Z-axis')\n",
    "                ax.fill_between(t, mean - ci, mean + ci, color=SELECTION_PROB_COLORS['z'], \n",
    "                               alpha=ALPHA_FILL)\n",
    "            \n",
    "            xy_data = normalize_selection_prob_segments(filtered_episodes, extract_selection_prob_xy,\n",
    "                                                         phase_proportions, n_points)\n",
    "            for policy, (t, mean, std, n) in xy_data.items():\n",
    "                ci = 1.96 * std / np.sqrt(n)\n",
    "                ax.plot(t, mean, color=SELECTION_PROB_COLORS['xy'], linestyle='--', \n",
    "                       linewidth=2, label='XY-axes')\n",
    "                ax.fill_between(t, mean - ci, mean + ci, color=SELECTION_PROB_COLORS['xy'], \n",
    "                               alpha=ALPHA_FILL)\n",
    "        else:\n",
    "            policy_data = normalize_phase_segments(episodes_by_policy, var_config, \n",
    "                                                   phase_proportions, n_points)\n",
    "            \n",
    "            if allowed_policies is not None:\n",
    "                policy_data = {p: data for p, data in policy_data.items() if p in allowed_policies}\n",
    "            \n",
    "            for policy, (t, mean, std, n) in policy_data.items():\n",
    "                ci = 1.96 * std / np.sqrt(n)\n",
    "                color = METHOD_COLORS.get(policy, 'gray')\n",
    "                style = METHOD_STYLES.get(policy, {\"linestyle\": \"-\", \"linewidth\": 2})\n",
    "                \n",
    "                ax.plot(t, mean, color=color, label=policy, **style)\n",
    "                ax.fill_between(t, mean - ci, mean + ci, color=color, alpha=ALPHA_FILL)\n",
    "        \n",
    "        # Configure subplot\n",
    "        ax.set_title(var_config.get('title', var_config['label']), fontsize=FONT_TITLE)\n",
    "        ax.set_ylabel(var_config['label'], fontsize=FONT_AXIS_LABEL, labelpad=AXIS_LABEL_PAD_Y)\n",
    "        ax.tick_params(axis='x', labelsize=FONT_TICK, pad=TICK_PAD_X)\n",
    "        ax.tick_params(axis='y', labelsize=FONT_TICK, pad=TICK_PAD_Y)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xlim(0, 1)\n",
    "        \n",
    "        if 'ylim' in var_config:\n",
    "            ax.set_ylim(var_config['ylim'])\n",
    "        \n",
    "        # X-axis label on bottom row only\n",
    "        row = ax_idx // n_cols\n",
    "        if row == n_rows - 1:\n",
    "            ax.set_xlabel('Normalized Time', fontsize=FONT_AXIS_LABEL, labelpad=AXIS_LABEL_PAD_X)\n",
    "        \n",
    "        # Per-subplot legend for methods\n",
    "        ax.legend(fontsize=FONT_LEGEND, loc='best', handlelength=LEGEND_HANDLE_LENGTH)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_vars, len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout(pad=TIGHT_PAD, w_pad=TIGHT_W_PAD, h_pad=TIGHT_H_PAD)\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_trajectory_multipanel(\n",
    "        all_episode_data,\n",
    "        VARIABLES,\n",
    "        n_points=N_POINTS_TOTAL,\n",
    "        figsize=FIGSIZE\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded. Please run trajectory evaluation first.\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_trajectory_single(\n",
    "    episode_data: List[Dict],\n",
    "    var_config: Dict,\n",
    "    phase_proportions: Dict[str, float],\n",
    "    n_points: int = 100,\n",
    "    figsize: Tuple[float, float] = (8, 5),\n",
    "    draw_boundary_lines: bool = TRAJ_PHASE_BOUNDARY_LINES,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a single trajectory plot for one variable with phase-based normalization.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=DEFAULT_DPI)\n",
    "    \n",
    "    # Group episodes by policy\n",
    "    episodes_by_policy = defaultdict(list)\n",
    "    for ep in episode_data:\n",
    "        episodes_by_policy[ep['policy']].append(ep)\n",
    "    \n",
    "    # Get phase boundaries\n",
    "    phase_boundaries = get_phase_boundaries(phase_proportions)\n",
    "    \n",
    "    # Draw phase backgrounds, labels, and boundary lines\n",
    "    draw_phase_decorations(ax, phase_boundaries, draw_boundary_lines)\n",
    "    \n",
    "    plot_type = var_config.get('type', 'standard')\n",
    "    allowed_policies = var_config.get('policies', None)\n",
    "    \n",
    "    if plot_type == 'selection_prob':\n",
    "        filtered_episodes = {p: eps for p, eps in episodes_by_policy.items() \n",
    "                           if allowed_policies is None or p in allowed_policies}\n",
    "        \n",
    "        z_data = normalize_selection_prob_segments(filtered_episodes, extract_selection_prob_z, \n",
    "                                                    phase_proportions, n_points)\n",
    "        for policy, (t, mean, std, n) in z_data.items():\n",
    "            ci = 1.96 * std / np.sqrt(n)\n",
    "            ax.plot(t, mean, color=SELECTION_PROB_COLORS['z'], linestyle='-', \n",
    "                   linewidth=2, label='Z-axis')\n",
    "            ax.fill_between(t, mean - ci, mean + ci, color=SELECTION_PROB_COLORS['z'], \n",
    "                           alpha=ALPHA_FILL)\n",
    "        \n",
    "        xy_data = normalize_selection_prob_segments(filtered_episodes, extract_selection_prob_xy,\n",
    "                                                     phase_proportions, n_points)\n",
    "        for policy, (t, mean, std, n) in xy_data.items():\n",
    "            ci = 1.96 * std / np.sqrt(n)\n",
    "            ax.plot(t, mean, color=SELECTION_PROB_COLORS['xy'], linestyle='--', \n",
    "                   linewidth=2, label='XY-axes')\n",
    "            ax.fill_between(t, mean - ci, mean + ci, color=SELECTION_PROB_COLORS['xy'], \n",
    "                           alpha=ALPHA_FILL)\n",
    "    else:\n",
    "        policy_data = normalize_phase_segments(episodes_by_policy, var_config, \n",
    "                                               phase_proportions, n_points)\n",
    "        \n",
    "        if allowed_policies is not None:\n",
    "            policy_data = {p: data for p, data in policy_data.items() if p in allowed_policies}\n",
    "        \n",
    "        for policy, (t, mean, std, n) in policy_data.items():\n",
    "            ci = 1.96 * std / np.sqrt(n)\n",
    "            color = METHOD_COLORS.get(policy, 'gray')\n",
    "            style = METHOD_STYLES.get(policy, {\"linestyle\": \"-\", \"linewidth\": 2})\n",
    "            \n",
    "            ax.plot(t, mean, color=color, label=policy, **style)\n",
    "            ax.fill_between(t, mean - ci, mean + ci, color=color, alpha=ALPHA_FILL)\n",
    "    \n",
    "    # Configure plot\n",
    "    ax.set_title(var_config.get('title', var_config['label']), fontsize=FONT_TITLE)\n",
    "    ax.set_ylabel(var_config['label'], fontsize=FONT_AXIS_LABEL, labelpad=AXIS_LABEL_PAD_Y)\n",
    "    ax.set_xlabel('Normalized Time', fontsize=FONT_AXIS_LABEL, labelpad=AXIS_LABEL_PAD_X)\n",
    "    ax.tick_params(axis='x', labelsize=FONT_TICK, pad=TICK_PAD_X)\n",
    "    ax.tick_params(axis='y', labelsize=FONT_TICK, pad=TICK_PAD_Y)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(0, 1)\n",
    "    \n",
    "    if 'ylim' in var_config:\n",
    "        ax.set_ylim(var_config['ylim'])\n",
    "    \n",
    "    # Methods legend (no phase legend - phases are labeled directly)\n",
    "    ax.legend(fontsize=FONT_LEGEND, loc='best', handlelength=LEGEND_HANDLE_LENGTH)\n",
    "    \n",
    "    plt.tight_layout(pad=TIGHT_PAD, w_pad=TIGHT_W_PAD, h_pad=TIGHT_H_PAD)\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Generate individual plots for each variable\n",
    "if all_episode_data:\n",
    "    # Compute phase proportions once for all plots\n",
    "    phase_proportions_single = compute_phase_proportions(all_episode_data)\n",
    "    \n",
    "    for var_config in VARIABLES:\n",
    "        fig = plot_trajectory_single(\n",
    "            all_episode_data,\n",
    "            var_config,\n",
    "            phase_proportions_single,\n",
    "            n_points=N_POINTS_TOTAL,\n",
    "            figsize=(8, 5)\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 6: BREAKS BY PHASE\n",
    "# ============================================================\n",
    "#\n",
    "# Bar chart showing the number of break events that occurred\n",
    "# during each phase, grouped by policy.\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_BREAKS = (10, 6)\n",
    "BAR_WIDTH = 0.25\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_break_count_by_phase(\n",
    "    episode_data: List[Dict],\n",
    "    figsize: Tuple[float, float] = (10, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Bar chart of break counts by phase, grouped by policy.\n",
    "    \"\"\"\n",
    "    # Extract phase at termination for break episodes\n",
    "    break_phases = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] == 'break':\n",
    "            policy = ep['policy']\n",
    "            # Find the last step (where break occurred)\n",
    "            if ep['steps']:\n",
    "                last_step = ep['steps'][-1]\n",
    "                phase = last_step.get('phase', 'unknown')\n",
    "                break_phases[policy][phase] += 1\n",
    "    \n",
    "    if not break_phases:\n",
    "        print(\"No break events found in data.\")\n",
    "        return None\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=DPI)\n",
    "    \n",
    "    policies = sorted(break_phases.keys())\n",
    "    x = np.arange(len(PHASES))\n",
    "    width = BAR_WIDTH\n",
    "    \n",
    "    for i, policy in enumerate(policies):\n",
    "        counts = [break_phases[policy][phase] for phase in PHASES]\n",
    "        offset = (i - len(policies)/2 + 0.5) * width\n",
    "        color = METHOD_COLORS.get(policy, 'gray')\n",
    "        ax.bar(x + offset, counts, width, label=policy, color=color)\n",
    "    \n",
    "    ax.set_xlabel('Phase', fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_ylabel('Break Count', fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_title('Break Events by Phase', fontsize=FONT_TITLE)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([p.replace('_', ' ').title() for p in PHASES], fontsize=FONT_TICK)\n",
    "    ax.legend(fontsize=FONT_LEGEND)\n",
    "    ax.tick_params(labelsize=FONT_TICK)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_break_count_by_phase(all_episode_data, figsize=FIGSIZE_BREAKS)\n",
    "    if fig:\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 7: SELECTION CONFIDENCE COMPARISON\n",
    "# ============================================================\n",
    "#\n",
    "# Compares selection confidence (max probability across modes)\n",
    "# at the moment of initial contact, separated by outcome.\n",
    "# Higher confidence may correlate with better outcomes.\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_CONFIDENCE = (10, 6)\n",
    "CONFIDENCE_AXIS = 2  # Z-axis for insertion\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_selection_confidence_at_contact(\n",
    "    episode_data: List[Dict],\n",
    "    axis: int = 2,\n",
    "    figsize: Tuple[float, float] = (10, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Box plot of selection confidence at initial contact, by outcome.\n",
    "    \n",
    "    Selection confidence = max(p, 1-p) where p is the selection probability.\n",
    "    This measures how \"certain\" the policy is about its mode choice.\n",
    "    \"\"\"\n",
    "    # Collect confidence at contact for each policy and outcome\n",
    "    data = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        outcome = ep['outcome']\n",
    "        \n",
    "        # Find first step in initial_contact phase\n",
    "        for step in ep['steps']:\n",
    "            if step.get('phase') == 'initial_contact':\n",
    "                prob = step.get('control_probability')\n",
    "                if prob is not None and len(prob) > axis:\n",
    "                    p = prob[axis]\n",
    "                    confidence = max(p, 1 - p)\n",
    "                    data[policy][outcome].append(confidence)\n",
    "                break\n",
    "    \n",
    "    if not data:\n",
    "        print(\"No selection confidence data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=DPI)\n",
    "    \n",
    "    policies = sorted(data.keys())\n",
    "    outcomes_present = ['success', 'break']  # Focus on these\n",
    "    \n",
    "    positions = []\n",
    "    labels = []\n",
    "    box_data = []\n",
    "    colors = []\n",
    "    \n",
    "    pos = 0\n",
    "    for policy in policies:\n",
    "        for outcome in outcomes_present:\n",
    "            if data[policy][outcome]:\n",
    "                box_data.append(data[policy][outcome])\n",
    "                positions.append(pos)\n",
    "                labels.append(f\"{policy}\\n{outcome}\")\n",
    "                colors.append(METHOD_COLORS.get(policy, 'gray'))\n",
    "                pos += 1\n",
    "        pos += 0.5  # Gap between policies\n",
    "    \n",
    "    bp = ax.boxplot(box_data, positions=positions, patch_artist=True, widths=0.6)\n",
    "    \n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(labels, fontsize=FONT_TICK)\n",
    "    ax.set_ylabel('Selection Confidence', fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_title('Selection Confidence at Initial Contact by Outcome', fontsize=FONT_TITLE)\n",
    "    ax.set_ylim(0.5, 1.0)  # Confidence ranges from 0.5 to 1.0\n",
    "    ax.tick_params(labelsize=FONT_TICK)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_selection_confidence_at_contact(\n",
    "        all_episode_data,\n",
    "        axis=CONFIDENCE_AXIS,\n",
    "        figsize=FIGSIZE_CONFIDENCE\n",
    "    )\n",
    "    if fig:\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 8: SELECTION PROBABILITY TRAJECTORIES BY PHASE\n",
    "# ============================================================\n",
    "#\n",
    "# Shows how selection probability (force vs position control)\n",
    "# evolves within each phase, separated by outcome.\n",
    "# Includes both LCLoP and Hybrid-Basic policies.\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_PROB_TRAJ = (14, 8)  # Taller to accommodate two rows\n",
    "PROB_AXIS = 2  # Z-axis\n",
    "NUM_BINS = 20  # Normalized time bins per phase\n",
    "\n",
    "# Outcome colors\n",
    "OUTCOME_COLORS = {\n",
    "    'success': '#2ca02c',  # Green\n",
    "    'break': '#d62728',    # Red\n",
    "    'timeout': '#7f7f7f',  # Gray\n",
    "}\n",
    "\n",
    "# Policies with selection probability\n",
    "HYBRID_POLICIES = ['SWISH', 'LCLoP', 'Hybrid-Basic']\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_selection_probability_by_phase_trajectory(\n",
    "    episode_data: List[Dict],\n",
    "    axis: int = 2,\n",
    "    num_bins: int = 20,\n",
    "    figsize: Tuple[float, float] = (14, 8)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot selection probability trajectories normalized within each phase.\n",
    "    Shows mean  std for success vs break outcomes.\n",
    "    Includes both LCLoP and Hybrid-Basic policies.\n",
    "    \"\"\"\n",
    "    # Filter to policies with selection probability\n",
    "    hybrid_episodes = [ep for ep in episode_data if ep['policy'] in HYBRID_POLICIES]\n",
    "    \n",
    "    if not hybrid_episodes:\n",
    "        print(\"No LCLoP or Hybrid-Basic episodes found.\")\n",
    "        return None\n",
    "    \n",
    "    # Group by policy\n",
    "    episodes_by_policy = defaultdict(list)\n",
    "    for ep in hybrid_episodes:\n",
    "        episodes_by_policy[ep['policy']].append(ep)\n",
    "    \n",
    "    # Create 2-row figure: one row per policy\n",
    "    policies_present = [p for p in HYBRID_POLICIES if p in episodes_by_policy]\n",
    "    n_policies = len(policies_present)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_policies, len(PHASES), figsize=figsize, dpi=DPI, sharey=True)\n",
    "    if n_policies == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row_idx, policy in enumerate(policies_present):\n",
    "        policy_episodes = episodes_by_policy[policy]\n",
    "        \n",
    "        # Collect trajectories: {phase: {outcome: [[prob_at_normalized_time]]}}\n",
    "        trajectories = {phase: {outcome: [] for outcome in ['success', 'break']} for phase in PHASES}\n",
    "        \n",
    "        for ep in policy_episodes:\n",
    "            outcome = ep['outcome']\n",
    "            if outcome not in ['success', 'break']:\n",
    "                continue\n",
    "            \n",
    "            # Group steps by phase\n",
    "            phase_steps = defaultdict(list)\n",
    "            for step in ep['steps']:\n",
    "                phase_steps[step.get('phase', 'unknown')].append(step)\n",
    "            \n",
    "            # Extract normalized trajectory for each phase\n",
    "            for phase in PHASES:\n",
    "                steps = phase_steps.get(phase, [])\n",
    "                if len(steps) < 2:\n",
    "                    continue\n",
    "                \n",
    "                probs = []\n",
    "                for step in steps:\n",
    "                    prob = step.get('control_probability')\n",
    "                    if prob is not None and len(prob) > axis:\n",
    "                        probs.append(prob[axis])\n",
    "                    else:\n",
    "                        probs.append(np.nan)\n",
    "                \n",
    "                # Interpolate to fixed number of bins\n",
    "                t_orig = np.linspace(0, 1, len(probs))\n",
    "                t_new = np.linspace(0, 1, num_bins)\n",
    "                normalized = np.interp(t_new, t_orig, probs)\n",
    "                trajectories[phase][outcome].append(normalized)\n",
    "        \n",
    "        t_norm = np.linspace(0, 100, num_bins)\n",
    "        \n",
    "        for col_idx, phase in enumerate(PHASES):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            \n",
    "            # Add phase background\n",
    "            ax.axvspan(0, 100, alpha=0.15, color=PHASE_COLORS[phase])\n",
    "            \n",
    "            for outcome in ['success', 'break']:\n",
    "                trajs = trajectories[phase][outcome]\n",
    "                if not trajs:\n",
    "                    continue\n",
    "                \n",
    "                trajs = np.array(trajs)\n",
    "                with np.errstate(all='ignore'):\n",
    "                    mean = np.nanmean(trajs, axis=0)\n",
    "                    std = np.nanstd(trajs, axis=0)\n",
    "                \n",
    "                color = OUTCOME_COLORS[outcome]\n",
    "                ax.plot(t_norm, mean, color=color, linewidth=2, label=outcome.title())\n",
    "                ax.fill_between(t_norm, mean - std, mean + std, color=color, alpha=ALPHA_FILL)\n",
    "            \n",
    "            ax.set_xlabel('Phase Progress (%)', fontsize=FONT_AXIS_LABEL)\n",
    "            ax.tick_params(labelsize=FONT_TICK)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.set_ylim(0, 1)\n",
    "            \n",
    "            # Column titles (phase names) only on top row\n",
    "            if row_idx == 0:\n",
    "                ax.set_title(phase.replace('_', ' ').title(), fontsize=FONT_TITLE)\n",
    "            \n",
    "            # Row labels (policy names) only on first column\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(f'{policy}\\nForce Control Prob', fontsize=FONT_AXIS_LABEL)\n",
    "                ax.legend(fontsize=FONT_LEGEND, loc='upper left')\n",
    "    \n",
    "    plt.suptitle('Selection Probability Trajectory by Phase', fontsize=FONT_TITLE, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_selection_probability_by_phase_trajectory(\n",
    "        all_episode_data,\n",
    "        axis=PROB_AXIS,\n",
    "        num_bins=NUM_BINS,\n",
    "        figsize=FIGSIZE_PROB_TRAJ\n",
    "    )\n",
    "    if fig:\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 9: SELECTION PROBABILITY BY PHASE (VIOLIN PLOT)\n",
    "# ============================================================\n",
    "#\n",
    "# Violin plots showing distribution of selection probability\n",
    "# values within each phase, comparing success vs break outcomes.\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_VIOLIN = (10, 6)\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_selection_probability_by_phase_violin(\n",
    "    episode_data: List[Dict],\n",
    "    axis: int = 2,\n",
    "    figsize: Tuple[float, float] = (10, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Violin plots of selection probability by phase, comparing outcomes.\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Filter to LCLoP only\n",
    "    lclop_episodes = [ep for ep in episode_data if ep['policy'] == 'SWISH']\n",
    "    \n",
    "    if not lclop_episodes:\n",
    "        print(\"No LCLoP episodes found.\")\n",
    "        return None\n",
    "    \n",
    "    # Collect data\n",
    "    data = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for ep in lclop_episodes:\n",
    "        outcome = ep['outcome']\n",
    "        if outcome not in ['success', 'break']:\n",
    "            continue\n",
    "        \n",
    "        for step in ep['steps']:\n",
    "            phase = step.get('phase', 'unknown')\n",
    "            prob = step.get('control_probability')\n",
    "            if prob is not None and len(prob) > axis and phase in PHASES:\n",
    "                data[phase][outcome].append(prob[axis])\n",
    "    \n",
    "    # Build DataFrame\n",
    "    rows = []\n",
    "    for phase in PHASES:\n",
    "        for outcome in ['success', 'break']:\n",
    "            for prob in data[phase][outcome]:\n",
    "                rows.append({\n",
    "                    'Phase': phase.replace('_', ' ').title(),\n",
    "                    'Outcome': outcome.title(),\n",
    "                    'Probability': prob\n",
    "                })\n",
    "    \n",
    "    if not rows:\n",
    "        print(\"No data to plot.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=DPI)\n",
    "    \n",
    "    phase_order = [p.replace('_', ' ').title() for p in PHASES]\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df, x='Phase', y='Probability', hue='Outcome',\n",
    "        order=phase_order, split=True, ax=ax,\n",
    "        palette={'Success': OUTCOME_COLORS['success'], 'Break': OUTCOME_COLORS['break']}\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('Phase', fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_ylabel('Force Control Probability', fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_title('Selection Probability Distribution by Phase and Outcome (LCLoP)', fontsize=FONT_TITLE)\n",
    "    ax.tick_params(labelsize=FONT_TICK)\n",
    "    ax.legend(fontsize=FONT_LEGEND)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    try:\n",
    "        fig = plot_selection_probability_by_phase_violin(\n",
    "            all_episode_data,\n",
    "            axis=PROB_AXIS,\n",
    "            figsize=FIGSIZE_VIOLIN\n",
    "        )\n",
    "        if fig:\n",
    "            plt.show()\n",
    "    except ImportError:\n",
    "        print(\"Seaborn not installed. Install with: pip install seaborn\")\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 10: BREAK DEPTH VS TRAJECTORY LENGTH\n",
    "# ============================================================\n",
    "#\n",
    "# Scatter plot showing for each break event:\n",
    "# - X-axis: Number of steps in the trajectory before break occurred\n",
    "# - Y-axis: Height relative to top of hole (0 = top, negative = inserted)\n",
    "# - Text annotation: XY distance to hole center (mm)\n",
    "#\n",
    "# Height is computed as: peg_z - hole_z - HOLE_DEPTH\n",
    "# So that 0 = top of hole, -HOLE_DEPTH = bottom (success)\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_BREAK_SCATTER = (10, 6)\n",
    "MARKER_SIZE = 80\n",
    "MARKER_ALPHA = 0.7\n",
    "\n",
    "# Hole depth in meters (2.5cm)\n",
    "HOLE_DEPTH = 0.025\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_break_depth_vs_steps(episode_data, hole_depth=0.025, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Scatter plot of break height vs number of steps in trajectory.\n",
    "    \n",
    "    Height is computed as: peg_z - hole_z - hole_depth\n",
    "    - Positive: peg is above the hole top (approach phase)\n",
    "    - Zero: peg is at the top of the hole\n",
    "    - Negative: peg is inside the hole (insertion phase)\n",
    "    - -hole_depth: peg is at the bottom (success)\n",
    "    \n",
    "    Also shows XY distance to hole center as text annotation.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        hole_depth: Depth of the hole in meters (default 0.025m = 2.5cm)\n",
    "        figsize: Figure size\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Collect data for break episodes\n",
    "    break_data = defaultdict(lambda: {'steps': [], 'heights': [], 'xy_dists': []})\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] != 'break':\n",
    "            continue\n",
    "        \n",
    "        policy = ep['policy']\n",
    "        steps = ep['steps']\n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        \n",
    "        if not steps or hole_pos is None:\n",
    "            continue\n",
    "        \n",
    "        # Number of steps in trajectory\n",
    "        n_steps = len(steps)\n",
    "        \n",
    "        # Get peg position at break (last step)\n",
    "        last_step = steps[-1]\n",
    "        peg_pos = last_step.get('peg_pos')\n",
    "        \n",
    "        if peg_pos is None or len(peg_pos) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Compute height relative to top of hole\n",
    "        # peg_z - hole_z - hole_depth\n",
    "        # 0 = at top of hole, negative = inserted, -hole_depth = bottom\n",
    "        height = peg_pos[2] - hole_pos[2] - hole_depth\n",
    "        \n",
    "        # Compute XY distance to hole center\n",
    "        xy_dist = np.sqrt((peg_pos[0] - hole_pos[0])**2 + (peg_pos[1] - hole_pos[1])**2)\n",
    "        \n",
    "        break_data[policy]['steps'].append(n_steps)\n",
    "        break_data[policy]['heights'].append(height)\n",
    "        break_data[policy]['xy_dists'].append(xy_dist)\n",
    "    \n",
    "    if not any(break_data[p]['steps'] for p in break_data):\n",
    "        print(\"No break events with valid height data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=DPI)\n",
    "    \n",
    "    for policy in sorted(break_data.keys()):\n",
    "        data = break_data[policy]\n",
    "        if not data['steps']:\n",
    "            continue\n",
    "        \n",
    "        color = METHOD_COLORS.get(policy, 'gray')\n",
    "        ax.scatter(\n",
    "            data['steps'], \n",
    "            data['heights'],\n",
    "            c=color,\n",
    "            s=MARKER_SIZE,\n",
    "            alpha=MARKER_ALPHA,\n",
    "            label=f\"{policy} (n={len(data['steps'])})\",\n",
    "            edgecolors='white',\n",
    "            linewidths=0.5\n",
    "        )\n",
    "        \n",
    "        # Add XY distance annotations next to each point\n",
    "        for i, (x, y, xy_dist) in enumerate(zip(data['steps'], data['heights'], data['xy_dists'])):\n",
    "            # Convert to mm for readability\n",
    "            xy_dist_mm = xy_dist * 1000\n",
    "            ax.annotate(\n",
    "                f'{xy_dist_mm:.1f}mm',\n",
    "                (x, y),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points',\n",
    "                fontsize=7,\n",
    "                color=color,\n",
    "                alpha=0.8\n",
    "            )\n",
    "    \n",
    "    ax.set_xlabel('Number of Steps in Trajectory', fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_ylabel('Height Relative to Hole Top (m)', fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_title('Break Height vs Trajectory Length (with XY distance to center)', fontsize=FONT_TITLE)\n",
    "    \n",
    "    # Add horizontal line for hole top reference\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1.5, alpha=0.7, label='Hole Top')\n",
    "    \n",
    "    ax.legend(fontsize=FONT_LEGEND, loc='best')\n",
    "    ax.tick_params(labelsize=FONT_TICK)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add summary statistics as text\n",
    "    total_breaks = sum(len(break_data[p]['steps']) for p in break_data)\n",
    "    ax.text(\n",
    "        0.02, 0.98, \n",
    "        f'Total breaks: {total_breaks}',\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=FONT_TICK,\n",
    "        verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_break_depth_vs_steps(\n",
    "        all_episode_data,\n",
    "        hole_depth=HOLE_DEPTH,\n",
    "        figsize=FIGSIZE_BREAK_SCATTER\n",
    "    )\n",
    "    if fig:\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "gmxi4axflx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 11: BREAK HEIGHT VS VELOCITY\n",
    "# ============================================================\n",
    "#\n",
    "# Two stacked scatter plots showing for each break event:\n",
    "# - Top: XY-plane velocity (magnitude) vs height relative to hole top\n",
    "# - Bottom: Z-velocity vs height relative to hole top\n",
    "# - Text annotation: XY distance to hole center (mm)\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_VELOCITY = (10, 10)\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_break_height_vs_velocity(episode_data, hole_depth=0.025, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Two stacked scatter plots of break height vs velocity.\n",
    "    \n",
    "    Top plot: XY velocity magnitude on x-axis\n",
    "    Bottom plot: Z velocity on x-axis\n",
    "    Both plots: Height relative to hole top on y-axis\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        hole_depth: Depth of the hole in meters (default 0.025m = 2.5cm)\n",
    "        figsize: Figure size\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Collect data for break episodes\n",
    "    break_data = defaultdict(lambda: {\n",
    "        'heights': [], \n",
    "        'xy_vels': [], \n",
    "        'z_vels': [], \n",
    "        'xy_dists': []\n",
    "    })\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] != 'break':\n",
    "            continue\n",
    "        \n",
    "        policy = ep['policy']\n",
    "        steps = ep['steps']\n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        \n",
    "        if not steps or hole_pos is None:\n",
    "            continue\n",
    "        \n",
    "        # Get last step (at break)\n",
    "        last_step = steps[-1]\n",
    "        peg_pos = last_step.get('peg_pos')\n",
    "        velocity = last_step.get('velocity')\n",
    "        \n",
    "        if peg_pos is None or len(peg_pos) < 3:\n",
    "            continue\n",
    "        if velocity is None or len(velocity) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Compute height relative to top of hole\n",
    "        height = peg_pos[2] - hole_pos[2] - hole_depth\n",
    "        \n",
    "        # Compute XY velocity magnitude\n",
    "        xy_vel = np.sqrt(velocity[0]**2 + velocity[1]**2)\n",
    "        \n",
    "        # Z velocity\n",
    "        z_vel = velocity[2]\n",
    "        \n",
    "        # Compute XY distance to hole center\n",
    "        xy_dist = np.sqrt((peg_pos[0] - hole_pos[0])**2 + (peg_pos[1] - hole_pos[1])**2)\n",
    "        \n",
    "        break_data[policy]['heights'].append(height)\n",
    "        break_data[policy]['xy_vels'].append(xy_vel)\n",
    "        break_data[policy]['z_vels'].append(z_vel)\n",
    "        break_data[policy]['xy_dists'].append(xy_dist)\n",
    "    \n",
    "    if not any(break_data[p]['heights'] for p in break_data):\n",
    "        print(\"No break events with valid velocity data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Create figure with two stacked subplots\n",
    "    fig, (ax_xy, ax_z) = plt.subplots(2, 1, figsize=figsize, dpi=DPI)\n",
    "    \n",
    "    for policy in sorted(break_data.keys()):\n",
    "        data = break_data[policy]\n",
    "        if not data['heights']:\n",
    "            continue\n",
    "        \n",
    "        color = METHOD_COLORS.get(policy, 'gray')\n",
    "        \n",
    "        # Top plot: XY velocity vs height\n",
    "        ax_xy.scatter(\n",
    "            data['xy_vels'], \n",
    "            data['heights'],\n",
    "            c=color,\n",
    "            s=MARKER_SIZE,\n",
    "            alpha=MARKER_ALPHA,\n",
    "            label=f\"{policy} (n={len(data['heights'])})\",\n",
    "            edgecolors='white',\n",
    "            linewidths=0.5\n",
    "        )\n",
    "        \n",
    "        # Add XY distance annotations\n",
    "        for x, y, xy_dist in zip(data['xy_vels'], data['heights'], data['xy_dists']):\n",
    "            xy_dist_mm = xy_dist * 1000\n",
    "            ax_xy.annotate(\n",
    "                f'{xy_dist_mm:.1f}mm',\n",
    "                (x, y),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points',\n",
    "                fontsize=7,\n",
    "                color=color,\n",
    "                alpha=0.8\n",
    "            )\n",
    "        \n",
    "        # Bottom plot: Z velocity vs height\n",
    "        ax_z.scatter(\n",
    "            data['z_vels'], \n",
    "            data['heights'],\n",
    "            c=color,\n",
    "            s=MARKER_SIZE,\n",
    "            alpha=MARKER_ALPHA,\n",
    "            label=f\"{policy} (n={len(data['heights'])})\",\n",
    "            edgecolors='white',\n",
    "            linewidths=0.5\n",
    "        )\n",
    "        \n",
    "        # Add XY distance annotations\n",
    "        for x, y, xy_dist in zip(data['z_vels'], data['heights'], data['xy_dists']):\n",
    "            xy_dist_mm = xy_dist * 1000\n",
    "            ax_z.annotate(\n",
    "                f'{xy_dist_mm:.1f}mm',\n",
    "                (x, y),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points',\n",
    "                fontsize=7,\n",
    "                color=color,\n",
    "                alpha=0.8\n",
    "            )\n",
    "    \n",
    "    # Configure top plot (XY velocity)\n",
    "    ax_xy.set_xlabel('XY Velocity Magnitude (m/s)', fontsize=FONT_AXIS_LABEL)\n",
    "    ax_xy.set_ylabel('Height Relative to Hole Top (m)', fontsize=FONT_AXIS_LABEL)\n",
    "    ax_xy.set_title('Break Height vs XY Velocity (with XY distance to center)', fontsize=FONT_TITLE)\n",
    "    ax_xy.axhline(y=0, color='black', linestyle='--', linewidth=1.5, alpha=0.7, label='Hole Top')\n",
    "    ax_xy.legend(fontsize=FONT_LEGEND, loc='best')\n",
    "    ax_xy.tick_params(labelsize=FONT_TICK)\n",
    "    ax_xy.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Configure bottom plot (Z velocity)\n",
    "    ax_z.set_xlabel('Z Velocity (m/s)', fontsize=FONT_AXIS_LABEL)\n",
    "    ax_z.set_ylabel('Height Relative to Hole Top (m)', fontsize=FONT_AXIS_LABEL)\n",
    "    ax_z.set_title('Break Height vs Z Velocity (with XY distance to center)', fontsize=FONT_TITLE)\n",
    "    ax_z.axhline(y=0, color='black', linestyle='--', linewidth=1.5, alpha=0.7, label='Hole Top')\n",
    "    ax_z.axvline(x=0, color='gray', linestyle=':', linewidth=1, alpha=0.5)  # Zero velocity reference\n",
    "    ax_z.legend(fontsize=FONT_LEGEND, loc='best')\n",
    "    ax_z.tick_params(labelsize=FONT_TICK)\n",
    "    ax_z.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_break_height_vs_velocity(\n",
    "        all_episode_data,\n",
    "        hole_depth=HOLE_DEPTH,\n",
    "        figsize=FIGSIZE_VELOCITY\n",
    "    )\n",
    "    if fig:\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ibytr1wttq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 12: BREAK TRAJECTORY ANALYSIS (6-PANEL)\n",
    "# ============================================================\n",
    "#\n",
    "# 3x2 grid showing trajectories leading up to break:\n",
    "# Left column (Z-related):\n",
    "#   - Relative Z position (height relative to hole top)\n",
    "#   - Z velocity\n",
    "#   - Z force\n",
    "# Right column (XY-related):\n",
    "#   - XY distance to hole center\n",
    "#   - XY velocity magnitude\n",
    "#   - XY force magnitude\n",
    "#\n",
    "# X-axis: timesteps leading up to break\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_BREAK_TRAJ = (12, 12)\n",
    "LINE_ALPHA = 0.5\n",
    "LINE_WIDTH = 1.5\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_break_trajectory_analysis(episode_data, hole_depth=0.025, figsize=(12, 12)):\n",
    "    \"\"\"\n",
    "    6-panel plot showing trajectories leading up to break events.\n",
    "    \n",
    "    Left column: Z-related (position, velocity, force)\n",
    "    Right column: XY-related (distance, velocity, force)\n",
    "    X-axis: timesteps (0 = start of episode)\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        hole_depth: Depth of the hole in meters\n",
    "        figsize: Figure size\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Collect trajectory data for break episodes\n",
    "    # Structure: {policy: [{'z_pos': [...], 'xy_dist': [...], ...}, ...]}\n",
    "    break_trajectories = defaultdict(list)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] != 'break':\n",
    "            continue\n",
    "        \n",
    "        policy = ep['policy']\n",
    "        steps = ep['steps']\n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        \n",
    "        if not steps or hole_pos is None:\n",
    "            continue\n",
    "        \n",
    "        # Extract trajectory data for each step\n",
    "        traj = {\n",
    "            'z_pos': [],\n",
    "            'xy_dist': [],\n",
    "            'z_vel': [],\n",
    "            'xy_vel': [],\n",
    "            'z_force': [],\n",
    "            'xy_force': [],\n",
    "            'timesteps': []\n",
    "        }\n",
    "        \n",
    "        for i, step in enumerate(steps):\n",
    "            peg_pos = step.get('peg_pos')\n",
    "            velocity = step.get('velocity')\n",
    "            force = step.get('contact_force')\n",
    "            \n",
    "            if peg_pos is None or len(peg_pos) < 3:\n",
    "                continue\n",
    "            if velocity is None or len(velocity) < 3:\n",
    "                continue\n",
    "            if force is None or len(force) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Z position relative to hole top\n",
    "            z_pos = peg_pos[2] - hole_pos[2] - hole_depth\n",
    "            \n",
    "            # XY distance to hole center\n",
    "            xy_dist = np.sqrt((peg_pos[0] - hole_pos[0])**2 + (peg_pos[1] - hole_pos[1])**2)\n",
    "            \n",
    "            # Velocities\n",
    "            z_vel = velocity[2]\n",
    "            xy_vel = np.sqrt(velocity[0]**2 + velocity[1]**2)\n",
    "            \n",
    "            # Forces\n",
    "            z_force = force[2]\n",
    "            xy_force = np.sqrt(force[0]**2 + force[1]**2)\n",
    "            \n",
    "            traj['z_pos'].append(z_pos)\n",
    "            traj['xy_dist'].append(xy_dist)\n",
    "            traj['z_vel'].append(z_vel)\n",
    "            traj['xy_vel'].append(xy_vel)\n",
    "            traj['z_force'].append(z_force)\n",
    "            traj['xy_force'].append(xy_force)\n",
    "            traj['timesteps'].append(i)\n",
    "        \n",
    "        if traj['timesteps']:\n",
    "            break_trajectories[policy].append(traj)\n",
    "    \n",
    "    if not any(break_trajectories[p] for p in break_trajectories):\n",
    "        print(\"No break trajectories found.\")\n",
    "        return None\n",
    "    \n",
    "    # Create 3x2 figure\n",
    "    fig, axes = plt.subplots(3, 2, figsize=figsize, dpi=DPI)\n",
    "    \n",
    "    # Define what to plot in each cell\n",
    "    # (row, col): (data_key, ylabel, title)\n",
    "    plot_config = {\n",
    "        (0, 0): ('z_pos', 'Height Rel. to Hole Top (m)', 'Z Position'),\n",
    "        (0, 1): ('xy_dist', 'XY Distance to Center (m)', 'XY Distance to Hole'),\n",
    "        (1, 0): ('z_vel', 'Z Velocity (m/s)', 'Z Velocity'),\n",
    "        (1, 1): ('xy_vel', 'XY Velocity (m/s)', 'XY Velocity'),\n",
    "        (2, 0): ('z_force', 'Z Force (N)', 'Z Force'),\n",
    "        (2, 1): ('xy_force', 'XY Force (N)', 'XY Force'),\n",
    "    }\n",
    "    \n",
    "    # Plot each trajectory\n",
    "    for policy in sorted(break_trajectories.keys()):\n",
    "        color = METHOD_COLORS.get(policy, 'gray')\n",
    "        trajectories = break_trajectories[policy]\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            timesteps = traj['timesteps']\n",
    "            \n",
    "            for (row, col), (data_key, ylabel, title) in plot_config.items():\n",
    "                ax = axes[row, col]\n",
    "                data = traj[data_key]\n",
    "                ax.plot(timesteps, data, color=color, alpha=LINE_ALPHA, linewidth=LINE_WIDTH)\n",
    "    \n",
    "    # Configure each subplot\n",
    "    for (row, col), (data_key, ylabel, title) in plot_config.items():\n",
    "        ax = axes[row, col]\n",
    "        ax.set_ylabel(ylabel, fontsize=FONT_AXIS_LABEL)\n",
    "        ax.set_title(title, fontsize=FONT_TITLE)\n",
    "        ax.tick_params(labelsize=FONT_TICK)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add reference lines\n",
    "        if data_key == 'z_pos':\n",
    "            ax.axhline(y=0, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "        elif data_key in ['z_vel', 'z_force']:\n",
    "            ax.axhline(y=0, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        # X-axis label only on bottom row\n",
    "        if row == 2:\n",
    "            ax.set_xlabel('Timestep', fontsize=FONT_AXIS_LABEL)\n",
    "    \n",
    "    # Create legend from policy colors\n",
    "    legend_handles = []\n",
    "    for policy in sorted(break_trajectories.keys()):\n",
    "        color = METHOD_COLORS.get(policy, 'gray')\n",
    "        n_breaks = len(break_trajectories[policy])\n",
    "        legend_handles.append(plt.Line2D([0], [0], color=color, linewidth=2, label=f'{policy} (n={n_breaks})'))\n",
    "    \n",
    "    fig.legend(handles=legend_handles, loc='upper center', ncol=len(legend_handles), \n",
    "               fontsize=FONT_LEGEND, bbox_to_anchor=(0.5, 1.02))\n",
    "    \n",
    "    plt.suptitle('Break Trajectory Analysis', fontsize=FONT_TITLE + 2, y=1.04)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_break_trajectory_analysis(\n",
    "        all_episode_data,\n",
    "        hole_depth=HOLE_DEPTH,\n",
    "        figsize=FIGSIZE_BREAK_TRAJ\n",
    "    )\n",
    "    if fig:\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0yvfqsotn3o9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data loaded.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 13: SUCCESS TRAJECTORY ANALYSIS (6-PANEL)\n",
    "# ============================================================\n",
    "#\n",
    "# 3x2 grid showing successful trajectories:\n",
    "# Left column (Z-related):\n",
    "#   - Relative Z position (height relative to hole top)\n",
    "#   - Z velocity\n",
    "#   - Z force\n",
    "# Right column (XY-related):\n",
    "#   - XY distance to hole center\n",
    "#   - XY velocity magnitude\n",
    "#   - XY force magnitude\n",
    "#\n",
    "# X-axis: timesteps\n",
    "\n",
    "# Plot Configuration\n",
    "FIGSIZE_SUCCESS_TRAJ = (12, 12)\n",
    "SUCCESS_LINE_ALPHA = 0.3  # Lower alpha since there are more trajectories\n",
    "SUCCESS_LINE_WIDTH = 1.0\n",
    "\n",
    "# Limit number of trajectories per policy to avoid clutter\n",
    "MAX_SUCCESS_TRAJECTORIES = 20  # Set to None for all\n",
    "\n",
    "# Policies to include (exclude Pose)\n",
    "SUCCESS_POLICIES = ['SWISH', 'Hybrid-Basic']\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def plot_success_trajectory_analysis(episode_data, hole_depth=0.025, max_per_policy=20, \n",
    "                                      policies_to_include=None, figsize=(12, 12)):\n",
    "    \"\"\"\n",
    "    6-panel plot showing successful trajectories.\n",
    "    \n",
    "    Left column: Z-related (position, velocity, force)\n",
    "    Right column: XY-related (distance, velocity, force)\n",
    "    X-axis: timesteps (0 = start of episode)\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        hole_depth: Depth of the hole in meters\n",
    "        max_per_policy: Max trajectories to plot per policy (None for all)\n",
    "        policies_to_include: List of policy names to include (None for all)\n",
    "        figsize: Figure size\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Collect trajectory data for success episodes\n",
    "    success_trajectories = defaultdict(list)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] != 'success':\n",
    "            continue\n",
    "        \n",
    "        policy = ep['policy']\n",
    "        \n",
    "        # Filter by policy if specified\n",
    "        if policies_to_include is not None and policy not in policies_to_include:\n",
    "            continue\n",
    "        \n",
    "        steps = ep['steps']\n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        \n",
    "        if not steps or hole_pos is None:\n",
    "            continue\n",
    "        \n",
    "        # Extract trajectory data for each step\n",
    "        traj = {\n",
    "            'z_pos': [],\n",
    "            'xy_dist': [],\n",
    "            'z_vel': [],\n",
    "            'xy_vel': [],\n",
    "            'z_force': [],\n",
    "            'xy_force': [],\n",
    "            'timesteps': []\n",
    "        }\n",
    "        \n",
    "        for i, step in enumerate(steps):\n",
    "            peg_pos = step.get('peg_pos')\n",
    "            velocity = step.get('velocity')\n",
    "            force = step.get('contact_force')\n",
    "            \n",
    "            if peg_pos is None or len(peg_pos) < 3:\n",
    "                continue\n",
    "            if velocity is None or len(velocity) < 3:\n",
    "                continue\n",
    "            if force is None or len(force) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Z position relative to hole top\n",
    "            z_pos = peg_pos[2] - hole_pos[2] - hole_depth\n",
    "            \n",
    "            # XY distance to hole center\n",
    "            xy_dist = np.sqrt((peg_pos[0] - hole_pos[0])**2 + (peg_pos[1] - hole_pos[1])**2)\n",
    "            \n",
    "            # Velocities\n",
    "            z_vel = velocity[2]\n",
    "            xy_vel = np.sqrt(velocity[0]**2 + velocity[1]**2)\n",
    "            \n",
    "            # Forces\n",
    "            z_force = force[2]\n",
    "            xy_force = np.sqrt(force[0]**2 + force[1]**2)\n",
    "            \n",
    "            traj['z_pos'].append(z_pos)\n",
    "            traj['xy_dist'].append(xy_dist)\n",
    "            traj['z_vel'].append(z_vel)\n",
    "            traj['xy_vel'].append(xy_vel)\n",
    "            traj['z_force'].append(z_force)\n",
    "            traj['xy_force'].append(xy_force)\n",
    "            traj['timesteps'].append(i)\n",
    "        \n",
    "        if traj['timesteps']:\n",
    "            success_trajectories[policy].append(traj)\n",
    "    \n",
    "    if not any(success_trajectories[p] for p in success_trajectories):\n",
    "        print(\"No success trajectories found.\")\n",
    "        return None\n",
    "    \n",
    "    # Create 3x2 figure\n",
    "    fig, axes = plt.subplots(3, 2, figsize=figsize, dpi=DPI)\n",
    "    \n",
    "    # Define what to plot in each cell\n",
    "    plot_config = {\n",
    "        (0, 0): ('z_pos', 'Height Rel. to Hole Top (m)', 'Z Position'),\n",
    "        (0, 1): ('xy_dist', 'XY Distance to Center (m)', 'XY Distance to Hole'),\n",
    "        (1, 0): ('z_vel', 'Z Velocity (m/s)', 'Z Velocity'),\n",
    "        (1, 1): ('xy_vel', 'XY Velocity (m/s)', 'XY Velocity'),\n",
    "        (2, 0): ('z_force', 'Z Force (N)', 'Z Force'),\n",
    "        (2, 1): ('xy_force', 'XY Force (N)', 'XY Force'),\n",
    "    }\n",
    "    \n",
    "    # Track total counts for legend\n",
    "    total_counts = {}\n",
    "    \n",
    "    # Plot each trajectory\n",
    "    for policy in sorted(success_trajectories.keys()):\n",
    "        color = METHOD_COLORS.get(policy, 'gray')\n",
    "        trajectories = success_trajectories[policy]\n",
    "        total_counts[policy] = len(trajectories)\n",
    "        \n",
    "        # Limit number of trajectories if specified\n",
    "        if max_per_policy is not None and len(trajectories) > max_per_policy:\n",
    "            # Randomly sample\n",
    "            np.random.seed(42)  # For reproducibility\n",
    "            indices = np.random.choice(len(trajectories), max_per_policy, replace=False)\n",
    "            trajectories = [trajectories[i] for i in indices]\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            timesteps = traj['timesteps']\n",
    "            \n",
    "            for (row, col), (data_key, ylabel, title) in plot_config.items():\n",
    "                ax = axes[row, col]\n",
    "                data = traj[data_key]\n",
    "                ax.plot(timesteps, data, color=color, alpha=SUCCESS_LINE_ALPHA, linewidth=SUCCESS_LINE_WIDTH)\n",
    "    \n",
    "    # Configure each subplot\n",
    "    for (row, col), (data_key, ylabel, title) in plot_config.items():\n",
    "        ax = axes[row, col]\n",
    "        ax.set_ylabel(ylabel, fontsize=FONT_AXIS_LABEL)\n",
    "        ax.set_title(title, fontsize=FONT_TITLE)\n",
    "        ax.tick_params(labelsize=FONT_TICK)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add reference lines\n",
    "        if data_key == 'z_pos':\n",
    "            ax.axhline(y=0, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "            ax.axhline(y=-hole_depth, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "        elif data_key in ['z_vel', 'z_force']:\n",
    "            ax.axhline(y=0, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        # X-axis label only on bottom row\n",
    "        if row == 2:\n",
    "            ax.set_xlabel('Timestep', fontsize=FONT_AXIS_LABEL)\n",
    "    \n",
    "    # Create legend from policy colors\n",
    "    legend_handles = []\n",
    "    for policy in sorted(success_trajectories.keys()):\n",
    "        color = METHOD_COLORS.get(policy, 'gray')\n",
    "        n_total = total_counts[policy]\n",
    "        n_shown = min(n_total, max_per_policy) if max_per_policy else n_total\n",
    "        label = f'{policy} (n={n_shown}/{n_total})' if max_per_policy and n_total > max_per_policy else f'{policy} (n={n_total})'\n",
    "        legend_handles.append(plt.Line2D([0], [0], color=color, linewidth=2, label=label))\n",
    "    \n",
    "    fig.legend(handles=legend_handles, loc='upper center', ncol=len(legend_handles), \n",
    "               fontsize=FONT_LEGEND, bbox_to_anchor=(0.5, 1.02))\n",
    "    \n",
    "    plt.suptitle('Success Trajectory Analysis', fontsize=FONT_TITLE + 2, y=1.04)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "if all_episode_data:\n",
    "    fig = plot_success_trajectory_analysis(\n",
    "        all_episode_data,\n",
    "        hole_depth=HOLE_DEPTH,\n",
    "        max_per_policy=MAX_SUCCESS_TRAJECTORIES,\n",
    "        policies_to_include=SUCCESS_POLICIES,\n",
    "        figsize=FIGSIZE_SUCCESS_TRAJ\n",
    "    )\n",
    "    if fig:\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No episode data loaded.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaaclab_drail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
