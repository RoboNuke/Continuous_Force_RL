{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamics Robustness Analysis\n",
    "\n",
    "This notebook generates:\n",
    "1. Success Rate heatmaps (friction x mass) per method\n",
    "2. Break Rate heatmaps (friction x mass) per method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 1: IMPORTS & CONSTANTS\n",
    "# ============================================================\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import defaultdict\n",
    "\n",
    "# WandB Configuration\n",
    "ENTITY = \"hur\"\n",
    "PROJECT = \"SG_Exps\"\n",
    "\n",
    "# Method Tags\n",
    "METHOD_TAGS = {\n",
    "    \"Pose\": \"pose_task_frag:2026-01-06_00:52\",\n",
    "    #\"Pose\" : \"pose_25mm-noise:2026-01-19_07:50_15N\",\n",
    "    #\"Pose-7.5mm\":\"pose_75mm-noise:2026-01-17_19:18\",\n",
    "    \"MATCH\": \"LCLoP_task_frag:2026-01-06_00:27\",\n",
    "    \"Hybrid-Basic\": \"basic-hybrid_task_frag:2026-01-06_00:56\",\n",
    "}\n",
    "\n",
    "# Method Colors - set colors for each method here\n",
    "\"\"\" THE COLORS KEY SHOULD NOT BE CHANGED FOR ANY REASON WITHOUT USER PERMISSION DO NOT OVERWRITE!!!\"\"\"\n",
    "COLORS = {\n",
    "    \"Pose\": \"#2ca02c\",        # Green\n",
    "    \"Hybrid-Basic\": \"#ff7f0e\", # Orange\n",
    "    \"MATCH\": \"#1f77b4\",       # Blue\n",
    "}\n",
    "\n",
    "# Evaluation Tags\n",
    "TAG_EVAL_PERFORMANCE = \"eval_performance\"\n",
    "TAG_EVAL_DYNAMICS = \"eval_dynamics\"\n",
    "\n",
    "# Dynamics Parameters\n",
    "FRIC_VALUES = [\"0.5x\", \"0.75x\", \"1.0x\"]\n",
    "MASS_VALUES = [\"0.5x\", \"1.0x\", \"1.5x\", \"2.0x\"]\n",
    "\n",
    "# Metrics\n",
    "METRIC_SUCCESS = \"num_successful_completions\"\n",
    "METRIC_BREAKS = \"num_breaks\"\n",
    "METRIC_TOTAL = \"total_episodes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrobonuke\u001b[0m (\u001b[33mhur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pose (pose_task_frag:2026-01-06_00:52):\n",
      "  Eval_performance_pose_task_frag_f(15)_0: best checkpoint at step 1152000 (score: 100)\n",
      "  Eval_performance_pose_task_frag_f(15)_1: best checkpoint at step 2688000 (score: 98)\n",
      "  Eval_performance_pose_task_frag_f(15)_2: best checkpoint at step 2649600 (score: 100)\n",
      "  Eval_performance_pose_task_frag_f(15)_3: best checkpoint at step 1651200 (score: 98)\n",
      "  Eval_performance_pose_task_frag_f(15)_4: best checkpoint at step 2995200 (score: 99)\n",
      "\n",
      "MATCH (LCLoP_task_frag:2026-01-06_00:27):\n",
      "  Eval_performance_LCLoP_task_frag_f(15)_0: best checkpoint at step 2380800 (score: 97)\n",
      "  Eval_performance_LCLoP_task_frag_f(15)_1: best checkpoint at step 2880000 (score: 95)\n",
      "  Eval_performance_LCLoP_task_frag_f(15)_3: best checkpoint at step 2995200 (score: 92)\n",
      "  Eval_performance_LCLoP_task_frag_f(15)_2: best checkpoint at step 2841600 (score: 100)\n",
      "  Eval_performance_LCLoP_task_frag_f(15)_4: best checkpoint at step 2611200 (score: 98)\n",
      "\n",
      "Hybrid-Basic (basic-hybrid_task_frag:2026-01-06_00:56):\n",
      "  Eval_performance_basic-hybrid_task_frag_f(15)_1: best checkpoint at step 2150400 (score: 96)\n",
      "  Eval_performance_basic-hybrid_task_frag_f(15)_0: best checkpoint at step 1497600 (score: 97)\n",
      "  Eval_performance_basic-hybrid_task_frag_f(15)_2: best checkpoint at step 2803200 (score: 98)\n",
      "  Eval_performance_basic-hybrid_task_frag_f(15)_3: best checkpoint at step 2841600 (score: 99)\n",
      "  Eval_performance_basic-hybrid_task_frag_f(15)_4: best checkpoint at step 2150400 (score: 97)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 2: DETERMINE BEST POLICY\n",
    "# ============================================================\n",
    "\n",
    "def get_best_checkpoint_per_run(api, method_tag):\n",
    "    \"\"\"Find the best checkpoint for each run with the given method tag.\"\"\"\n",
    "    runs = api.runs(\n",
    "        f\"{ENTITY}/{PROJECT}\",\n",
    "        filters={\"$and\": [{\"tags\": method_tag}, {\"tags\": TAG_EVAL_PERFORMANCE}]}\n",
    "    )\n",
    "    \n",
    "    best_checkpoints = {}\n",
    "    for run in runs:\n",
    "        history = run.history()\n",
    "        if history.empty:\n",
    "            print(f\"Warning: Run {run.name} has no history data\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate score: successes - breaks\n",
    "        history[\"score\"] = history[f\"Eval_Core/{METRIC_SUCCESS}\"] - history[f\"Eval_Core/{METRIC_BREAKS}\"]\n",
    "        best_idx = history[\"score\"].idxmax()\n",
    "        best_step = int(history.loc[best_idx, \"total_steps\"])\n",
    "        \n",
    "        best_checkpoints[run.id] = {\n",
    "            \"run_name\": run.name,\n",
    "            \"best_step\": best_step,\n",
    "            \"score\": history.loc[best_idx, \"score\"],\n",
    "        }\n",
    "        print(f\"  {run.name}: best checkpoint at step {best_step} (score: {history.loc[best_idx, 'score']:.0f})\")\n",
    "    \n",
    "    return best_checkpoints\n",
    "\n",
    "# Get best checkpoints for each method\n",
    "api = wandb.Api()\n",
    "best_checkpoints_by_method = {}\n",
    "\n",
    "for method_name, method_tag in METHOD_TAGS.items():\n",
    "    print(f\"\\n{method_name} ({method_tag}):\")\n",
    "    best_checkpoints_by_method[method_name] = get_best_checkpoint_per_run(api, method_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading data for Pose...\n",
      "Warning: Checkpoint 1152000 not found in Eval_dynamics_pose_task_frag_f(15)_0\n",
      "Warning: Checkpoint 2688000 not found in Eval_dynamics_pose_task_frag_f(15)_1\n",
      "Warning: Checkpoint 2649600 not found in Eval_dynamics_pose_task_frag_f(15)_2\n",
      "Warning: Checkpoint 1651200 not found in Eval_dynamics_pose_task_frag_f(15)_3\n",
      "Warning: Checkpoint 2995200 not found in Eval_dynamics_pose_task_frag_f(15)_4\n",
      "\n",
      "Downloading data for MATCH...\n",
      "Warning: Checkpoint 2380800 not found in Eval_dynamics_LCLoP_task_frag_f(15)_0\n",
      "Warning: Checkpoint 2880000 not found in Eval_dynamics_LCLoP_task_frag_f(15)_1\n",
      "Warning: Checkpoint 2841600 not found in Eval_dynamics_LCLoP_task_frag_f(15)_2\n",
      "Warning: Checkpoint 2995200 not found in Eval_dynamics_LCLoP_task_frag_f(15)_3\n",
      "Warning: Checkpoint 2611200 not found in Eval_dynamics_LCLoP_task_frag_f(15)_4\n",
      "\n",
      "Downloading data for Hybrid-Basic...\n",
      "Warning: Checkpoint 1497600 not found in Eval_dynamics_basic-hybrid_task_frag_f(15)_0\n",
      "Warning: Checkpoint 2803200 not found in Eval_dynamics_basic-hybrid_task_frag_f(15)_2\n",
      "Warning: Checkpoint 2150400 not found in Eval_dynamics_basic-hybrid_task_frag_f(15)_1\n",
      "Warning: Checkpoint 2841600 not found in Eval_dynamics_basic-hybrid_task_frag_f(15)_3\n",
      "Warning: Checkpoint 2150400 not found in Eval_dynamics_basic-hybrid_task_frag_f(15)_4\n",
      "\n",
      "============================================================\n",
      "DYNAMICS DATA SUMMARY\n",
      "============================================================\n",
      "\n",
      "Pose:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fric_level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fric \u001b[38;5;129;01min\u001b[39;00m FRIC_VALUES:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mass \u001b[38;5;129;01min\u001b[39;00m MASS_VALUES:\n\u001b[0;32m---> 69\u001b[0m         subset \u001b[38;5;241m=\u001b[39m df[(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfric_level\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m fric) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmass_level\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m mass)]\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subset\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     71\u001b[0m             total \u001b[38;5;241m=\u001b[39m subset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/isaaclab_drail/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fric_level'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BLOCK 3: DOWNLOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "def download_eval_dynamics_data(api, method_tag, best_checkpoints):\n",
    "    \"\"\"Download eval_dynamics data for best checkpoints across all fric x mass combinations.\"\"\"\n",
    "    runs = api.runs(\n",
    "        f\"{ENTITY}/{PROJECT}\",\n",
    "        filters={\"$and\": [{\"tags\": method_tag}, {\"tags\": TAG_EVAL_DYNAMICS}]}\n",
    "    )\n",
    "\n",
    "    # Build lookup by agent number from best_checkpoints\n",
    "    checkpoint_by_agent = {}\n",
    "    for run_id, info in best_checkpoints.items():\n",
    "        agent_num = info[\"run_name\"].rsplit(\"_\", 1)[-1]\n",
    "        checkpoint_by_agent[agent_num] = info[\"best_step\"]\n",
    "\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        # Extract agent number from run name\n",
    "        agent_num = run.name.rsplit(\"_\", 1)[-1]\n",
    "\n",
    "        if agent_num not in checkpoint_by_agent:\n",
    "            print(f\"Warning: No matching performance run for agent {agent_num} ({run.name})\")\n",
    "            continue\n",
    "\n",
    "        best_step = checkpoint_by_agent[agent_num]\n",
    "        history = run.history()\n",
    "        \n",
    "        if best_step not in history[\"total_steps\"].values:\n",
    "            print(f\"Warning: Checkpoint {best_step} not found in {run.name}\")\n",
    "            continue\n",
    "        \n",
    "        row = history[history[\"total_steps\"] == best_step].iloc[0]\n",
    "        \n",
    "        for fric in FRIC_VALUES:\n",
    "            for mass in MASS_VALUES:\n",
    "                prefix = f\"Dyn_Eval(fric={fric},mass={mass})_Core\"\n",
    "                data.append({\n",
    "                    \"run_id\": run.id,\n",
    "                    \"run_name\": run.name,\n",
    "                    \"checkpoint\": best_step,\n",
    "                    \"fric_level\": fric,\n",
    "                    \"mass_level\": mass,\n",
    "                    \"success\": row[f\"{prefix}/{METRIC_SUCCESS}\"],\n",
    "                    \"breaks\": row[f\"{prefix}/{METRIC_BREAKS}\"],\n",
    "                    \"total\": row[f\"{prefix}/{METRIC_TOTAL}\"],\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Download all data\n",
    "dynamics_data = {}\n",
    "\n",
    "for method_name, method_tag in METHOD_TAGS.items():\n",
    "    print(f\"\\nDownloading data for {method_name}...\")\n",
    "    dynamics_data[method_name] = download_eval_dynamics_data(\n",
    "        api, method_tag, best_checkpoints_by_method[method_name]\n",
    "    )\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DYNAMICS DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for method_name, df in dynamics_data.items():\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    for fric in FRIC_VALUES:\n",
    "        for mass in MASS_VALUES:\n",
    "            subset = df[(df[\"fric_level\"] == fric) & (df[\"mass_level\"] == mass)]\n",
    "            if not subset.empty:\n",
    "                total = subset[\"total\"].sum()\n",
    "                success_rate = 100 * subset[\"success\"].sum() / total\n",
    "                break_rate = 100 * subset[\"breaks\"].sum() / total\n",
    "                print(f\"  fric={fric}, mass={mass}: Success={success_rate:.1f}%, Break={break_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 4: SUCCESS RATE HEATMAP (FRICTION x MASS)\n",
    "# ============================================================\n",
    "\n",
    "# Policy Selection\n",
    "TOP_N_POLICIES = None  # Set to integer (e.g., 3) to use top N policies, or None for all\n",
    "\n",
    "# Plot Constants\n",
    "FIGSIZE_PER_METHOD = (5, 4)  # Size per individual heatmap\n",
    "DPI = 150\n",
    "\n",
    "# Font sizes\n",
    "FONT_TITLE = 14\n",
    "FONT_SUPTITLE = 16\n",
    "FONT_AXIS_LABEL = 12\n",
    "FONT_TICK = 10\n",
    "FONT_CELL = 11\n",
    "FONT_COLORBAR = 10\n",
    "\n",
    "# Colormap for success rate: red (low) -> green (high)\n",
    "# Alternative colormaps to try:\n",
    "#   CMAP = \"viridis\"       # Perceptually uniform: purple -> yellow\n",
    "#   CMAP = \"plasma\"        # Perceptually uniform: purple -> yellow (warmer)\n",
    "#   CMAP = \"YlGn\"          # Sequential: yellow -> green\n",
    "#   CMAP = \"coolwarm\"      # Diverging: blue -> red\n",
    "#   CMAP = \"RdYlBu\"        # Diverging: red -> blue\n",
    "CMAP = \"RdYlGn\"\n",
    "\n",
    "# Value range for color normalization\n",
    "VMIN = 0\n",
    "VMAX = 100\n",
    "\n",
    "# Labels\n",
    "SUPTITLE = \"Success Rate vs Dynamics Parameters\"\n",
    "X_LABEL = \"Friction\"\n",
    "Y_LABEL = \"Mass\"\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def filter_top_n_runs(df, best_checkpoints, top_n):\n",
    "    \"\"\"Filter dataframe to only include top N runs by score.\"\"\"\n",
    "    if top_n is None or len(best_checkpoints) <= top_n:\n",
    "        return df\n",
    "    sorted_runs = sorted(best_checkpoints.items(), key=lambda x: x[1][\"score\"], reverse=True)\n",
    "    top_run_names = {info[\"run_name\"] for _, info in sorted_runs[:top_n]}\n",
    "    top_agent_nums = {name.rsplit(\"_\", 1)[-1] for name in top_run_names}\n",
    "    return df[df[\"run_name\"].apply(lambda x: x.rsplit(\"_\", 1)[-1] in top_agent_nums)]\n",
    "\n",
    "def build_heatmap_grid(df, fric_values, mass_values, metric, total_col=\"total\"):\n",
    "    \"\"\"Build a 2D array of mean rates for the heatmap.\n",
    "    \n",
    "    Returns grid with shape (len(mass_values), len(fric_values)).\n",
    "    Rows = mass (y-axis), Columns = fric (x-axis).\n",
    "    \"\"\"\n",
    "    grid = np.zeros((len(mass_values), len(fric_values)))\n",
    "    for mi, mass in enumerate(mass_values):\n",
    "        for fi, fric in enumerate(fric_values):\n",
    "            subset = df[(df[\"fric_level\"] == fric) & (df[\"mass_level\"] == mass)]\n",
    "            if not subset.empty:\n",
    "                subset = subset.copy()\n",
    "                subset[\"rate\"] = 100 * subset[metric] / subset[total_col]\n",
    "                grid[mi, fi] = subset[\"rate\"].mean()\n",
    "    return grid\n",
    "\n",
    "method_names = list(METHOD_TAGS.keys())\n",
    "n_methods = len(method_names)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(FIGSIZE_PER_METHOD[0] * n_methods, FIGSIZE_PER_METHOD[1]), dpi=DPI)\n",
    "if n_methods == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "norm = mcolors.Normalize(vmin=VMIN, vmax=VMAX)\n",
    "\n",
    "for ax, method_name in zip(axes, method_names):\n",
    "    df = dynamics_data[method_name]\n",
    "    df = filter_top_n_runs(df, best_checkpoints_by_method[method_name], TOP_N_POLICIES)\n",
    "    \n",
    "    grid = build_heatmap_grid(df, FRIC_VALUES, MASS_VALUES, \"success\")\n",
    "    \n",
    "    im = ax.imshow(grid, cmap=CMAP, norm=norm, aspect=\"auto\", origin=\"lower\")\n",
    "    \n",
    "    # Add text annotations\n",
    "    for mi in range(len(MASS_VALUES)):\n",
    "        for fi in range(len(FRIC_VALUES)):\n",
    "            val = grid[mi, fi]\n",
    "            # Use black text on light backgrounds, white on dark\n",
    "            text_color = \"white\" if val < 40 else \"black\"\n",
    "            ax.text(fi, mi, f\"{val:.1f}\", ha=\"center\", va=\"center\",\n",
    "                    fontsize=FONT_CELL, fontweight=\"bold\", color=text_color)\n",
    "    \n",
    "    ax.set_xticks(range(len(FRIC_VALUES)))\n",
    "    ax.set_xticklabels(FRIC_VALUES, fontsize=FONT_TICK)\n",
    "    ax.set_yticks(range(len(MASS_VALUES)))\n",
    "    ax.set_yticklabels(MASS_VALUES, fontsize=FONT_TICK)\n",
    "    ax.set_xlabel(X_LABEL, fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_ylabel(Y_LABEL, fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_title(method_name, fontsize=FONT_TITLE)\n",
    "\n",
    "fig.suptitle(SUPTITLE, fontsize=FONT_SUPTITLE, y=1.02)\n",
    "cbar = fig.colorbar(im, ax=axes, shrink=0.8, pad=0.04)\n",
    "cbar.set_label(\"Success Rate (%)\", fontsize=FONT_COLORBAR)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 5: BREAK RATE HEATMAP (FRICTION x MASS)\n",
    "# ============================================================\n",
    "\n",
    "# Policy Selection\n",
    "TOP_N_POLICIES = None  # Set to integer (e.g., 3) to use top N policies, or None for all\n",
    "\n",
    "# Plot Constants\n",
    "FIGSIZE_PER_METHOD = (5, 4)  # Size per individual heatmap\n",
    "DPI = 150\n",
    "\n",
    "# Font sizes\n",
    "FONT_TITLE = 14\n",
    "FONT_SUPTITLE = 16\n",
    "FONT_AXIS_LABEL = 12\n",
    "FONT_TICK = 10\n",
    "FONT_CELL = 11\n",
    "FONT_COLORBAR = 10\n",
    "\n",
    "# Colormap for break rate: green (low) -> red (high)\n",
    "# Alternative colormaps to try:\n",
    "#   CMAP = \"viridis\"       # Perceptually uniform: purple -> yellow\n",
    "#   CMAP = \"plasma\"        # Perceptually uniform: purple -> yellow (warmer)\n",
    "#   CMAP = \"YlOrRd\"        # Sequential: yellow -> red\n",
    "#   CMAP = \"coolwarm\"      # Diverging: blue -> red\n",
    "#   CMAP = \"RdYlBu_r\"      # Diverging: blue -> red (reversed)\n",
    "CMAP = \"RdYlGn_r\"\n",
    "\n",
    "# Value range for color normalization\n",
    "VMIN = 0\n",
    "VMAX = 100\n",
    "\n",
    "# Labels\n",
    "SUPTITLE = \"Break Rate vs Dynamics Parameters\"\n",
    "X_LABEL = \"Friction\"\n",
    "Y_LABEL = \"Mass\"\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "def filter_top_n_runs(df, best_checkpoints, top_n):\n",
    "    \"\"\"Filter dataframe to only include top N runs by score.\"\"\"\n",
    "    if top_n is None or len(best_checkpoints) <= top_n:\n",
    "        return df\n",
    "    sorted_runs = sorted(best_checkpoints.items(), key=lambda x: x[1][\"score\"], reverse=True)\n",
    "    top_run_names = {info[\"run_name\"] for _, info in sorted_runs[:top_n]}\n",
    "    top_agent_nums = {name.rsplit(\"_\", 1)[-1] for name in top_run_names}\n",
    "    return df[df[\"run_name\"].apply(lambda x: x.rsplit(\"_\", 1)[-1] in top_agent_nums)]\n",
    "\n",
    "def build_heatmap_grid(df, fric_values, mass_values, metric, total_col=\"total\"):\n",
    "    \"\"\"Build a 2D array of mean rates for the heatmap.\n",
    "    \n",
    "    Returns grid with shape (len(mass_values), len(fric_values)).\n",
    "    Rows = mass (y-axis), Columns = fric (x-axis).\n",
    "    \"\"\"\n",
    "    grid = np.zeros((len(mass_values), len(fric_values)))\n",
    "    for mi, mass in enumerate(mass_values):\n",
    "        for fi, fric in enumerate(fric_values):\n",
    "            subset = df[(df[\"fric_level\"] == fric) & (df[\"mass_level\"] == mass)]\n",
    "            if not subset.empty:\n",
    "                subset = subset.copy()\n",
    "                subset[\"rate\"] = 100 * subset[metric] / subset[total_col]\n",
    "                grid[mi, fi] = subset[\"rate\"].mean()\n",
    "    return grid\n",
    "\n",
    "method_names = list(METHOD_TAGS.keys())\n",
    "n_methods = len(method_names)\n",
    "\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(FIGSIZE_PER_METHOD[0] * n_methods, FIGSIZE_PER_METHOD[1]), dpi=DPI)\n",
    "if n_methods == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "norm = mcolors.Normalize(vmin=VMIN, vmax=VMAX)\n",
    "\n",
    "for ax, method_name in zip(axes, method_names):\n",
    "    df = dynamics_data[method_name]\n",
    "    df = filter_top_n_runs(df, best_checkpoints_by_method[method_name], TOP_N_POLICIES)\n",
    "    \n",
    "    grid = build_heatmap_grid(df, FRIC_VALUES, MASS_VALUES, \"breaks\")\n",
    "    \n",
    "    im = ax.imshow(grid, cmap=CMAP, norm=norm, aspect=\"auto\", origin=\"lower\")\n",
    "    \n",
    "    # Add text annotations\n",
    "    for mi in range(len(MASS_VALUES)):\n",
    "        for fi in range(len(FRIC_VALUES)):\n",
    "            val = grid[mi, fi]\n",
    "            # Use black text on light backgrounds, white on dark\n",
    "            text_color = \"white\" if val > 60 else \"black\"\n",
    "            ax.text(fi, mi, f\"{val:.1f}\", ha=\"center\", va=\"center\",\n",
    "                    fontsize=FONT_CELL, fontweight=\"bold\", color=text_color)\n",
    "    \n",
    "    ax.set_xticks(range(len(FRIC_VALUES)))\n",
    "    ax.set_xticklabels(FRIC_VALUES, fontsize=FONT_TICK)\n",
    "    ax.set_yticks(range(len(MASS_VALUES)))\n",
    "    ax.set_yticklabels(MASS_VALUES, fontsize=FONT_TICK)\n",
    "    ax.set_xlabel(X_LABEL, fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_ylabel(Y_LABEL, fontsize=FONT_AXIS_LABEL)\n",
    "    ax.set_title(method_name, fontsize=FONT_TITLE)\n",
    "\n",
    "fig.suptitle(SUPTITLE, fontsize=FONT_SUPTITLE, y=1.02)\n",
    "cbar = fig.colorbar(im, ax=axes, shrink=0.8, pad=0.04)\n",
    "cbar.set_label(\"Break Rate (%)\", fontsize=FONT_COLORBAR)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaaclab_drail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
