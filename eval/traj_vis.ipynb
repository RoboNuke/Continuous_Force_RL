{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a264df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional, Tuple, Union\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "def load_experiment_data(\n",
    "    base_filepath: Union[str, Path],\n",
    "    filename: str,\n",
    "    hybrid_run_ids: List[str],\n",
    "    pose_run_ids: List[str],\n",
    "    verbose: bool = True\n",
    ") -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Load pose and LCLoP (hybrid) experiment data from multiple seeds.\n",
    "    \n",
    "    Loads from: {base_filepath}/{hybrid|pose}/{run_id}/{filename}\n",
    "    \n",
    "    Args:\n",
    "        base_filepath: Base directory containing 'hybrid' and 'pose' subdirectories.\n",
    "        filename: Name of pickle file (e.g., 'traj_2995200.pkl').\n",
    "        hybrid_run_ids: List of run IDs for hybrid/LCLoP experiments (e.g., ['run_1', 'run_2', ...]).\n",
    "        pose_run_ids: List of run IDs for pose control experiments.\n",
    "        verbose: Print summary statistics after loading.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (episode_data, break_events) formatted for plotting functions.\n",
    "    \n",
    "    Example:\n",
    "        episode_data, break_events = load_experiment_data(\n",
    "            base_filepath='/path/to/experiments',\n",
    "            filename='traj_2995200.pkl',\n",
    "            hybrid_run_ids=['seed_0', 'seed_1', 'seed_2', 'seed_3', 'seed_4'],\n",
    "            pose_run_ids=['seed_0', 'seed_1', 'seed_2', 'seed_3', 'seed_4']\n",
    "        )\n",
    "    \"\"\"\n",
    "    base_filepath = Path(base_filepath)\n",
    "    \n",
    "    episode_data = []\n",
    "    break_events = []\n",
    "    \n",
    "    # Track loading stats\n",
    "    load_stats = {\n",
    "        'hybrid': {'loaded': 0, 'failed': []},\n",
    "        'pose': {'loaded': 0, 'failed': []}\n",
    "    }\n",
    "    \n",
    "    # Load hybrid (LCLoP) experiments\n",
    "    for run_id in hybrid_run_ids:\n",
    "        filepath = base_filepath / 'hybrid' / run_id / filename\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                raw_data = pickle.load(f)\n",
    "            \n",
    "            episodes, breaks = _parse_experiment(raw_data, policy='lclop', run_id=run_id)\n",
    "            episode_data.extend(episodes)\n",
    "            break_events.extend(breaks)\n",
    "            load_stats['hybrid']['loaded'] += 1\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            load_stats['hybrid']['failed'].append(str(filepath))\n",
    "        except Exception as e:\n",
    "            load_stats['hybrid']['failed'].append(f\"{filepath}: {e}\")\n",
    "    \n",
    "    # Load pose experiments\n",
    "    for run_id in pose_run_ids:\n",
    "        filepath = base_filepath / 'pose' / run_id / filename\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                raw_data = pickle.load(f)\n",
    "            \n",
    "            episodes, breaks = _parse_experiment(raw_data, policy='pose', run_id=run_id)\n",
    "            episode_data.extend(episodes)\n",
    "            break_events.extend(breaks)\n",
    "            load_stats['pose']['loaded'] += 1\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            load_stats['pose']['failed'].append(str(filepath))\n",
    "        except Exception as e:\n",
    "            load_stats['pose']['failed'].append(f\"{filepath}: {e}\")\n",
    "    \n",
    "    if verbose:\n",
    "        _print_load_summary(episode_data, break_events, load_stats)\n",
    "    \n",
    "    return episode_data, break_events\n",
    "\n",
    "\n",
    "def _parse_experiment(\n",
    "    raw_data: Union[List, Dict],\n",
    "    policy: str,\n",
    "    run_id: str = 'default'\n",
    ") -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Parse raw pickle data into standardized episode format.\n",
    "    \n",
    "    Handles Hunter's format:\n",
    "    {\n",
    "        'trajectories': {'env_0': {...}, 'env_1': {...}, ...},\n",
    "        'metadata': {...}\n",
    "    }\n",
    "    \n",
    "    Also handles other formats for flexibility.\n",
    "    \"\"\"\n",
    "    episodes = []\n",
    "    break_events = []\n",
    "    \n",
    "    # Hunter's format: dict with 'trajectories' key\n",
    "    if isinstance(raw_data, dict) and 'trajectories' in raw_data:\n",
    "        trajectories = raw_data['trajectories']\n",
    "        for env_key, env_data in trajectories.items():\n",
    "            # Extract env index as episode_id\n",
    "            env_idx = int(env_key.replace('env_', ''))\n",
    "            # Create unique episode_id combining run_id and env_idx\n",
    "            episode_id = f\"{run_id}_env_{env_idx}\"\n",
    "            parsed_ep, break_event = _parse_episode(env_data, policy, episode_id, run_id)\n",
    "            episodes.append(parsed_ep)\n",
    "            if break_event is not None:\n",
    "                break_events.append(break_event)\n",
    "        return episodes, break_events\n",
    "    \n",
    "    # Fallback: other formats\n",
    "    if isinstance(raw_data, list):\n",
    "        raw_episodes = raw_data\n",
    "    elif isinstance(raw_data, dict):\n",
    "        if 'episodes' in raw_data:\n",
    "            raw_episodes = raw_data['episodes']\n",
    "        elif 'policy_steps' in raw_data or 'steps' in raw_data:\n",
    "            # Single episode\n",
    "            raw_episodes = [raw_data]\n",
    "        else:\n",
    "            # Dict keyed by episode_id\n",
    "            raw_episodes = list(raw_data.values())\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected data type: {type(raw_data)}\")\n",
    "    \n",
    "    for idx, raw_ep in enumerate(raw_episodes):\n",
    "        episode_id = f\"{run_id}_ep_{idx}\"\n",
    "        parsed_ep, break_event = _parse_episode(raw_ep, policy, episode_id, run_id)\n",
    "        episodes.append(parsed_ep)\n",
    "        if break_event is not None:\n",
    "            break_events.append(break_event)\n",
    "    \n",
    "    return episodes, break_events\n",
    "\n",
    "\n",
    "def _parse_episode(\n",
    "    raw_ep: Dict,\n",
    "    policy: str,\n",
    "    episode_id: str,\n",
    "    run_id: str = 'default'\n",
    ") -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    Parse a single episode into standardized format.\n",
    "    \n",
    "    Hunter's format per env:\n",
    "    {\n",
    "        'policy_steps': [...],\n",
    "        'break_sim_steps': [...] or None,\n",
    "        'hole_pos': [x, y, z],  # optional\n",
    "        'initial_peg_pos': [x, y, z]  # optional\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Get steps - handle Hunter's 'policy_steps' or generic 'steps'\n",
    "    steps = raw_ep.get('policy_steps', raw_ep.get('steps', raw_ep.get('trajectory', [])))\n",
    "    \n",
    "    # Standardize step format\n",
    "    standardized_steps = [_standardize_step(s) for s in steps]\n",
    "    \n",
    "    # Get break sim steps if present (Hunter's format)\n",
    "    break_sim_steps = raw_ep.get('break_sim_steps', None)\n",
    "    \n",
    "    # Infer outcome\n",
    "    outcome = raw_ep.get('outcome', None)\n",
    "    if outcome is None:\n",
    "        outcome = _infer_outcome(standardized_steps, raw_ep, break_sim_steps)\n",
    "    \n",
    "    # Get episode-level position data if available\n",
    "    hole_pos = raw_ep.get('hole_pos', None)\n",
    "    initial_peg_pos = raw_ep.get('initial_peg_pos', None)\n",
    "    \n",
    "    # Convert numpy arrays to lists if needed\n",
    "    if hole_pos is not None and hasattr(hole_pos, 'tolist'):\n",
    "        hole_pos = hole_pos.tolist()\n",
    "    if initial_peg_pos is not None and hasattr(initial_peg_pos, 'tolist'):\n",
    "        initial_peg_pos = initial_peg_pos.tolist()\n",
    "    \n",
    "    parsed_episode = {\n",
    "        'policy': policy,\n",
    "        'episode_id': episode_id,\n",
    "        'run_id': run_id,\n",
    "        'outcome': outcome,\n",
    "        'steps': standardized_steps,\n",
    "        'hole_pos': hole_pos,\n",
    "        'initial_peg_pos': initial_peg_pos,\n",
    "    }\n",
    "    \n",
    "    # Extract break event data if present\n",
    "    break_event = None\n",
    "    if outcome == 'break' and break_sim_steps is not None:\n",
    "        break_event = {\n",
    "            'policy': policy,\n",
    "            'episode_id': episode_id,\n",
    "            'run_id': run_id,\n",
    "            'sim_steps': [_standardize_step(s) for s in break_sim_steps]\n",
    "        }\n",
    "    \n",
    "    return parsed_episode, break_event\n",
    "\n",
    "\n",
    "def _standardize_step(step: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Ensure step dict has all expected fields with correct format.\n",
    "    \n",
    "    Converts numpy arrays to lists, handles missing fields with defaults.\n",
    "    Modify field mappings here if your schema uses different key names.\n",
    "    \"\"\"\n",
    "    # Field mapping: your_key -> standardized_key\n",
    "    field_map = {\n",
    "        'contact_force': ['contact_force', 'force', 'wrench'],\n",
    "        'contact_state': ['contact_state', 'in_contact', 'contact'],\n",
    "        'control_selection': ['control_selection', 'mode_selection', 'selection'],\n",
    "        'control_probability': ['control_probability', 'mode_prob', 'selection_prob'],\n",
    "        'velocity': ['velocity', 'ee_velocity', 'vel'],\n",
    "        'position_error': ['position_error', 'pos_error', 'pos_err'],\n",
    "        'force_error': ['force_error', 'f_error', 'force_err'],\n",
    "        'phase': ['phase'],\n",
    "        'step': ['step', 't', 'timestep'],\n",
    "        'terminated': ['terminated', 'done', 'terminal'],\n",
    "        'rewards': ['rewards', 'reward_components', 'reward_dict'],\n",
    "        'peg_pos': ['peg_pos', 'ee_pos', 'end_effector_pos', 'tcp_pos'],\n",
    "    }\n",
    "    \n",
    "    def get_field(step, candidates, default=None):\n",
    "        for key in candidates:\n",
    "            if key in step:\n",
    "                val = step[key]\n",
    "                # Convert numpy to list for consistency\n",
    "                if hasattr(val, 'tolist'):\n",
    "                    return val.tolist()\n",
    "                return val\n",
    "        return default\n",
    "    \n",
    "    standardized = {\n",
    "        'step': get_field(step, field_map['step'], 0),\n",
    "        'phase': get_field(step, field_map['phase'], 'unknown'),\n",
    "        'contact_force': get_field(step, field_map['contact_force'], [0.0, 0.0, 0.0]),\n",
    "        'contact_state': get_field(step, field_map['contact_state'], [False, False, False]),\n",
    "        'control_selection': get_field(step, field_map['control_selection'], [0, 0, 0]),\n",
    "        'control_probability': get_field(step, field_map['control_probability'], [0.0, 0.0, 0.0]),\n",
    "        'velocity': get_field(step, field_map['velocity'], [0.0, 0.0, 0.0]),\n",
    "        'position_error': get_field(step, field_map['position_error'], [float('nan')] * 3),\n",
    "        'force_error': get_field(step, field_map['force_error'], [float('nan')] * 3),\n",
    "        'terminated': get_field(step, field_map['terminated'], False),\n",
    "        'rewards': get_field(step, field_map['rewards'], {}),\n",
    "        'peg_pos': get_field(step, field_map['peg_pos'], None),\n",
    "    }\n",
    "    \n",
    "    # Preserve any additional fields not in the standard schema\n",
    "    for key, val in step.items():\n",
    "        if key not in standardized:\n",
    "            if hasattr(val, 'tolist'):\n",
    "                standardized[key] = val.tolist()\n",
    "            else:\n",
    "                standardized[key] = val\n",
    "    \n",
    "    return standardized\n",
    "\n",
    "\n",
    "def _infer_outcome(\n",
    "    steps: List[Dict], \n",
    "    raw_ep: Dict,\n",
    "    break_sim_steps: Optional[List] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Infer episode outcome from step data if not explicitly provided.\n",
    "    \n",
    "    Hunter's format:\n",
    "    - break: break_sim_steps is not None\n",
    "    - success: any step has rewards['curr_successes'] > 0\n",
    "    - timeout: otherwise\n",
    "    \"\"\"\n",
    "    # Check for break (has break sim data)\n",
    "    if break_sim_steps is not None:\n",
    "        return 'break'\n",
    "    \n",
    "    # Check for explicit flags in raw episode\n",
    "    if raw_ep.get('success', False):\n",
    "        return 'success'\n",
    "    if raw_ep.get('broken', False) or raw_ep.get('broke', False):\n",
    "        return 'break'\n",
    "    \n",
    "    # Check steps for success indicator (Hunter's format)\n",
    "    for step in steps:\n",
    "        rewards = step.get('rewards', {})\n",
    "        if rewards.get('curr_successes', 0) > 0:\n",
    "            return 'success'\n",
    "        # Also check for break reward as backup\n",
    "        if rewards.get('peg_break', 0) != 0:\n",
    "            return 'break'\n",
    "    \n",
    "    # Default to timeout\n",
    "    return 'timeout'\n",
    "\n",
    "\n",
    "def _print_load_summary(\n",
    "    episode_data: List[Dict], \n",
    "    break_events: List[Dict],\n",
    "    load_stats: Optional[Dict] = None\n",
    ") -> None:\n",
    "    \"\"\"Print summary of loaded data.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DATA LOADING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show loading results if provided\n",
    "    if load_stats:\n",
    "        print(\"\\nFiles loaded:\")\n",
    "        for policy_type in ['hybrid', 'pose']:\n",
    "            stats = load_stats[policy_type]\n",
    "            policy_label = 'lclop' if policy_type == 'hybrid' else 'pose'\n",
    "            print(f\"  {policy_label}: {stats['loaded']} runs loaded\")\n",
    "            if stats['failed']:\n",
    "                print(f\"    Failed to load:\")\n",
    "                for f in stats['failed']:\n",
    "                    print(f\"      - {f}\")\n",
    "    \n",
    "    # Count by policy and outcome\n",
    "    stats = defaultdict(lambda: defaultdict(int))\n",
    "    run_ids_by_policy = defaultdict(set)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        stats[ep['policy']][ep['outcome']] += 1\n",
    "        stats[ep['policy']]['total'] += 1\n",
    "        run_ids_by_policy[ep['policy']].add(ep.get('run_id', 'unknown'))\n",
    "    \n",
    "    for policy in sorted(stats.keys()):\n",
    "        s = stats[policy]\n",
    "        n_runs = len(run_ids_by_policy[policy])\n",
    "        print(f\"\\n{policy.upper()} ({n_runs} runs):\")\n",
    "        print(f\"  Total episodes: {s['total']}\")\n",
    "        for outcome in ['success', 'break', 'timeout']:\n",
    "            count = s.get(outcome, 0)\n",
    "            pct = 100 * count / s['total'] if s['total'] > 0 else 0\n",
    "            print(f\"  {outcome:12s}: {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Break events\n",
    "    break_by_policy = defaultdict(int)\n",
    "    for be in break_events:\n",
    "        break_by_policy[be['policy']] += 1\n",
    "    \n",
    "    print(f\"\\nBreak events with high-res data:\")\n",
    "    for policy, count in sorted(break_by_policy.items()):\n",
    "        print(f\"  {policy}: {count}\")\n",
    "    \n",
    "    # Sample data validation\n",
    "    if episode_data:\n",
    "        sample_ep = episode_data[0]\n",
    "        if sample_ep['steps']:\n",
    "            sample_step = sample_ep['steps'][0]\n",
    "            print(f\"\\nSample step fields: {list(sample_step.keys())}\")\n",
    "    \n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "\n",
    "def load_single_experiment(\n",
    "    path: Union[str, Path],\n",
    "    policy: str,\n",
    "    run_id: str = 'default',\n",
    "    verbose: bool = True\n",
    ") -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Load a single experiment file (convenience wrapper).\n",
    "    \n",
    "    Args:\n",
    "        path: Path to pickle file.\n",
    "        policy: Policy name ('pose' or 'lclop').\n",
    "        run_id: Identifier for this run (used in episode_id).\n",
    "        verbose: Print summary after loading.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (episode_data, break_events).\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    \n",
    "    with open(path, 'rb') as f:\n",
    "        raw_data = pickle.load(f)\n",
    "    \n",
    "    episodes, break_events = _parse_experiment(raw_data, policy, run_id)\n",
    "    \n",
    "    if verbose:\n",
    "        _print_load_summary(episodes, break_events)\n",
    "    \n",
    "    return episodes, break_events\n",
    "\n",
    "\n",
    "def merge_experiments(\n",
    "    *experiment_tuples: Tuple[List[Dict], List[Dict]]\n",
    ") -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Merge multiple (episode_data, break_events) tuples.\n",
    "    \n",
    "    Usage:\n",
    "        pose_data = load_single_experiment('pose.pkl', 'pose')\n",
    "        lclop_data = load_single_experiment('lclop.pkl', 'lclop')\n",
    "        episode_data, break_events = merge_experiments(pose_data, lclop_data)\n",
    "    \"\"\"\n",
    "    all_episodes = []\n",
    "    all_breaks = []\n",
    "    \n",
    "    for episodes, breaks in experiment_tuples:\n",
    "        all_episodes.extend(episodes)\n",
    "        all_breaks.extend(breaks)\n",
    "    \n",
    "    return all_episodes, all_breaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0daae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data, break_events = load_experiment_data(\n",
    "    base_filepath='/home/hunter/traj_data',\n",
    "    filename='traj_2995200.pkl',\n",
    "    hybrid_run_ids=['exublcre','ized9kl1','k71urjeq','q057zww5','xcidy52f'],\n",
    "    pose_run_ids=['fw1aost5', 'tkder8at', 'fm5fzmeg', 'nvrug9gj', 'umb7v274']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec9e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. WHERE DO BREAKS HAPPEN?\n",
    "# =============================================================================\n",
    "\n",
    "def plot_break_count_by_phase(\n",
    "    episode_data: List[Dict],\n",
    "    figsize: Tuple[float, float] = (10, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Bar chart of break counts by phase, grouped by policy.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts with 'policy', 'outcome', and 'steps'.\n",
    "                      Each step must have 'phase' and 'terminated' fields.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Extract phase at termination for break episodes\n",
    "    break_phases = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] != 'break':\n",
    "            continue\n",
    "        \n",
    "        policy = ep['policy']\n",
    "        # Find the step where termination occurred\n",
    "        for step in ep['steps']:\n",
    "            if step['terminated']:\n",
    "                break_phases[policy][step['phase']] += 1\n",
    "                break\n",
    "    \n",
    "    # Build plot data\n",
    "    policies = sorted(break_phases.keys())\n",
    "    phases = ['approaching', 'initial_contact', 'insertion']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    x = np.arange(len(phases))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, policy in enumerate(policies):\n",
    "        counts = [break_phases[policy][phase] for phase in phases]\n",
    "        offset = (i - len(policies)/2 + 0.5) * width\n",
    "        ax.bar(x + offset, counts, width, label=policy)\n",
    "    \n",
    "    ax.set_xlabel('Phase')\n",
    "    ax.set_ylabel('Break Count')\n",
    "    ax.set_title('Break Events by Phase')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(phases)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_break_count_by_mode(\n",
    "    episode_data: List[Dict],\n",
    "    figsize: Tuple[float, float] = (8, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Bar chart of break counts by active Z control mode at break (LCLoP only).\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts. Each step must have 'control_selection'.\n",
    "                      control_selection[2] is Z axis (0=position, 1=force).\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    mode_counts = {'position': 0, 'force': 0}\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] != 'break' or ep['policy'] != 'lclop':\n",
    "            continue\n",
    "        \n",
    "        for step in ep['steps']:\n",
    "            if step['terminated']:\n",
    "                z_mode = step['control_selection'][2]\n",
    "                mode_counts['force' if z_mode else 'position'] += 1\n",
    "                break\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    modes = list(mode_counts.keys())\n",
    "    counts = list(mode_counts.values())\n",
    "    colors = ['#2ecc71', '#e74c3c']  # green for position, red for force\n",
    "    \n",
    "    ax.bar(modes, counts, color=colors)\n",
    "    ax.set_xlabel('Active Z Control Mode at Break')\n",
    "    ax.set_ylabel('Break Count')\n",
    "    ax.set_title('LCLoP Breaks by Z-Axis Control Mode')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    total = sum(counts)\n",
    "    if total > 0:\n",
    "        for i, (mode, count) in enumerate(zip(modes, counts)):\n",
    "            pct = 100 * count / total\n",
    "            ax.annotate(f'{pct:.1f}%', xy=(i, count), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_break_count_by_mode(episode_data)\n",
    "plot_break_count_by_phase(episode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. WHAT'S DIFFERENT ABOUT LCLoP VS POSE CONTROL?\n",
    "# =============================================================================\n",
    "\n",
    "def plot_force_by_phase(\n",
    "    episode_data: List[Dict],\n",
    "    axis: int = 2,  # default to Z\n",
    "    figsize: Tuple[float, float] = (12, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Violin/box plot of contact force magnitude by phase, comparing policies.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts with steps containing 'contact_force'.\n",
    "        axis: Which axis to plot (0=X, 1=Y, 2=Z).\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    axis_names = ['X', 'Y', 'Z']\n",
    "    \n",
    "    # Collect force data by policy and phase\n",
    "    data_rows = []\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        for step in ep['steps']:\n",
    "            force_mag = abs(step['contact_force'][axis])\n",
    "            data_rows.append({\n",
    "                'policy': policy,\n",
    "                'phase': step['phase'],\n",
    "                'force': force_mag\n",
    "            })\n",
    "    \n",
    "    # Convert to arrays for seaborn\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    phase_order = ['approaching', 'initial_contact', 'insertion']\n",
    "    sns.violinplot(\n",
    "        data=df, x='phase', y='force', hue='policy',\n",
    "        order=phase_order, split=True, ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('Phase')\n",
    "    ax.set_ylabel(f'{axis_names[axis]} Force Magnitude (N)')\n",
    "    ax.set_title(f'{axis_names[axis]}-Axis Contact Force by Phase')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_velocity_by_phase(\n",
    "    episode_data: List[Dict],\n",
    "    axis: int = 2,  # default to Z\n",
    "    figsize: Tuple[float, float] = (12, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Violin/box plot of velocity by phase, comparing policies.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts with steps containing 'velocity'.\n",
    "        axis: Which axis to plot (0=X, 1=Y, 2=Z).\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    axis_names = ['X', 'Y', 'Z']\n",
    "    \n",
    "    data_rows = []\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        for step in ep['steps']:\n",
    "            vel = step['velocity'][axis]\n",
    "            data_rows.append({\n",
    "                'policy': policy,\n",
    "                'phase': step['phase'],\n",
    "                'velocity': vel\n",
    "            })\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    phase_order = ['approaching', 'initial_contact', 'insertion']\n",
    "    sns.violinplot(\n",
    "        data=df, x='phase', y='velocity', hue='policy',\n",
    "        order=phase_order, split=True, ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('Phase')\n",
    "    ax.set_ylabel(f'{axis_names[axis]} Velocity (m/s)')\n",
    "    ax.set_title(f'{axis_names[axis]}-Axis Velocity by Phase')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_force_over_depth(\n",
    "    episode_data: List[Dict],\n",
    "    depth_key: str = 'insertion_depth',\n",
    "    num_bins: int = 20,\n",
    "    figsize: Tuple[float, float] = (10, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Line plot of mean Z force vs insertion depth, comparing policies.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts. Steps must contain 'contact_force' \n",
    "                      and a depth metric (default: 'insertion_depth').\n",
    "        depth_key: Key in step dict for insertion depth.\n",
    "        num_bins: Number of depth bins for averaging.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Collect force vs depth by policy\n",
    "    policy_data = defaultdict(lambda: {'depths': [], 'forces': []})\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        for step in ep['steps']:\n",
    "            if step['phase'] == 'insertion':\n",
    "                depth = step.get(depth_key, None)\n",
    "                if depth is not None:\n",
    "                    policy_data[policy]['depths'].append(depth)\n",
    "                    policy_data[policy]['forces'].append(abs(step['contact_force'][2]))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    for policy, data in policy_data.items():\n",
    "        if not data['depths']:\n",
    "            continue\n",
    "        \n",
    "        depths = np.array(data['depths'])\n",
    "        forces = np.array(data['forces'])\n",
    "        \n",
    "        # Bin by depth\n",
    "        depth_min, depth_max = depths.min(), depths.max()\n",
    "        bins = np.linspace(depth_min, depth_max, num_bins + 1)\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "        \n",
    "        bin_indices = np.digitize(depths, bins) - 1\n",
    "        bin_indices = np.clip(bin_indices, 0, num_bins - 1)\n",
    "        \n",
    "        mean_forces = []\n",
    "        std_forces = []\n",
    "        valid_centers = []\n",
    "        \n",
    "        for i in range(num_bins):\n",
    "            mask = bin_indices == i\n",
    "            if mask.sum() > 0:\n",
    "                mean_forces.append(forces[mask].mean())\n",
    "                std_forces.append(forces[mask].std())\n",
    "                valid_centers.append(bin_centers[i])\n",
    "        \n",
    "        mean_forces = np.array(mean_forces)\n",
    "        std_forces = np.array(std_forces)\n",
    "        valid_centers = np.array(valid_centers)\n",
    "        \n",
    "        ax.plot(valid_centers, mean_forces, label=policy, linewidth=2)\n",
    "        ax.fill_between(\n",
    "            valid_centers, \n",
    "            mean_forces - std_forces, \n",
    "            mean_forces + std_forces,\n",
    "            alpha=0.2\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel('Insertion Depth (m)')\n",
    "    ax.set_ylabel('Z Force Magnitude (N)')\n",
    "    ax.set_title('Contact Force Profile During Insertion')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "plot_force_by_phase(episode_data)\n",
    "plot_velocity_by_phase(episode_data)\n",
    "plot_force_over_depth(episode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. WHAT HAPPENS LEADING UP TO BREAKS?\n",
    "# =============================================================================\n",
    "\n",
    "def plot_prebreak_timeseries(\n",
    "    break_events: List[Dict],\n",
    "    figsize: Tuple[float, float] = (14, 10)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Multi-panel overlay of all break events showing Z force, velocity, and mode.\n",
    "    \n",
    "    Args:\n",
    "        break_events: List of break event dicts with 'sim_steps' containing\n",
    "                      high-resolution pre-break data. Each sim_step should have\n",
    "                      'contact_force', 'velocity', 'control_selection'.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=figsize, sharex=True)\n",
    "    \n",
    "    # Color by policy\n",
    "    colors = {'lclop': '#3498db', 'pose': '#e74c3c'}\n",
    "    \n",
    "    for event in break_events:\n",
    "        policy = event['policy']\n",
    "        color = colors.get(policy, '#95a5a6')\n",
    "        sim_steps = event['sim_steps']\n",
    "        \n",
    "        n_steps = len(sim_steps)\n",
    "        t = np.arange(-n_steps, 0)  # negative time = before break\n",
    "        \n",
    "        z_forces = [s['contact_force'][2] for s in sim_steps]\n",
    "        z_vels = [s['velocity'][2] for s in sim_steps]\n",
    "        \n",
    "        # Handle None or missing control_selection\n",
    "        z_modes = []\n",
    "        for s in sim_steps:\n",
    "            sel = s.get('control_selection')\n",
    "            if sel is not None:\n",
    "                z_modes.append(sel[2])\n",
    "            else:\n",
    "                z_modes.append(0)  # default to position control\n",
    "        \n",
    "        axes[0].plot(t, z_forces, color=color, alpha=0.3, linewidth=0.8)\n",
    "        axes[1].plot(t, z_vels, color=color, alpha=0.3, linewidth=0.8)\n",
    "        axes[2].plot(t, z_modes, color=color, alpha=0.3, linewidth=0.8)\n",
    "    \n",
    "    axes[0].set_ylabel('Z Force (N)')\n",
    "    axes[0].set_title('Pre-Break Time Series (All Break Events Overlaid)')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    axes[1].set_ylabel('Z Velocity (m/s)')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    axes[2].set_ylabel('Z Mode (0=pos, 1=force)')\n",
    "    axes[2].set_xlabel('Sim Steps Before Break')\n",
    "    axes[2].set_ylim(-0.1, 1.1)\n",
    "    axes[2].grid(alpha=0.3)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color=c, label=p) for p, c in colors.items()\n",
    "    ]\n",
    "    axes[0].legend(handles=legend_elements, loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_prebreak_summary(\n",
    "    break_events: List[Dict],\n",
    "    figsize: Tuple[float, float] = (14, 8)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Summary statistics of pre-break trajectories: mean ± std across events.\n",
    "    \n",
    "    Args:\n",
    "        break_events: List of break event dicts (same format as plot_prebreak_timeseries)\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Group by policy\n",
    "    policy_traces = defaultdict(lambda: {'forces': [], 'vels': [], 'modes': []})\n",
    "    \n",
    "    for event in break_events:\n",
    "        policy = event['policy']\n",
    "        sim_steps = event['sim_steps']\n",
    "        \n",
    "        forces = [s['contact_force'][2] for s in sim_steps]\n",
    "        vels = [s['velocity'][2] for s in sim_steps]\n",
    "        \n",
    "        # Handle None or missing control_selection\n",
    "        modes = []\n",
    "        for s in sim_steps:\n",
    "            sel = s.get('control_selection')\n",
    "            if sel is not None:\n",
    "                modes.append(sel[2])\n",
    "            else:\n",
    "                modes.append(0)\n",
    "        \n",
    "        policy_traces[policy]['forces'].append(forces)\n",
    "        policy_traces[policy]['vels'].append(vels)\n",
    "        policy_traces[policy]['modes'].append(modes)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=figsize, sharex=True)\n",
    "    colors = {'lclop': '#3498db', 'pose': '#e74c3c'}\n",
    "    \n",
    "    for policy, traces in policy_traces.items():\n",
    "        color = colors.get(policy, '#95a5a6')\n",
    "        \n",
    "        # Align traces to break point (may have different lengths)\n",
    "        # Use shortest length for alignment\n",
    "        min_len = min(len(f) for f in traces['forces'])\n",
    "        \n",
    "        forces = np.array([f[-min_len:] for f in traces['forces']])\n",
    "        vels = np.array([v[-min_len:] for v in traces['vels']])\n",
    "        modes = np.array([m[-min_len:] for m in traces['modes']])\n",
    "        \n",
    "        t = np.arange(-min_len, 0)\n",
    "        \n",
    "        for ax, data, ylabel in zip(\n",
    "            axes,\n",
    "            [forces, vels, modes],\n",
    "            ['Z Force (N)', 'Z Velocity (m/s)', 'Z Mode (force %)']\n",
    "        ):\n",
    "            mean = data.mean(axis=0)\n",
    "            std = data.std(axis=0)\n",
    "            \n",
    "            ax.plot(t, mean, color=color, label=policy, linewidth=2)\n",
    "            ax.fill_between(t, mean - std, mean + std, color=color, alpha=0.2)\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.grid(alpha=0.3)\n",
    "    \n",
    "    axes[0].set_title('Pre-Break Trajectory Statistics (Mean ± Std)')\n",
    "    axes[0].legend()\n",
    "    axes[2].set_xlabel('Sim Steps Before Break')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_velocity_at_contact_comparison(\n",
    "    episode_data: List[Dict],\n",
    "    figsize: Tuple[float, float] = (10, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Histogram comparing Z velocity at initial contact for break vs success episodes.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts. Must have 'outcome' and steps with 'phase'.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    # Collect velocity at contact onset\n",
    "    velocities = defaultdict(list)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        outcome = ep['outcome']\n",
    "        if outcome not in ['success', 'break']:\n",
    "            continue\n",
    "        \n",
    "        # Find first contact step\n",
    "        for i, step in enumerate(ep['steps']):\n",
    "            if step['phase'] == 'initial_contact':\n",
    "                # Get velocity from previous step (just before contact)\n",
    "                if i > 0:\n",
    "                    vel = ep['steps'][i-1]['velocity'][2]\n",
    "                else:\n",
    "                    vel = step['velocity'][2]\n",
    "                velocities[outcome].append(vel)\n",
    "                break\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    colors = {'success': '#2ecc71', 'break': '#e74c3c'}\n",
    "    \n",
    "    for outcome in ['success', 'break']:\n",
    "        if velocities[outcome]:\n",
    "            ax.hist(\n",
    "                velocities[outcome], \n",
    "                bins=30, \n",
    "                alpha=0.6, \n",
    "                label=f'{outcome} (n={len(velocities[outcome])})',\n",
    "                color=colors[outcome]\n",
    "            )\n",
    "    \n",
    "    ax.set_xlabel('Z Velocity at Contact (m/s)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Velocity at Contact Onset: Break vs Success')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_selection_confidence_at_contact(\n",
    "    episode_data: List[Dict],\n",
    "    figsize: Tuple[float, float] = (10, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Histogram of mode selection probability at contact for break vs success.\n",
    "    \n",
    "    Tests hypothesis: uncertain selection (prob near 0.5) correlates with breaks.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts. Steps must have 'control_probability'.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    probabilities = defaultdict(list)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['policy'] != 'lclop':\n",
    "            continue\n",
    "        \n",
    "        outcome = ep['outcome']\n",
    "        if outcome not in ['success', 'break']:\n",
    "            continue\n",
    "        \n",
    "        # Find first contact step\n",
    "        for step in ep['steps']:\n",
    "            if step['phase'] == 'initial_contact':\n",
    "                z_prob = step['control_probability'][2]\n",
    "                probabilities[outcome].append(z_prob)\n",
    "                break\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    colors = {'success': '#2ecc71', 'break': '#e74c3c'}\n",
    "    \n",
    "    for outcome in ['success', 'break']:\n",
    "        if probabilities[outcome]:\n",
    "            ax.hist(\n",
    "                probabilities[outcome], \n",
    "                bins=20, \n",
    "                alpha=0.6, \n",
    "                label=f'{outcome} (n={len(probabilities[outcome])})',\n",
    "                color=colors[outcome],\n",
    "                range=(0, 1)\n",
    "            )\n",
    "    \n",
    "    ax.axvline(0.5, color='black', linestyle='--', alpha=0.5, label='Max uncertainty')\n",
    "    ax.set_xlabel('Z Mode Selection Probability (force)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Selection Confidence at Contact: Break vs Success (LCLoP)')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "plot_prebreak_timeseries(break_events)\n",
    "plot_prebreak_summary(break_events)\n",
    "plot_velocity_at_contact_comparison(episode_data)\n",
    "plot_selection_confidence_at_contact(episode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3b. PHASE TRAJECTORY ANALYSIS\n",
    "# =============================================================================\n",
    "def compute_trajectory_variable(\n",
    "    step: Dict,\n",
    "    var_name: str,\n",
    "    hole_pos: Optional[List[float]] = None,\n",
    "    peg_pos: Optional[List[float]] = None,\n",
    "    filter_contact: bool = False\n",
    ") -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Compute a derived variable from step data.\n",
    "    \n",
    "    Supported variables:\n",
    "        Positional (requires hole_pos in episode):\n",
    "            'plane-dist': XY distance from peg to hole\n",
    "            'z-dist': Z distance from peg to hole (signed)\n",
    "            'z-dist-abs': Absolute Z distance\n",
    "        \n",
    "        Velocity:\n",
    "            'plane-vel': XY velocity magnitude\n",
    "            'z-vel': Z velocity (signed, negative = downward)\n",
    "        \n",
    "        Force:\n",
    "            'plane-force': XY force magnitude\n",
    "            'z-force': Z force (signed)\n",
    "            'z-force-abs': Absolute Z force\n",
    "        \n",
    "        Position error:\n",
    "            'plane-pos-error': XY position error magnitude\n",
    "            'z-pos-error': Z position error\n",
    "        \n",
    "        Force error:\n",
    "            'plane-force-error': XY force error magnitude  \n",
    "            'z-force-error': Z force error\n",
    "        \n",
    "        Control:\n",
    "            'z-mode': Z control mode (0=pos, 1=force)\n",
    "            'z-mode-prob': Z force mode probability\n",
    "    \n",
    "    Args:\n",
    "        step: Step dict with standard fields\n",
    "        var_name: Name of variable to compute\n",
    "        hole_pos: [x, y, z] position of hole (from episode data)\n",
    "        peg_pos: [x, y, z] current peg position (from step, if available)\n",
    "        filter_contact: If True, return None for steps where contact is detected\n",
    "                        on relevant axes (z for z-*, xy for plane-*)\n",
    "    \n",
    "    Returns:\n",
    "        Computed value or None if not computable\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check contact filtering\n",
    "        if filter_contact:\n",
    "            contact_state = step.get('contact_state', [False, False, False])\n",
    "            if contact_state is None:\n",
    "                contact_state = [False, False, False]\n",
    "            \n",
    "            # Determine which axes matter for this variable\n",
    "            if var_name.startswith('z-'):\n",
    "                # Z variables - filter if Z contact\n",
    "                if contact_state[2]:\n",
    "                    return None\n",
    "            elif var_name.startswith('plane-'):\n",
    "                # Plane variables - filter if X or Y contact\n",
    "                if contact_state[0] or contact_state[1]:\n",
    "                    return None\n",
    "        \n",
    "        if var_name == 'plane-dist':\n",
    "            if hole_pos is None or peg_pos is None:\n",
    "                return None\n",
    "            dx = peg_pos[0] - hole_pos[0]\n",
    "            dy = peg_pos[1] - hole_pos[1]\n",
    "            return np.sqrt(dx**2 + dy**2)\n",
    "        \n",
    "        elif var_name == 'z-dist':\n",
    "            if hole_pos is None or peg_pos is None:\n",
    "                return None\n",
    "            return peg_pos[2] - hole_pos[2]\n",
    "        \n",
    "        elif var_name == 'z-dist-abs':\n",
    "            if hole_pos is None or peg_pos is None:\n",
    "                return None\n",
    "            return abs(peg_pos[2] - hole_pos[2])\n",
    "        \n",
    "        elif var_name == 'plane-vel':\n",
    "            vel = step.get('velocity')\n",
    "            if vel is None:\n",
    "                return None\n",
    "            return np.sqrt(vel[0]**2 + vel[1]**2)\n",
    "        \n",
    "        elif var_name == 'z-vel':\n",
    "            vel = step.get('velocity')\n",
    "            if vel is None:\n",
    "                return None\n",
    "            return vel[2]\n",
    "        \n",
    "        elif var_name == 'plane-force':\n",
    "            force = step.get('contact_force')\n",
    "            if force is None:\n",
    "                return None\n",
    "            return np.sqrt(force[0]**2 + force[1]**2)\n",
    "        \n",
    "        elif var_name == 'z-force':\n",
    "            force = step.get('contact_force')\n",
    "            if force is None:\n",
    "                return None\n",
    "            return force[2]\n",
    "        \n",
    "        elif var_name == 'z-force-abs':\n",
    "            force = step.get('contact_force')\n",
    "            if force is None:\n",
    "                return None\n",
    "            return abs(force[2])\n",
    "        \n",
    "        elif var_name == 'plane-pos-error':\n",
    "            err = step.get('position_error')\n",
    "            if err is None:\n",
    "                return None\n",
    "            return np.sqrt(err[0]**2 + err[1]**2)\n",
    "        \n",
    "        elif var_name == 'z-pos-error':\n",
    "            err = step.get('position_error')\n",
    "            if err is None:\n",
    "                return None\n",
    "            return err[2]\n",
    "        \n",
    "        elif var_name == 'plane-force-error':\n",
    "            err = step.get('force_error')\n",
    "            if err is None:\n",
    "                return None\n",
    "            return np.sqrt(err[0]**2 + err[1]**2)\n",
    "        \n",
    "        elif var_name == 'z-force-error':\n",
    "            err = step.get('force_error')\n",
    "            if err is None:\n",
    "                return None\n",
    "            return err[2]\n",
    "        \n",
    "        elif var_name == 'z-mode':\n",
    "            sel = step.get('control_selection')\n",
    "            if sel is None:\n",
    "                return None\n",
    "            return sel[2]\n",
    "        \n",
    "        elif var_name == 'z-mode-prob':\n",
    "            prob = step.get('control_probability')\n",
    "            if prob is None:\n",
    "                return None\n",
    "            return prob[2]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown variable: {var_name}\")\n",
    "    \n",
    "    except (IndexError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def plot_phase_trajectories(\n",
    "    episode_data: List[Dict],\n",
    "    phase: str,\n",
    "    variables: List[str],\n",
    "    filter_contact: bool = False,\n",
    "    figsize: Tuple[float, float] = None,\n",
    "    alpha: float = 0.3,\n",
    "    max_trajectories: int = 100\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot all trajectories for specified variables within a phase.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts. Episodes should have 'hole_pos' field\n",
    "                      if using distance variables. Steps should have 'peg_pos' field.\n",
    "        phase: Phase to filter (\"approaching\", \"initial_contact\", \"insertion\")\n",
    "        variables: List of variable names to plot (see compute_trajectory_variable)\n",
    "        filter_contact: If True, exclude timesteps where contact is detected on\n",
    "                        relevant axes (z for z-*, xy for plane-*)\n",
    "        figsize: Figure size (auto-calculated if None)\n",
    "        alpha: Transparency for trajectory lines\n",
    "        max_trajectories: Max trajectories per policy to plot (for performance)\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    n_vars = len(variables)\n",
    "    if figsize is None:\n",
    "        figsize = (14, 4 * n_vars)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_vars, 1, figsize=figsize, sharex=True)\n",
    "    if n_vars == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = {'lclop': '#3498db', 'pose': '#e74c3c'}\n",
    "    \n",
    "    # Track trajectory counts per policy\n",
    "    traj_counts = defaultdict(int)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        \n",
    "        # Limit trajectories for performance\n",
    "        if traj_counts[policy] >= max_trajectories:\n",
    "            continue\n",
    "        \n",
    "        # Get hole position if available\n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        \n",
    "        # Extract steps in the desired phase\n",
    "        phase_steps = []\n",
    "        for step in ep['steps']:\n",
    "            if step.get('phase') == phase:\n",
    "                phase_steps.append(step)\n",
    "        \n",
    "        if not phase_steps:\n",
    "            continue\n",
    "        \n",
    "        traj_counts[policy] += 1\n",
    "        color = colors.get(policy, '#95a5a6')\n",
    "        \n",
    "        # Time axis: steps since phase entry\n",
    "        t = np.arange(len(phase_steps))\n",
    "        \n",
    "        # Plot each variable\n",
    "        for ax, var_name in zip(axes, variables):\n",
    "            values = []\n",
    "            for step in phase_steps:\n",
    "                peg_pos = step.get('peg_pos')\n",
    "                val = compute_trajectory_variable(step, var_name, hole_pos, peg_pos, filter_contact)\n",
    "                values.append(val)\n",
    "            \n",
    "            # Filter out None values for plotting\n",
    "            valid_t = [ti for ti, v in zip(t, values) if v is not None]\n",
    "            valid_v = [v for v in values if v is not None]\n",
    "            \n",
    "            if valid_v:\n",
    "                ax.plot(valid_t, valid_v, color=color, alpha=alpha, linewidth=0.8)\n",
    "    \n",
    "    # Format axes\n",
    "    for ax, var_name in zip(axes, variables):\n",
    "        ax.set_ylabel(var_name)\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    title_suffix = ' (no-contact only)' if filter_contact else ''\n",
    "    axes[0].set_title(f'Trajectories During \"{phase}\" Phase{title_suffix}')\n",
    "    axes[-1].set_xlabel('Steps Since Phase Entry')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color=c, label=f'{p} (n={traj_counts[p]})') \n",
    "        for p, c in colors.items() if traj_counts[p] > 0\n",
    "    ]\n",
    "    axes[0].legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_phase_trajectories_summary(\n",
    "    episode_data: List[Dict],\n",
    "    phase: str,\n",
    "    variables: List[str],\n",
    "    normalize_time: bool = False,\n",
    "    n_points: int = 100,\n",
    "    filter_contact: bool = False,\n",
    "    figsize: Tuple[float, float] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot mean ± std trajectories for specified variables within a phase.\n",
    "    \n",
    "    Like plot_phase_trajectories but shows aggregated statistics instead of\n",
    "    individual trajectories.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        phase: Phase to filter\n",
    "        variables: List of variable names to plot\n",
    "        normalize_time: If True, interpolate all trajectories to 0-100% phase completion.\n",
    "                        If False, use raw step counts with NaN padding for shorter trajectories.\n",
    "        n_points: Number of points to interpolate to when normalize_time=True\n",
    "        filter_contact: If True, exclude timesteps where contact is detected on\n",
    "                        relevant axes (z for z-*, xy for plane-*)\n",
    "        figsize: Figure size (auto-calculated if None)\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    n_vars = len(variables)\n",
    "    if figsize is None:\n",
    "        figsize = (14, 4 * n_vars)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_vars, 1, figsize=figsize, sharex=True)\n",
    "    if n_vars == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = {'lclop': '#3498db', 'pose': '#e74c3c'}\n",
    "    \n",
    "    # Collect trajectories by policy\n",
    "    policy_trajectories = defaultdict(lambda: {var: [] for var in variables})\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        \n",
    "        # Extract steps in the desired phase\n",
    "        phase_steps = [s for s in ep['steps'] if s.get('phase') == phase]\n",
    "        \n",
    "        if not phase_steps:\n",
    "            continue\n",
    "        \n",
    "        # Compute each variable\n",
    "        for var_name in variables:\n",
    "            values = []\n",
    "            for step in phase_steps:\n",
    "                peg_pos = step.get('peg_pos')\n",
    "                val = compute_trajectory_variable(step, var_name, hole_pos, peg_pos, filter_contact)\n",
    "                values.append(val if val is not None else np.nan)\n",
    "            \n",
    "            policy_trajectories[policy][var_name].append(values)\n",
    "    \n",
    "    # Plot mean ± std for each policy\n",
    "    for policy, var_trajs in policy_trajectories.items():\n",
    "        color = colors.get(policy, '#95a5a6')\n",
    "        n_trajs = len(var_trajs[variables[0]]) if variables else 0\n",
    "        \n",
    "        for ax, var_name in zip(axes, variables):\n",
    "            trajs = var_trajs[var_name]\n",
    "            if not trajs:\n",
    "                continue\n",
    "            \n",
    "            if normalize_time:\n",
    "                # Interpolate all trajectories to common 0-100% scale\n",
    "                t_norm = np.linspace(0, 100, n_points)\n",
    "                interpolated = []\n",
    "                \n",
    "                for traj in trajs:\n",
    "                    if len(traj) < 2:\n",
    "                        continue\n",
    "                    # Original time as percentage\n",
    "                    t_orig = np.linspace(0, 100, len(traj))\n",
    "                    # Interpolate (handle NaN by interpolating only valid segments)\n",
    "                    traj_arr = np.array(traj)\n",
    "                    valid_mask = ~np.isnan(traj_arr)\n",
    "                    if valid_mask.sum() < 2:\n",
    "                        continue\n",
    "                    # Simple linear interpolation\n",
    "                    interp_vals = np.interp(t_norm, t_orig, traj_arr, left=np.nan, right=np.nan)\n",
    "                    interpolated.append(interp_vals)\n",
    "                \n",
    "                if not interpolated:\n",
    "                    continue\n",
    "                \n",
    "                aligned = np.array(interpolated)\n",
    "                t = t_norm\n",
    "                xlabel = 'Phase Completion (%)'\n",
    "            else:\n",
    "                # Pad shorter trajectories with NaN to match longest\n",
    "                max_len = max(len(tr) for tr in trajs)\n",
    "                aligned = np.full((len(trajs), max_len), np.nan)\n",
    "                for i, tr in enumerate(trajs):\n",
    "                    aligned[i, :len(tr)] = tr\n",
    "                \n",
    "                t = np.arange(max_len)\n",
    "                xlabel = 'Steps Since Phase Entry'\n",
    "            \n",
    "            # Compute stats (ignoring NaN)\n",
    "            with np.errstate(all='ignore'):\n",
    "                mean = np.nanmean(aligned, axis=0)\n",
    "                std = np.nanstd(aligned, axis=0)\n",
    "                # Count non-NaN values at each timestep for transparency\n",
    "                count = np.sum(~np.isnan(aligned), axis=0)\n",
    "            \n",
    "            # Plot mean line\n",
    "            ax.plot(t, mean, color=color, label=f'{policy} (n={n_trajs})', linewidth=2)\n",
    "            \n",
    "            # Plot std band with alpha based on sample count\n",
    "            # More transparent where fewer trajectories contribute\n",
    "            if not normalize_time:\n",
    "                # Variable alpha based on how many trajectories contribute\n",
    "                max_count = count.max()\n",
    "                for i in range(len(t) - 1):\n",
    "                    alpha = 0.3 * (count[i] / max_count) if max_count > 0 else 0.1\n",
    "                    ax.fill_between(\n",
    "                        t[i:i+2], \n",
    "                        (mean - std)[i:i+2], \n",
    "                        (mean + std)[i:i+2], \n",
    "                        color=color, \n",
    "                        alpha=alpha,\n",
    "                        linewidth=0\n",
    "                    )\n",
    "            else:\n",
    "                ax.fill_between(t, mean - std, mean + std, color=color, alpha=0.2)\n",
    "    \n",
    "    # Format axes\n",
    "    for ax, var_name in zip(axes, variables):\n",
    "        ax.set_ylabel(var_name)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.legend()\n",
    "    \n",
    "    title_suffix = ' (Normalized Time)' if normalize_time else ' (Raw Steps)'\n",
    "    if filter_contact:\n",
    "        title_suffix += ' (no-contact only)'\n",
    "    axes[0].set_title(f'Trajectory Statistics During \"{phase}\" Phase{title_suffix}')\n",
    "    axes[-1].set_xlabel('Phase Completion (%)' if normalize_time else 'Steps Since Phase Entry')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_full_trajectories(\n",
    "    episode_data: List[Dict],\n",
    "    variables: List[str],\n",
    "    outcomes: List[str] = None,\n",
    "    filter_contact: bool = False,\n",
    "    figsize: Tuple[float, float] = None,\n",
    "    alpha: float = 0.3,\n",
    "    max_trajectories_per_group: int = 50\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot all full trajectories (not filtered by phase), colored by policy and outcome.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        variables: List of variable names to plot\n",
    "        outcomes: List of outcomes to include (default: ['success', 'break'])\n",
    "        filter_contact: If True, exclude timesteps where contact is detected on\n",
    "                        relevant axes (z for z-*, xy for plane-*)\n",
    "        figsize: Figure size (auto-calculated if None)\n",
    "        alpha: Transparency for trajectory lines\n",
    "        max_trajectories_per_group: Max trajectories per policy+outcome combo\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    if outcomes is None:\n",
    "        outcomes = ['success', 'break']\n",
    "    \n",
    "    n_vars = len(variables)\n",
    "    if figsize is None:\n",
    "        figsize = (14, 4 * n_vars)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_vars, 1, figsize=figsize, sharex=True)\n",
    "    if n_vars == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Color scheme: policy determines hue, outcome determines shade\n",
    "    color_map = {\n",
    "        ('lclop', 'success'): '#3498db',    # blue\n",
    "        ('lclop', 'break'): '#1a5276',      # dark blue\n",
    "        ('lclop', 'timeout'): '#85c1e9',    # light blue\n",
    "        ('pose', 'success'): '#e74c3c',     # red\n",
    "        ('pose', 'break'): '#922b21',       # dark red\n",
    "        ('pose', 'timeout'): '#f1948a',     # light red\n",
    "    }\n",
    "    \n",
    "    # Track counts per group\n",
    "    group_counts = defaultdict(int)\n",
    "    plotted_counts = defaultdict(int)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        outcome = ep['outcome']\n",
    "        \n",
    "        if outcome not in outcomes:\n",
    "            continue\n",
    "        \n",
    "        group_key = (policy, outcome)\n",
    "        group_counts[group_key] += 1\n",
    "        \n",
    "        if plotted_counts[group_key] >= max_trajectories_per_group:\n",
    "            continue\n",
    "        \n",
    "        plotted_counts[group_key] += 1\n",
    "        \n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        steps = ep['steps']\n",
    "        \n",
    "        if not steps:\n",
    "            continue\n",
    "        \n",
    "        color = color_map.get(group_key, '#95a5a6')\n",
    "        t = np.arange(len(steps))\n",
    "        \n",
    "        for ax, var_name in zip(axes, variables):\n",
    "            values = []\n",
    "            for step in steps:\n",
    "                peg_pos = step.get('peg_pos')\n",
    "                val = compute_trajectory_variable(step, var_name, hole_pos, peg_pos, filter_contact)\n",
    "                values.append(val)\n",
    "            \n",
    "            valid_t = [ti for ti, v in zip(t, values) if v is not None]\n",
    "            valid_v = [v for v in values if v is not None]\n",
    "            \n",
    "            if valid_v:\n",
    "                ax.plot(valid_t, valid_v, color=color, alpha=alpha, linewidth=0.8)\n",
    "    \n",
    "    # Format axes\n",
    "    for ax, var_name in zip(axes, variables):\n",
    "        ax.set_ylabel(var_name)\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    title_suffix = ' (no-contact only)' if filter_contact else ''\n",
    "    axes[0].set_title(f'Full Trajectories by Policy and Outcome{title_suffix}')\n",
    "    axes[-1].set_xlabel('Step')\n",
    "    \n",
    "    # Build legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = []\n",
    "    for (policy, outcome), count in sorted(group_counts.items()):\n",
    "        if outcome in outcomes:\n",
    "            color = color_map.get((policy, outcome), '#95a5a6')\n",
    "            label = f'{policy}/{outcome} (n={count})'\n",
    "            legend_elements.append(Line2D([0], [0], color=color, label=label))\n",
    "    \n",
    "    axes[0].legend(handles=legend_elements, loc='upper right', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_full_trajectories_summary(\n",
    "    episode_data: List[Dict],\n",
    "    variables: List[str],\n",
    "    outcomes: List[str] = None,\n",
    "    normalize_time: bool = False,\n",
    "    n_points: int = 100,\n",
    "    split_by_outcome: bool = True,\n",
    "    filter_contact: bool = False,\n",
    "    figsize: Tuple[float, float] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot mean ± std for full trajectories, with options to split by outcome.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        variables: List of variable names to plot\n",
    "        outcomes: List of outcomes to include (default: ['success', 'break'])\n",
    "        normalize_time: If True, interpolate to 0-100% episode completion\n",
    "        n_points: Interpolation resolution when normalize_time=True\n",
    "        split_by_outcome: If True, separate lines for each policy+outcome combo.\n",
    "                          If False, aggregate all outcomes per policy.\n",
    "        filter_contact: If True, exclude timesteps where contact is detected on\n",
    "                        relevant axes (z for z-*, xy for plane-*)\n",
    "        figsize: Figure size (auto-calculated if None)\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    if outcomes is None:\n",
    "        outcomes = ['success', 'break']\n",
    "    \n",
    "    n_vars = len(variables)\n",
    "    if figsize is None:\n",
    "        figsize = (14, 4 * n_vars)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_vars, 1, figsize=figsize, sharex=True)\n",
    "    if n_vars == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Color and style scheme\n",
    "    if split_by_outcome:\n",
    "        color_map = {\n",
    "            ('lclop', 'success'): ('#3498db', '-'),     # blue solid\n",
    "            ('lclop', 'break'): ('#3498db', '--'),      # blue dashed\n",
    "            ('lclop', 'timeout'): ('#3498db', ':'),     # blue dotted\n",
    "            ('pose', 'success'): ('#e74c3c', '-'),      # red solid\n",
    "            ('pose', 'break'): ('#e74c3c', '--'),       # red dashed\n",
    "            ('pose', 'timeout'): ('#e74c3c', ':'),      # red dotted\n",
    "        }\n",
    "    else:\n",
    "        color_map = {\n",
    "            'lclop': ('#3498db', '-'),\n",
    "            'pose': ('#e74c3c', '-'),\n",
    "        }\n",
    "    \n",
    "    # Collect trajectories\n",
    "    if split_by_outcome:\n",
    "        trajectory_groups = defaultdict(lambda: {var: [] for var in variables})\n",
    "        group_key_fn = lambda ep: (ep['policy'], ep['outcome'])\n",
    "    else:\n",
    "        trajectory_groups = defaultdict(lambda: {var: [] for var in variables})\n",
    "        group_key_fn = lambda ep: ep['policy']\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['outcome'] not in outcomes:\n",
    "            continue\n",
    "        \n",
    "        group_key = group_key_fn(ep)\n",
    "        hole_pos = ep.get('hole_pos')\n",
    "        steps = ep['steps']\n",
    "        \n",
    "        if not steps:\n",
    "            continue\n",
    "        \n",
    "        for var_name in variables:\n",
    "            values = []\n",
    "            for step in steps:\n",
    "                peg_pos = step.get('peg_pos')\n",
    "                val = compute_trajectory_variable(step, var_name, hole_pos, peg_pos, filter_contact)\n",
    "                values.append(val if val is not None else np.nan)\n",
    "            \n",
    "            trajectory_groups[group_key][var_name].append(values)\n",
    "    \n",
    "    # Plot each group\n",
    "    for group_key, var_trajs in trajectory_groups.items():\n",
    "        if split_by_outcome:\n",
    "            color, linestyle = color_map.get(group_key, ('#95a5a6', '-'))\n",
    "            label_base = f'{group_key[0]}/{group_key[1]}'\n",
    "        else:\n",
    "            color, linestyle = color_map.get(group_key, ('#95a5a6', '-'))\n",
    "            label_base = group_key\n",
    "        \n",
    "        n_trajs = len(var_trajs[variables[0]]) if variables else 0\n",
    "        \n",
    "        for ax, var_name in zip(axes, variables):\n",
    "            trajs = var_trajs[var_name]\n",
    "            if not trajs:\n",
    "                continue\n",
    "            \n",
    "            if normalize_time:\n",
    "                t_norm = np.linspace(0, 100, n_points)\n",
    "                interpolated = []\n",
    "                \n",
    "                for traj in trajs:\n",
    "                    if len(traj) < 2:\n",
    "                        continue\n",
    "                    t_orig = np.linspace(0, 100, len(traj))\n",
    "                    traj_arr = np.array(traj)\n",
    "                    valid_mask = ~np.isnan(traj_arr)\n",
    "                    if valid_mask.sum() < 2:\n",
    "                        continue\n",
    "                    interp_vals = np.interp(t_norm, t_orig, traj_arr, left=np.nan, right=np.nan)\n",
    "                    interpolated.append(interp_vals)\n",
    "                \n",
    "                if not interpolated:\n",
    "                    continue\n",
    "                \n",
    "                aligned = np.array(interpolated)\n",
    "                t = t_norm\n",
    "            else:\n",
    "                max_len = max(len(tr) for tr in trajs)\n",
    "                aligned = np.full((len(trajs), max_len), np.nan)\n",
    "                for i, tr in enumerate(trajs):\n",
    "                    aligned[i, :len(tr)] = tr\n",
    "                t = np.arange(max_len)\n",
    "            \n",
    "            with np.errstate(all='ignore'):\n",
    "                mean = np.nanmean(aligned, axis=0)\n",
    "                std = np.nanstd(aligned, axis=0)\n",
    "                count = np.sum(~np.isnan(aligned), axis=0)\n",
    "            \n",
    "            ax.plot(t, mean, color=color, linestyle=linestyle, \n",
    "                    label=f'{label_base} (n={n_trajs})', linewidth=2)\n",
    "            \n",
    "            if not normalize_time:\n",
    "                max_count = count.max() if count.max() > 0 else 1\n",
    "                for i in range(len(t) - 1):\n",
    "                    alpha = 0.3 * (count[i] / max_count)\n",
    "                    ax.fill_between(\n",
    "                        t[i:i+2],\n",
    "                        (mean - std)[i:i+2],\n",
    "                        (mean + std)[i:i+2],\n",
    "                        color=color,\n",
    "                        alpha=alpha,\n",
    "                        linewidth=0\n",
    "                    )\n",
    "            else:\n",
    "                ax.fill_between(t, mean - std, mean + std, color=color, alpha=0.15)\n",
    "    \n",
    "    # Format axes\n",
    "    for ax, var_name in zip(axes, variables):\n",
    "        ax.set_ylabel(var_name)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.legend(fontsize=8)\n",
    "    \n",
    "    title_suffix = ' (Normalized Time)' if normalize_time else ' (Raw Steps)'\n",
    "    if filter_contact:\n",
    "        title_suffix += ' (no-contact only)'\n",
    "    axes[0].set_title(f'Full Trajectory Statistics by Policy/Outcome{title_suffix}')\n",
    "    axes[-1].set_xlabel('Episode Completion (%)' if normalize_time else 'Step')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# motion stats\n",
    "var_groups = [\n",
    "    ['z-dist','z-vel','z-pos-error','plane-dist','plane-vel','plane-pos-error'],\n",
    "    ['z-force','z-force-error', 'plane-force', 'plane-force-error']\n",
    "]\n",
    "\n",
    "for group in var_groups:\n",
    "    plot_full_trajectories_summary(\n",
    "        episode_data,\n",
    "        variables=group,\n",
    "        outcomes=['success', 'break'],\n",
    "        split_by_outcome=True,    # separate lines for success/break\n",
    "        normalize_time=True       # 0-100% episode completion\n",
    "    )\n",
    "    #for phase in ['approaching','initial_contact','insertion']:\n",
    "        #plot_phase_trajectories(\n",
    "        #    episode_data,\n",
    "        #    phase=phase,\n",
    "        #    variables=group\n",
    "        #)\n",
    "        #plot_phase_trajectories_summary(\n",
    "        #    episode_data,\n",
    "        #    phase=phase,\n",
    "        #    variables=group,\n",
    "        #    outcomes=['success', 'break'],\n",
    "        #    normalize_time=True\n",
    "        #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b84bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. IS FORCE CONTROL ACTUALLY WORKING?\n",
    "# =============================================================================\n",
    "\n",
    "def plot_force_tracking(\n",
    "    episode_data: List[Dict],\n",
    "    figsize: Tuple[float, float] = (10, 8)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Scatter plot of commanded vs actual Z force when force mode is active.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts. Steps must have 'force_error' and\n",
    "                      'contact_force'. Assumes commanded = actual + error.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    commanded = []\n",
    "    actual = []\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['policy'] != 'lclop':\n",
    "            continue\n",
    "        \n",
    "        for step in ep['steps']:\n",
    "            if step['control_selection'][2] == 1:  # force mode active on Z\n",
    "                force_error = step['force_error'][2]\n",
    "                actual_force = step['contact_force'][2]\n",
    "                \n",
    "                if not np.isnan(force_error):\n",
    "                    commanded.append(actual_force + force_error)\n",
    "                    actual.append(actual_force)\n",
    "    \n",
    "    if not commanded:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.text(0.5, 0.5, 'No force control data available', \n",
    "                ha='center', va='center', transform=ax.transAxes)\n",
    "        return fig\n",
    "    \n",
    "    commanded = np.array(commanded)\n",
    "    actual = np.array(actual)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=figsize)\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(commanded, actual, alpha=0.3, s=5)\n",
    "    \n",
    "    # Perfect tracking line\n",
    "    lims = [\n",
    "        min(commanded.min(), actual.min()),\n",
    "        max(commanded.max(), actual.max())\n",
    "    ]\n",
    "    axes[0].plot(lims, lims, 'r--', label='Perfect tracking')\n",
    "    axes[0].set_xlabel('Commanded Z Force (N)')\n",
    "    axes[0].set_ylabel('Actual Z Force (N)')\n",
    "    axes[0].set_title('Force Controller Tracking Quality')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Error histogram\n",
    "    errors = actual - commanded\n",
    "    axes[1].hist(errors, bins=50, alpha=0.7)\n",
    "    axes[1].axvline(0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1].axvline(errors.mean(), color='g', linestyle='-', \n",
    "                    label=f'Mean error: {errors.mean():.3f} N')\n",
    "    axes[1].set_xlabel('Tracking Error (N)')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title(f'Force Tracking Error Distribution (std={errors.std():.3f} N)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_force_error_timeseries(\n",
    "    episode_data: List[Dict],\n",
    "    max_episodes: int = 20,\n",
    "    figsize: Tuple[float, float] = (12, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Time series of force tracking error during insertion phase.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts.\n",
    "        max_episodes: Maximum number of episodes to overlay.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    episode_count = 0\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        if ep['policy'] != 'lclop':\n",
    "            continue\n",
    "        if episode_count >= max_episodes:\n",
    "            break\n",
    "        \n",
    "        errors = []\n",
    "        for step in ep['steps']:\n",
    "            if step['phase'] == 'insertion' and step['control_selection'][2] == 1:\n",
    "                err = step['force_error'][2]\n",
    "                if not np.isnan(err):\n",
    "                    errors.append(err)\n",
    "        \n",
    "        if errors:\n",
    "            ax.plot(errors, alpha=0.4, linewidth=0.8)\n",
    "            episode_count += 1\n",
    "    \n",
    "    ax.axhline(0, color='r', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Steps in Force Control Mode (during insertion)')\n",
    "    ax.set_ylabel('Z Force Tracking Error (N)')\n",
    "    ax.set_title('Force Tracking Error During Insertion')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_force_tracking(episode_data)\n",
    "plot_force_error_timeseries(episode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def generate_all_diagnostics(\n",
    "    episode_data: List[Dict],\n",
    "    break_events: List[Dict],\n",
    "    output_dir: str = './diagnostics'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate all diagnostic plots and save to directory.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts.\n",
    "        break_events: List of break event dicts with high-res pre-break data.\n",
    "        output_dir: Directory to save plots.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    plots = [\n",
    "        ('break_by_phase', plot_break_count_by_phase, [episode_data]),\n",
    "        ('break_by_mode', plot_break_count_by_mode, [episode_data]),\n",
    "        ('force_by_phase', plot_force_by_phase, [episode_data]),\n",
    "        ('velocity_by_phase', plot_velocity_by_phase, [episode_data]),\n",
    "        ('prebreak_timeseries', plot_prebreak_timeseries, [break_events]),\n",
    "        ('prebreak_summary', plot_prebreak_summary, [break_events]),\n",
    "        ('velocity_at_contact', plot_velocity_at_contact_comparison, [episode_data]),\n",
    "        ('selection_confidence', plot_selection_confidence_at_contact, [episode_data]),\n",
    "        ('force_tracking', plot_force_tracking, [episode_data]),\n",
    "        ('force_error_ts', plot_force_error_timeseries, [episode_data]),\n",
    "    ]\n",
    "    \n",
    "    for name, func, args in plots:\n",
    "        try:\n",
    "            fig = func(*args)\n",
    "            fig.savefig(os.path.join(output_dir, f'{name}.png'), dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            print(f'Saved {name}.png')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to generate {name}: {e}')\n",
    "\n",
    "\n",
    "def print_break_summary(episode_data: List[Dict]) -> None:\n",
    "    \"\"\"\n",
    "    Print summary statistics about break events.\n",
    "    \"\"\"\n",
    "    stats = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        outcome = ep['outcome']\n",
    "        stats[policy]['total'] += 1\n",
    "        stats[policy][outcome] += 1\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"BREAK RATE SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for policy, s in stats.items():\n",
    "        total = s['total']\n",
    "        print(f\"\\n{policy.upper()}:\")\n",
    "        print(f\"  Total episodes: {total}\")\n",
    "        for outcome in ['success', 'break', 'timeout']:\n",
    "            count = s[outcome]  # defaultdict returns 0 for missing keys\n",
    "            rate = 100 * count / total if total > 0 else 0\n",
    "            print(f\"  {outcome:12s}: {count:4d} ({rate:5.1f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "generate_all_diagnostics(episode_data, break_events) \n",
    "print_break_summary(episode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550bef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. EPISODE RETURN ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def compute_episode_returns(\n",
    "    episode_data: List[Dict],\n",
    "    reward_key: str = None,\n",
    "    ignore_keys: List[str] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Compute and print episode return statistics grouped by policy and outcome.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        reward_key: Specific reward component to sum. If None, sums all components.\n",
    "                    If 'total' or '_total', looks for a total field.\n",
    "        ignore_keys: List of reward keys to exclude from summation.\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    if ignore_keys is None:\n",
    "        ignore_keys = []\n",
    "    \n",
    "    # Group returns by (policy, outcome)\n",
    "    returns_by_group = defaultdict(list)\n",
    "    per_step_by_group = defaultdict(list)\n",
    "    steps_by_group = defaultdict(list)\n",
    "    \n",
    "    # Track what reward keys are available\n",
    "    all_reward_keys = set()\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        outcome = ep['outcome']\n",
    "        steps = ep['steps']\n",
    "        \n",
    "        episode_return = 0.0\n",
    "        for step in steps:\n",
    "            rewards = step.get('rewards', {})\n",
    "            if isinstance(rewards, dict):\n",
    "                all_reward_keys.update(rewards.keys())\n",
    "                if reward_key is None:\n",
    "                    # Sum all components except ignored ones\n",
    "                    episode_return += sum(v for k, v in rewards.items() if k not in ignore_keys)\n",
    "                elif reward_key in rewards and reward_key not in ignore_keys:\n",
    "                    episode_return += rewards[reward_key]\n",
    "            elif isinstance(rewards, (int, float)):\n",
    "                # Single reward value\n",
    "                episode_return += rewards\n",
    "        \n",
    "        returns_by_group[(policy, outcome)].append(episode_return)\n",
    "        steps_by_group[(policy, outcome)].append(len(steps))\n",
    "        if len(steps) > 0:\n",
    "            per_step_by_group[(policy, outcome)].append(episode_return / len(steps))\n",
    "        else:\n",
    "            per_step_by_group[(policy, outcome)].append(0.0)\n",
    "    \n",
    "    # Print available reward keys\n",
    "    print(\"=\" * 105)\n",
    "    print(\"EPISODE RETURN ANALYSIS\")\n",
    "    print(\"=\" * 105)\n",
    "    if all_reward_keys:\n",
    "        print(f\"Available reward keys: {sorted(all_reward_keys)}\")\n",
    "        if ignore_keys:\n",
    "            print(f\"Ignoring: {ignore_keys}\")\n",
    "        print(f\"Analyzing: {'all components summed' if reward_key is None else reward_key}\")\n",
    "    print()\n",
    "    \n",
    "    # Print statistics by group\n",
    "    print(f\"{'Policy':<8} {'Outcome':<8} {'N':>5} {'EpLen':>8} {'LenStd':>8} {'Total':>10} {'TotalStd':>10} {'PerStep':>10}\")\n",
    "    print(\"-\" * 105)\n",
    "    \n",
    "    for (policy, outcome) in sorted(returns_by_group.keys()):\n",
    "        returns = returns_by_group[(policy, outcome)]\n",
    "        per_step = per_step_by_group[(policy, outcome)]\n",
    "        steps = steps_by_group[(policy, outcome)]\n",
    "        n = len(returns)\n",
    "        mean_return = np.mean(returns)\n",
    "        std_return = np.std(returns)\n",
    "        mean_per_step = np.mean(per_step)\n",
    "        mean_steps = np.mean(steps)\n",
    "        std_steps = np.std(steps)\n",
    "        print(f\"{policy:<8} {outcome:<8} {n:>5} {mean_steps:>8.1f} {std_steps:>8.1f} {mean_return:>10.2f} {std_return:>10.2f} {mean_per_step:>10.4f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Summary by policy (all outcomes)\n",
    "    print(\"Summary by policy (all outcomes):\")\n",
    "    print(\"-\" * 60)\n",
    "    for policy in ['lclop', 'pose']:\n",
    "        all_returns = []\n",
    "        all_per_step = []\n",
    "        all_steps = []\n",
    "        for (p, o), returns in returns_by_group.items():\n",
    "            if p == policy:\n",
    "                all_returns.extend(returns)\n",
    "                all_per_step.extend(per_step_by_group[(p, o)])\n",
    "                all_steps.extend(steps_by_group[(p, o)])\n",
    "        if all_returns:\n",
    "            print(f\"{policy}: total={np.mean(all_returns):.2f}±{np.std(all_returns):.2f}, \"\n",
    "                  f\"per_step={np.mean(all_per_step):.4f}, \"\n",
    "                  f\"ep_len={np.mean(all_steps):.1f}±{np.std(all_steps):.1f}, n={len(all_returns)}\")\n",
    "    \n",
    "    print(\"=\" * 105)\n",
    "\n",
    "\n",
    "def compute_reward_breakdown(\n",
    "    episode_data: List[Dict],\n",
    "    ignore_keys: List[str] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Compute breakdown of reward components by policy and outcome.\n",
    "    \n",
    "    Args:\n",
    "        episode_data: List of episode dicts\n",
    "        ignore_keys: List of reward keys to exclude from display.\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    if ignore_keys is None:\n",
    "        ignore_keys = []\n",
    "    \n",
    "    # Collect reward sums by (policy, outcome, reward_key)\n",
    "    reward_sums = defaultdict(lambda: defaultdict(list))\n",
    "    step_counts = defaultdict(list)\n",
    "    \n",
    "    for ep in episode_data:\n",
    "        policy = ep['policy']\n",
    "        outcome = ep['outcome']\n",
    "        steps = ep['steps']\n",
    "        group = (policy, outcome)\n",
    "        \n",
    "        step_counts[group].append(len(steps))\n",
    "        \n",
    "        ep_rewards = defaultdict(float)\n",
    "        for step in steps:\n",
    "            rewards = step.get('rewards', {})\n",
    "            if isinstance(rewards, dict):\n",
    "                for key, val in rewards.items():\n",
    "                    if key not in ignore_keys:\n",
    "                        ep_rewards[key] += val\n",
    "        \n",
    "        for key, total in ep_rewards.items():\n",
    "            reward_sums[group][key].append(total)\n",
    "    \n",
    "    print(\"=\" * 75)\n",
    "    print(\"REWARD BREAKDOWN\")\n",
    "    if ignore_keys:\n",
    "        print(f\"Ignoring: {ignore_keys}\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    # Get all reward keys\n",
    "    all_keys = set()\n",
    "    for group_rewards in reward_sums.values():\n",
    "        all_keys.update(group_rewards.keys())\n",
    "    all_keys = sorted(all_keys)\n",
    "    \n",
    "    if not all_keys:\n",
    "        print(\"No reward components found in data.\")\n",
    "        return\n",
    "    \n",
    "    for (policy, outcome) in sorted(reward_sums.keys()):\n",
    "        group = (policy, outcome)\n",
    "        n_eps = len(step_counts[group])\n",
    "        avg_steps = np.mean(step_counts[group])\n",
    "        \n",
    "        print(f\"\\n{policy}/{outcome} (n={n_eps}, avg_steps={avg_steps:.1f}):\")\n",
    "        print(f\"  {'Component':<30} {'PerStep':>12} {'Total':>12}\")\n",
    "        print(\"-\" * 58)\n",
    "        \n",
    "        total_per_step = 0.0\n",
    "        total_episode = 0.0\n",
    "        \n",
    "        for key in all_keys:\n",
    "            if key in reward_sums[group]:\n",
    "                values = reward_sums[group][key]\n",
    "                mean_total = np.mean(values)\n",
    "                mean_per_step = mean_total / avg_steps\n",
    "                total_per_step += mean_per_step\n",
    "                total_episode += mean_total\n",
    "                print(f\"  {key:<30} {mean_per_step:>12.4f} {mean_total:>12.2f}\")\n",
    "        \n",
    "        print(\"-\" * 58)\n",
    "        print(f\"  {'TOTAL':<30} {total_per_step:>12.4f} {total_episode:>12.2f}\")\n",
    "    \n",
    "    print(\"=\" * 75)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ignore = ['action_penalty', 'action_grad_penalty']\n",
    "compute_episode_returns(episode_data, ignore_keys=ignore)\n",
    "compute_reward_breakdown(episode_data, ignore_keys=ignore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d929ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_returns(r_dense, R_success, R_engaged, R_break, R_timeout,\n",
    "                             L_break=12, L_success=48, L_timeout=150):\n",
    "    G_break = L_break * r_dense + R_break\n",
    "    G_success = L_success * r_dense + R_engaged + R_success\n",
    "    G_timeout = L_timeout * r_dense + R_timeout\n",
    "    \n",
    "    print(f\"G_break:   {G_break:>8.2f}\")\n",
    "    print(f\"G_timeout: {G_timeout:>8.2f}\")\n",
    "    print(f\"G_success: {G_success:>8.2f}\")\n",
    "    print(f\"Ordering:  break({'<' if G_break < G_timeout else '>'})timeout({'<' if G_timeout < G_success else '>'})success\")\n",
    "    print(f\"Margins:   timeout-break={G_timeout-G_break:.1f}, success-timeout={G_success-G_timeout:.1f}\")\n",
    "    \n",
    "    return G_break, G_success, G_timeout\n",
    "\n",
    "compute_expected_returns(1, 10, 10, -10, -115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ad19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. REWARD ORDERING ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_reward_ordering(\n",
    "    R_success: float,\n",
    "    R_engaged: float,\n",
    "    R_break: float,\n",
    "    R_timeout: float,\n",
    "    L_break: float = 12,\n",
    "    L_success: float = 48,\n",
    "    L_timeout: float = 150,\n",
    "    r_dense_range: Tuple[float, float] = (0, 1),\n",
    "    n_points: int = 100,\n",
    "    figsize: Tuple[float, float] = (10, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot expected returns for break, timeout, engaged_only, and success across r_dense values.\n",
    "    \n",
    "    Helps visualize whether reward ordering (break < timeout < engaged_only < success) holds\n",
    "    throughout training as dense reward rate changes.\n",
    "    \n",
    "    Args:\n",
    "        R_success: Sparse success reward\n",
    "        R_engaged: Sparse engagement reward\n",
    "        R_break: Sparse break penalty (typically negative or zero)\n",
    "        R_timeout: Sparse timeout penalty (typically negative)\n",
    "        L_break: Expected episode length for break outcomes\n",
    "        L_success: Expected episode length for success outcomes\n",
    "        L_timeout: Episode length for timeout (max steps)\n",
    "        r_dense_range: (min, max) range for r_dense to plot\n",
    "        n_points: Number of points to plot\n",
    "        figsize: Figure size\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure\n",
    "    \"\"\"\n",
    "    r_dense = np.linspace(r_dense_range[0], r_dense_range[1], n_points)\n",
    "    \n",
    "    G_break = L_break * r_dense + R_break\n",
    "    G_timeout = L_timeout * r_dense + R_timeout\n",
    "    G_engaged_only = L_success * r_dense + R_engaged  # Gets engaged but times out\n",
    "    G_engaged_break = L_success * r_dense + R_engaged + R_break  # Gets engaged then breaks\n",
    "    G_success = L_success * r_dense + R_engaged + R_success\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    ax.plot(r_dense, G_break, 'r-', linewidth=2, label=f'Break (L={L_break}, R={R_break})')\n",
    "    ax.plot(r_dense, G_engaged_break, 'darkred', linewidth=2, linestyle='--', \n",
    "            label=f'Engaged+Break (L={L_success}, R={R_engaged}+{R_break})')\n",
    "    ax.plot(r_dense, G_timeout, 'orange', linewidth=2, label=f'Timeout (L={L_timeout}, R={R_timeout})')\n",
    "    ax.plot(r_dense, G_engaged_only, 'gold', linewidth=2, linestyle='--', \n",
    "            label=f'Engaged Only (L={L_success}, R={R_engaged})')\n",
    "    ax.plot(r_dense, G_success, 'g-', linewidth=2, label=f'Success (L={L_success}, R={R_engaged}+{R_success})')\n",
    "    \n",
    "    # Find crossover points for break=timeout\n",
    "    denom_bt = L_break - L_timeout\n",
    "    if denom_bt != 0:\n",
    "        r_cross_bt = (R_timeout - R_break) / denom_bt\n",
    "        if r_dense_range[0] <= r_cross_bt <= r_dense_range[1]:\n",
    "            G_cross = L_break * r_cross_bt + R_break\n",
    "            ax.axvline(x=r_cross_bt, color='purple', linestyle='--', alpha=0.5)\n",
    "            ax.plot(r_cross_bt, G_cross, 'ko', markersize=8)\n",
    "            ax.annotate(f'Break=Timeout\\nr={r_cross_bt:.3f}', \n",
    "                       xy=(r_cross_bt, G_cross), xytext=(r_cross_bt + 0.05, G_cross),\n",
    "                       fontsize=9)\n",
    "    \n",
    "    # Find crossover for timeout=engaged_only\n",
    "    # L_timeout * r + R_timeout = L_success * r + R_engaged\n",
    "    denom_te = L_timeout - L_success\n",
    "    if denom_te != 0:\n",
    "        r_cross_te = (R_engaged - R_timeout) / denom_te\n",
    "        if r_dense_range[0] <= r_cross_te <= r_dense_range[1]:\n",
    "            G_cross = L_timeout * r_cross_te + R_timeout\n",
    "            ax.axvline(x=r_cross_te, color='blue', linestyle='--', alpha=0.5)\n",
    "            ax.plot(r_cross_te, G_cross, 'bs', markersize=8)\n",
    "            ax.annotate(f'Timeout=Engaged\\nr={r_cross_te:.3f}', \n",
    "                       xy=(r_cross_te, G_cross), xytext=(r_cross_te + 0.05, G_cross + 5),\n",
    "                       fontsize=9)\n",
    "    \n",
    "    # Mark typical training stages\n",
    "    ax.axvline(x=0.16, color='gray', linestyle=':', alpha=0.7)\n",
    "    ax.annotate('Early\\n(~0.16)', xy=(0.16, ax.get_ylim()[0]), fontsize=8, ha='center')\n",
    "    \n",
    "    ax.axvline(x=0.46, color='gray', linestyle=':', alpha=0.7)\n",
    "    ax.annotate('Late\\n(~0.46)', xy=(0.46, ax.get_ylim()[0]), fontsize=8, ha='center')\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    ax.set_xlabel('Dense Reward Rate (r_dense)', fontsize=12)\n",
    "    ax.set_ylabel('Expected Episode Return (G)', fontsize=12)\n",
    "    ax.set_title('Reward Ordering Across Training\\n(Goal: Break < Timeout < Eng+Break < Engaged < Success)', fontsize=12)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def check_reward_ordering(\n",
    "    R_success: float,\n",
    "    R_engaged: float,\n",
    "    R_break: float,\n",
    "    R_timeout: float,\n",
    "    L_break: float = 12,\n",
    "    L_success: float = 48,\n",
    "    L_timeout: float = 150,\n",
    "    r_dense_values: List[float] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Print expected returns at specific r_dense values to verify ordering.\n",
    "    \n",
    "    Args:\n",
    "        R_success: Sparse success reward\n",
    "        R_engaged: Sparse engagement reward  \n",
    "        R_break: Sparse break penalty\n",
    "        R_timeout: Sparse timeout penalty\n",
    "        L_break: Expected episode length for break\n",
    "        L_success: Expected episode length for success\n",
    "        L_timeout: Episode length for timeout\n",
    "        r_dense_values: List of r_dense values to check (default: [0.1, 0.16, 0.3, 0.46, 0.6])\n",
    "    \"\"\"\n",
    "    if r_dense_values is None:\n",
    "        r_dense_values = [0.1, 0.16, 0.3, 0.46, 0.6]\n",
    "    \n",
    "    print(\"=\" * 105)\n",
    "    print(\"REWARD ORDERING CHECK\")\n",
    "    print(f\"R_success={R_success}, R_engaged={R_engaged}, R_break={R_break}, R_timeout={R_timeout}\")\n",
    "    print(f\"L_break={L_break}, L_success={L_success}, L_timeout={L_timeout}\")\n",
    "    print(\"=\" * 105)\n",
    "    print(f\"{'r_dense':>8} {'G_break':>10} {'G_timeout':>10} {'G_eng+brk':>10} {'G_engaged':>10} {'G_success':>10} {'Ordering':>30}\")\n",
    "    print(\"-\" * 105)\n",
    "    \n",
    "    for r in r_dense_values:\n",
    "        G_break = L_break * r + R_break\n",
    "        G_timeout = L_timeout * r + R_timeout\n",
    "        G_engaged_only = L_success * r + R_engaged\n",
    "        G_engaged_break = L_success * r + R_engaged + R_break\n",
    "        G_success = L_success * r + R_engaged + R_success\n",
    "        \n",
    "        # Determine ordering\n",
    "        outcomes = [('B', G_break), ('EB', G_engaged_break), ('T', G_timeout), ('E', G_engaged_only), ('S', G_success)]\n",
    "        outcomes.sort(key=lambda x: x[1])\n",
    "        ordering = '<'.join([o[0] for o in outcomes])\n",
    "        \n",
    "        correct = (G_break < G_timeout < G_engaged_break < G_engaged_only < G_success)\n",
    "        status = \"✓\" if correct else \"✗\"\n",
    "        \n",
    "        print(f\"{r:>8.2f} {G_break:>10.2f} {G_timeout:>10.2f} {G_engaged_break:>10.2f} {G_engaged_only:>10.2f} {G_success:>10.2f} {ordering:>28} {status}\")\n",
    "    \n",
    "    print(\"=\" * 105)\n",
    "    print(\"Legend: B=Break, T=Timeout, EB=Engaged+Break, E=Engaged only, S=Success\")\n",
    "    print(\"Target: B < T < EB < E < S\")\n",
    "\n",
    "\n",
    "rs = 40\n",
    "re = 60\n",
    "rb = -15\n",
    "rt = -20\n",
    "\n",
    "\n",
    "plot_reward_ordering(\n",
    "    R_success=rs, R_engaged=re, R_break=rb, R_timeout=rt\n",
    ")\n",
    "\n",
    "check_reward_ordering(\n",
    "    R_success=rs, R_engaged=re, R_break=rb, R_timeout=rt\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaaclab_drail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
